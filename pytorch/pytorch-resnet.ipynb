{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# https://github.com/yunjey/pytorch-tutorial/blob/master/tutorials/02-intermediate/deep_residual_network/main.py#L76-L113","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-09-08T10:44:19.142025Z","iopub.execute_input":"2021-09-08T10:44:19.142328Z","iopub.status.idle":"2021-09-08T10:44:19.147639Z","shell.execute_reply.started":"2021-09-08T10:44:19.142251Z","shell.execute_reply":"2021-09-08T10:44:19.146029Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!pip uninstall torch -y\n!pip uninstall torchvision -y\n!pip install torch \n!pip install torchvision\nimport torch \nimport torchvision\nimport torch.nn as nn\nimport numpy as np\nimport torchvision.transforms as transforms","metadata":{"execution":{"iopub.status.busy":"2021-09-08T10:51:25.123928Z","iopub.execute_input":"2021-09-08T10:51:25.124301Z","iopub.status.idle":"2021-09-08T10:52:47.828188Z","shell.execute_reply.started":"2021-09-08T10:51:25.124242Z","shell.execute_reply":"2021-09-08T10:52:47.827385Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Found existing installation: torch 1.7.0\nUninstalling torch-1.7.0:\n  Successfully uninstalled torch-1.7.0\n\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\nFound existing installation: torchvision 0.8.1\nUninstalling torchvision-0.8.1:\n  Successfully uninstalled torchvision-0.8.1\n\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\nCollecting torch\n  Downloading torch-1.9.0-cp37-cp37m-manylinux1_x86_64.whl (831.4 MB)\n\u001b[K     |████████████████████████████████| 831.4 MB 2.1 kB/s  eta 0:00:01   |█▋                              | 42.8 MB 4.4 MB/s eta 0:03:01     |█████████▌                      | 246.3 MB 24.6 MB/s eta 0:00:24     |█████████████████▋              | 458.2 MB 70.5 MB/s eta 0:00:06     |██████████████████████████▋     | 691.3 MB 50.4 MB/s eta 0:00:03     |████████████████████████████▎   | 735.2 MB 15.4 MB/s eta 0:00:07     |████████████████████████████▍   | 736.5 MB 15.4 MB/s eta 0:00:07     |████████████████████████████▍   | 737.2 MB 15.4 MB/s eta 0:00:07     |████████████████████████████▍   | 737.8 MB 15.4 MB/s eta 0:00:07     |████████████████████████████▌   | 739.1 MB 15.4 MB/s eta 0:00:06     |█████████████████████████████▉  | 776.1 MB 49.7 MB/s eta 0:00:02     |██████████████████████████████  | 777.3 MB 49.7 MB/s eta 0:00:02     |██████████████████████████████  | 778.4 MB 49.7 MB/s eta 0:00:02�█▌ | 791.1 MB 49.7 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch) (3.7.4.3)\nInstalling collected packages: torch\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nfastai 2.2.7 requires torchvision<0.9,>=0.8, which is not installed.\neasyocr 1.3.2 requires torchvision>=0.5, which is not installed.\nallennlp 2.5.0 requires torchvision<0.10.0,>=0.8.1, which is not installed.\nkornia 0.5.5 requires numpy<=1.19, but you have numpy 1.19.5 which is incompatible.\nfastai 2.2.7 requires torch<1.8,>=1.7.0, but you have torch 1.9.0 which is incompatible.\nallennlp 2.5.0 requires torch<1.9.0,>=1.6.0, but you have torch 1.9.0 which is incompatible.\u001b[0m\nSuccessfully installed torch-1.9.0\n\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\nCollecting torchvision\n  Downloading torchvision-0.10.0-cp37-cp37m-manylinux1_x86_64.whl (22.1 MB)\n\u001b[K     |████████████████████████████████| 22.1 MB 4.6 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torchvision) (1.19.5)\nRequirement already satisfied: torch==1.9.0 in /opt/conda/lib/python3.7/site-packages (from torchvision) (1.9.0)\nRequirement already satisfied: pillow>=5.3.0 in /opt/conda/lib/python3.7/site-packages (from torchvision) (8.2.0)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch==1.9.0->torchvision) (3.7.4.3)\nInstalling collected packages: torchvision\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nfastai 2.2.7 requires torch<1.8,>=1.7.0, but you have torch 1.9.0 which is incompatible.\nfastai 2.2.7 requires torchvision<0.9,>=0.8, but you have torchvision 0.10.0 which is incompatible.\nallennlp 2.5.0 requires torch<1.9.0,>=1.6.0, but you have torch 1.9.0 which is incompatible.\nallennlp 2.5.0 requires torchvision<0.10.0,>=0.8.1, but you have torchvision 0.10.0 which is incompatible.\u001b[0m\nSuccessfully installed torchvision-0.10.0\n\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"# Device configuration\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"execution":{"iopub.status.busy":"2021-09-08T11:05:10.103108Z","iopub.execute_input":"2021-09-08T11:05:10.103474Z","iopub.status.idle":"2021-09-08T11:05:10.149055Z","shell.execute_reply.started":"2021-09-08T11:05:10.103422Z","shell.execute_reply":"2021-09-08T11:05:10.148173Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Hyper-parameters\nnum_epochs = 80\nbatch_size = 100\nlearning_rate = 0.001","metadata":{"execution":{"iopub.status.busy":"2021-09-08T11:05:20.977990Z","iopub.execute_input":"2021-09-08T11:05:20.978332Z","iopub.status.idle":"2021-09-08T11:05:20.983356Z","shell.execute_reply.started":"2021-09-08T11:05:20.978300Z","shell.execute_reply":"2021-09-08T11:05:20.982233Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Image preprocessing modules\ntransform = transforms.Compose([\n    transforms.Pad(4),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomCrop(32),\n    transforms.ToTensor()])","metadata":{"execution":{"iopub.status.busy":"2021-09-08T11:06:35.327264Z","iopub.execute_input":"2021-09-08T11:06:35.327624Z","iopub.status.idle":"2021-09-08T11:06:35.332212Z","shell.execute_reply.started":"2021-09-08T11:06:35.327592Z","shell.execute_reply":"2021-09-08T11:06:35.331354Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# CIFAR-10 dataset\ntrain_dataset = torchvision.datasets.CIFAR10(root='../../data/',\n                                             train=True, \n                                             transform=transform,\n                                             download=True)\n\ntest_dataset = torchvision.datasets.CIFAR10(root='../../data/',\n                                            train=False, \n                                            transform=transforms.ToTensor())\n\n# Data loader\ntrain_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n                                           batch_size=batch_size,\n                                           shuffle=True)\n\ntest_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n                                          batch_size=batch_size,\n                                          shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2021-09-08T11:06:44.392818Z","iopub.execute_input":"2021-09-08T11:06:44.393167Z","iopub.status.idle":"2021-09-08T11:06:49.926052Z","shell.execute_reply.started":"2021-09-08T11:06:44.393136Z","shell.execute_reply":"2021-09-08T11:06:49.925091Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ../../data/cifar-10-python.tar.gz\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/170498071 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"393292c9d33d4743a83dd7944142dad5"}},"metadata":{}},{"name":"stdout","text":"Extracting ../../data/cifar-10-python.tar.gz to ../../data/\n","output_type":"stream"}]},{"cell_type":"code","source":"# 3x3 convolution\ndef conv3x3(in_channels, out_channels, stride=1):\n    return nn.Conv2d(in_channels, out_channels, kernel_size=3, \n                     stride=stride, padding=1, bias=False)","metadata":{"execution":{"iopub.status.busy":"2021-09-08T11:07:37.835304Z","iopub.execute_input":"2021-09-08T11:07:37.835673Z","iopub.status.idle":"2021-09-08T11:07:37.839750Z","shell.execute_reply.started":"2021-09-08T11:07:37.835642Z","shell.execute_reply":"2021-09-08T11:07:37.838861Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Residual block\nclass ResidualBlock(nn.Module):\n    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n        super(ResidualBlock, self).__init__()\n        self.conv1 = conv3x3(in_channels, out_channels, stride)\n        self.bn1 = nn.BatchNorm2d(out_channels)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = conv3x3(out_channels, out_channels)\n        self.bn2 = nn.BatchNorm2d(out_channels)\n        self.downsample = downsample\n        \n    def forward(self, x):\n        residual = x\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n        out = self.conv2(out)\n        out = self.bn2(out)\n        if self.downsample:\n            residual = self.downsample(x)\n        out += residual\n        out = self.relu(out)\n        return out","metadata":{"execution":{"iopub.status.busy":"2021-09-08T11:07:47.183632Z","iopub.execute_input":"2021-09-08T11:07:47.183959Z","iopub.status.idle":"2021-09-08T11:07:47.191117Z","shell.execute_reply.started":"2021-09-08T11:07:47.183928Z","shell.execute_reply":"2021-09-08T11:07:47.190242Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# ResNet\nclass ResNet(nn.Module):\n    def __init__(self, block, layers, num_classes=10):\n        super(ResNet, self).__init__()\n        self.in_channels = 16\n        self.conv = conv3x3(3, 16)\n        self.bn = nn.BatchNorm2d(16)\n        self.relu = nn.ReLU(inplace=True)\n        self.layer1 = self.make_layer(block, 16, layers[0])\n        self.layer2 = self.make_layer(block, 32, layers[1], 2)\n        self.layer3 = self.make_layer(block, 64, layers[2], 2)\n        self.avg_pool = nn.AvgPool2d(8)\n        self.fc = nn.Linear(64, num_classes)\n        \n    def make_layer(self, block, out_channels, blocks, stride=1):\n        downsample = None\n        if (stride != 1) or (self.in_channels != out_channels):\n            downsample = nn.Sequential(\n                conv3x3(self.in_channels, out_channels, stride=stride),\n                nn.BatchNorm2d(out_channels))\n        layers = []\n        layers.append(block(self.in_channels, out_channels, stride, downsample))\n        self.in_channels = out_channels\n        for i in range(1, blocks):\n            layers.append(block(out_channels, out_channels))\n        return nn.Sequential(*layers)\n    \n    def forward(self, x):\n        out = self.conv(x)\n        out = self.bn(out)\n        out = self.relu(out)\n        out = self.layer1(out)\n        out = self.layer2(out)\n        out = self.layer3(out)\n        out = self.avg_pool(out)\n        out = out.view(out.size(0), -1)\n        out = self.fc(out)\n        return out","metadata":{"execution":{"iopub.status.busy":"2021-09-08T11:20:07.069389Z","iopub.execute_input":"2021-09-08T11:20:07.069855Z","iopub.status.idle":"2021-09-08T11:20:07.085455Z","shell.execute_reply.started":"2021-09-08T11:20:07.069814Z","shell.execute_reply":"2021-09-08T11:20:07.084622Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"model = ResNet(ResidualBlock, [2, 2, 2]).to(device)","metadata":{"execution":{"iopub.status.busy":"2021-09-08T11:21:06.760036Z","iopub.execute_input":"2021-09-08T11:21:06.760368Z","iopub.status.idle":"2021-09-08T11:21:09.189740Z","shell.execute_reply.started":"2021-09-08T11:21:06.760338Z","shell.execute_reply":"2021-09-08T11:21:09.188858Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"\n# Loss and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)","metadata":{"execution":{"iopub.status.busy":"2021-09-08T11:21:44.238563Z","iopub.execute_input":"2021-09-08T11:21:44.238890Z","iopub.status.idle":"2021-09-08T11:21:44.245737Z","shell.execute_reply.started":"2021-09-08T11:21:44.238860Z","shell.execute_reply":"2021-09-08T11:21:44.244800Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# For updating learning rate\ndef update_lr(optimizer, lr):    \n    for param_group in optimizer.param_groups:\n        param_group['lr'] = lr","metadata":{"execution":{"iopub.status.busy":"2021-09-08T11:22:41.833924Z","iopub.execute_input":"2021-09-08T11:22:41.834262Z","iopub.status.idle":"2021-09-08T11:22:41.838558Z","shell.execute_reply.started":"2021-09-08T11:22:41.834232Z","shell.execute_reply":"2021-09-08T11:22:41.837587Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# Train the model\ntotal_step = len(train_loader)\ncurr_lr = learning_rate\nfor epoch in range(num_epochs):\n    for i, (images, labels) in enumerate(train_loader):\n        images = images.to(device)\n        labels = labels.to(device)\n        \n        # Forward pass\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        \n        # Backward and optimize\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        if (i+1) % 100 == 0:\n            print (\"Epoch [{}/{}], Step [{}/{}] Loss: {:.4f}\"\n                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n\n    # Decay learning rate\n    if (epoch+1) % 20 == 0:\n        curr_lr /= 3\n        update_lr(optimizer, curr_lr)","metadata":{"execution":{"iopub.status.busy":"2021-09-08T11:39:00.907794Z","iopub.execute_input":"2021-09-08T11:39:00.908201Z","iopub.status.idle":"2021-09-08T11:58:31.613996Z","shell.execute_reply.started":"2021-09-08T11:39:00.908166Z","shell.execute_reply":"2021-09-08T11:58:31.613042Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Epoch [1/80], Step [100/500] Loss: 0.1353\nEpoch [1/80], Step [200/500] Loss: 0.1589\nEpoch [1/80], Step [300/500] Loss: 0.2783\nEpoch [1/80], Step [400/500] Loss: 0.1995\nEpoch [1/80], Step [500/500] Loss: 0.1979\nEpoch [2/80], Step [100/500] Loss: 0.1527\nEpoch [2/80], Step [200/500] Loss: 0.2163\nEpoch [2/80], Step [300/500] Loss: 0.1902\nEpoch [2/80], Step [400/500] Loss: 0.2046\nEpoch [2/80], Step [500/500] Loss: 0.2448\nEpoch [3/80], Step [100/500] Loss: 0.1331\nEpoch [3/80], Step [200/500] Loss: 0.1561\nEpoch [3/80], Step [300/500] Loss: 0.2080\nEpoch [3/80], Step [400/500] Loss: 0.1957\nEpoch [3/80], Step [500/500] Loss: 0.1842\nEpoch [4/80], Step [100/500] Loss: 0.1439\nEpoch [4/80], Step [200/500] Loss: 0.1469\nEpoch [4/80], Step [300/500] Loss: 0.1919\nEpoch [4/80], Step [400/500] Loss: 0.2458\nEpoch [4/80], Step [500/500] Loss: 0.2072\nEpoch [5/80], Step [100/500] Loss: 0.1801\nEpoch [5/80], Step [200/500] Loss: 0.1937\nEpoch [5/80], Step [300/500] Loss: 0.1733\nEpoch [5/80], Step [400/500] Loss: 0.2230\nEpoch [5/80], Step [500/500] Loss: 0.1573\nEpoch [6/80], Step [100/500] Loss: 0.1719\nEpoch [6/80], Step [200/500] Loss: 0.1602\nEpoch [6/80], Step [300/500] Loss: 0.1702\nEpoch [6/80], Step [400/500] Loss: 0.1507\nEpoch [6/80], Step [500/500] Loss: 0.1633\nEpoch [7/80], Step [100/500] Loss: 0.2727\nEpoch [7/80], Step [200/500] Loss: 0.1447\nEpoch [7/80], Step [300/500] Loss: 0.1530\nEpoch [7/80], Step [400/500] Loss: 0.0912\nEpoch [7/80], Step [500/500] Loss: 0.1863\nEpoch [8/80], Step [100/500] Loss: 0.1263\nEpoch [8/80], Step [200/500] Loss: 0.1761\nEpoch [8/80], Step [300/500] Loss: 0.1826\nEpoch [8/80], Step [400/500] Loss: 0.1973\nEpoch [8/80], Step [500/500] Loss: 0.1181\nEpoch [9/80], Step [100/500] Loss: 0.1455\nEpoch [9/80], Step [200/500] Loss: 0.1414\nEpoch [9/80], Step [300/500] Loss: 0.1295\nEpoch [9/80], Step [400/500] Loss: 0.0459\nEpoch [9/80], Step [500/500] Loss: 0.2168\nEpoch [10/80], Step [100/500] Loss: 0.2557\nEpoch [10/80], Step [200/500] Loss: 0.2703\nEpoch [10/80], Step [300/500] Loss: 0.0999\nEpoch [10/80], Step [400/500] Loss: 0.1553\nEpoch [10/80], Step [500/500] Loss: 0.2005\nEpoch [11/80], Step [100/500] Loss: 0.0600\nEpoch [11/80], Step [200/500] Loss: 0.1835\nEpoch [11/80], Step [300/500] Loss: 0.1601\nEpoch [11/80], Step [400/500] Loss: 0.2696\nEpoch [11/80], Step [500/500] Loss: 0.1679\nEpoch [12/80], Step [100/500] Loss: 0.1309\nEpoch [12/80], Step [200/500] Loss: 0.1750\nEpoch [12/80], Step [300/500] Loss: 0.1830\nEpoch [12/80], Step [400/500] Loss: 0.1350\nEpoch [12/80], Step [500/500] Loss: 0.1893\nEpoch [13/80], Step [100/500] Loss: 0.2941\nEpoch [13/80], Step [200/500] Loss: 0.1547\nEpoch [13/80], Step [300/500] Loss: 0.1948\nEpoch [13/80], Step [400/500] Loss: 0.1450\nEpoch [13/80], Step [500/500] Loss: 0.2642\nEpoch [14/80], Step [100/500] Loss: 0.0816\nEpoch [14/80], Step [200/500] Loss: 0.1218\nEpoch [14/80], Step [300/500] Loss: 0.1134\nEpoch [14/80], Step [400/500] Loss: 0.1825\nEpoch [14/80], Step [500/500] Loss: 0.2162\nEpoch [15/80], Step [100/500] Loss: 0.1183\nEpoch [15/80], Step [200/500] Loss: 0.0782\nEpoch [15/80], Step [300/500] Loss: 0.1829\nEpoch [15/80], Step [400/500] Loss: 0.1599\nEpoch [15/80], Step [500/500] Loss: 0.2987\nEpoch [16/80], Step [100/500] Loss: 0.2077\nEpoch [16/80], Step [200/500] Loss: 0.2111\nEpoch [16/80], Step [300/500] Loss: 0.2005\nEpoch [16/80], Step [400/500] Loss: 0.1517\nEpoch [16/80], Step [500/500] Loss: 0.1663\nEpoch [17/80], Step [100/500] Loss: 0.0496\nEpoch [17/80], Step [200/500] Loss: 0.0737\nEpoch [17/80], Step [300/500] Loss: 0.1832\nEpoch [17/80], Step [400/500] Loss: 0.1728\nEpoch [17/80], Step [500/500] Loss: 0.1146\nEpoch [18/80], Step [100/500] Loss: 0.2618\nEpoch [18/80], Step [200/500] Loss: 0.2372\nEpoch [18/80], Step [300/500] Loss: 0.1159\nEpoch [18/80], Step [400/500] Loss: 0.1742\nEpoch [18/80], Step [500/500] Loss: 0.0826\nEpoch [19/80], Step [100/500] Loss: 0.0975\nEpoch [19/80], Step [200/500] Loss: 0.0665\nEpoch [19/80], Step [300/500] Loss: 0.0852\nEpoch [19/80], Step [400/500] Loss: 0.1480\nEpoch [19/80], Step [500/500] Loss: 0.1251\nEpoch [20/80], Step [100/500] Loss: 0.1380\nEpoch [20/80], Step [200/500] Loss: 0.1779\nEpoch [20/80], Step [300/500] Loss: 0.2182\nEpoch [20/80], Step [400/500] Loss: 0.2131\nEpoch [20/80], Step [500/500] Loss: 0.1340\nEpoch [21/80], Step [100/500] Loss: 0.1007\nEpoch [21/80], Step [200/500] Loss: 0.1913\nEpoch [21/80], Step [300/500] Loss: 0.1475\nEpoch [21/80], Step [400/500] Loss: 0.0652\nEpoch [21/80], Step [500/500] Loss: 0.1205\nEpoch [22/80], Step [100/500] Loss: 0.1643\nEpoch [22/80], Step [200/500] Loss: 0.1508\nEpoch [22/80], Step [300/500] Loss: 0.0775\nEpoch [22/80], Step [400/500] Loss: 0.1435\nEpoch [22/80], Step [500/500] Loss: 0.0920\nEpoch [23/80], Step [100/500] Loss: 0.1074\nEpoch [23/80], Step [200/500] Loss: 0.0706\nEpoch [23/80], Step [300/500] Loss: 0.2006\nEpoch [23/80], Step [400/500] Loss: 0.0763\nEpoch [23/80], Step [500/500] Loss: 0.0804\nEpoch [24/80], Step [100/500] Loss: 0.0458\nEpoch [24/80], Step [200/500] Loss: 0.0988\nEpoch [24/80], Step [300/500] Loss: 0.0260\nEpoch [24/80], Step [400/500] Loss: 0.1410\nEpoch [24/80], Step [500/500] Loss: 0.0322\nEpoch [25/80], Step [100/500] Loss: 0.1631\nEpoch [25/80], Step [200/500] Loss: 0.1457\nEpoch [25/80], Step [300/500] Loss: 0.0792\nEpoch [25/80], Step [400/500] Loss: 0.0509\nEpoch [25/80], Step [500/500] Loss: 0.0638\nEpoch [26/80], Step [100/500] Loss: 0.0864\nEpoch [26/80], Step [200/500] Loss: 0.0861\nEpoch [26/80], Step [300/500] Loss: 0.1262\nEpoch [26/80], Step [400/500] Loss: 0.0386\nEpoch [26/80], Step [500/500] Loss: 0.0683\nEpoch [27/80], Step [100/500] Loss: 0.0849\nEpoch [27/80], Step [200/500] Loss: 0.1183\nEpoch [27/80], Step [300/500] Loss: 0.0745\nEpoch [27/80], Step [400/500] Loss: 0.1757\nEpoch [27/80], Step [500/500] Loss: 0.0965\nEpoch [28/80], Step [100/500] Loss: 0.0926\nEpoch [28/80], Step [200/500] Loss: 0.1304\nEpoch [28/80], Step [300/500] Loss: 0.1081\nEpoch [28/80], Step [400/500] Loss: 0.1231\nEpoch [28/80], Step [500/500] Loss: 0.1112\nEpoch [29/80], Step [100/500] Loss: 0.1221\nEpoch [29/80], Step [200/500] Loss: 0.1069\nEpoch [29/80], Step [300/500] Loss: 0.0457\nEpoch [29/80], Step [400/500] Loss: 0.0427\nEpoch [29/80], Step [500/500] Loss: 0.1346\nEpoch [30/80], Step [100/500] Loss: 0.0735\nEpoch [30/80], Step [200/500] Loss: 0.0428\nEpoch [30/80], Step [300/500] Loss: 0.0682\nEpoch [30/80], Step [400/500] Loss: 0.0450\nEpoch [30/80], Step [500/500] Loss: 0.0797\nEpoch [31/80], Step [100/500] Loss: 0.0565\nEpoch [31/80], Step [200/500] Loss: 0.0916\nEpoch [31/80], Step [300/500] Loss: 0.1002\nEpoch [31/80], Step [400/500] Loss: 0.0346\nEpoch [31/80], Step [500/500] Loss: 0.0516\nEpoch [32/80], Step [100/500] Loss: 0.0372\nEpoch [32/80], Step [200/500] Loss: 0.1070\nEpoch [32/80], Step [300/500] Loss: 0.1228\nEpoch [32/80], Step [400/500] Loss: 0.1245\nEpoch [32/80], Step [500/500] Loss: 0.1451\nEpoch [33/80], Step [100/500] Loss: 0.0695\nEpoch [33/80], Step [200/500] Loss: 0.0517\nEpoch [33/80], Step [300/500] Loss: 0.0467\nEpoch [33/80], Step [400/500] Loss: 0.0624\nEpoch [33/80], Step [500/500] Loss: 0.0833\nEpoch [34/80], Step [100/500] Loss: 0.1003\nEpoch [34/80], Step [200/500] Loss: 0.0614\nEpoch [34/80], Step [300/500] Loss: 0.0521\nEpoch [34/80], Step [400/500] Loss: 0.0782\nEpoch [34/80], Step [500/500] Loss: 0.0664\nEpoch [35/80], Step [100/500] Loss: 0.0861\nEpoch [35/80], Step [200/500] Loss: 0.1305\nEpoch [35/80], Step [300/500] Loss: 0.0656\nEpoch [35/80], Step [400/500] Loss: 0.1108\nEpoch [35/80], Step [500/500] Loss: 0.1129\nEpoch [36/80], Step [100/500] Loss: 0.0530\nEpoch [36/80], Step [200/500] Loss: 0.0163\nEpoch [36/80], Step [300/500] Loss: 0.0863\nEpoch [36/80], Step [400/500] Loss: 0.0476\nEpoch [36/80], Step [500/500] Loss: 0.0952\nEpoch [37/80], Step [100/500] Loss: 0.0789\nEpoch [37/80], Step [200/500] Loss: 0.0672\nEpoch [37/80], Step [300/500] Loss: 0.0542\nEpoch [37/80], Step [400/500] Loss: 0.0471\nEpoch [37/80], Step [500/500] Loss: 0.0558\nEpoch [38/80], Step [100/500] Loss: 0.0226\nEpoch [38/80], Step [200/500] Loss: 0.0672\nEpoch [38/80], Step [300/500] Loss: 0.0260\nEpoch [38/80], Step [400/500] Loss: 0.0778\nEpoch [38/80], Step [500/500] Loss: 0.0521\nEpoch [39/80], Step [100/500] Loss: 0.1064\nEpoch [39/80], Step [200/500] Loss: 0.0546\nEpoch [39/80], Step [300/500] Loss: 0.0556\nEpoch [39/80], Step [400/500] Loss: 0.0384\nEpoch [39/80], Step [500/500] Loss: 0.0708\nEpoch [40/80], Step [100/500] Loss: 0.0945\nEpoch [40/80], Step [200/500] Loss: 0.1371\nEpoch [40/80], Step [300/500] Loss: 0.0740\nEpoch [40/80], Step [400/500] Loss: 0.0976\nEpoch [40/80], Step [500/500] Loss: 0.0296\nEpoch [41/80], Step [100/500] Loss: 0.1034\nEpoch [41/80], Step [200/500] Loss: 0.0202\nEpoch [41/80], Step [300/500] Loss: 0.0911\nEpoch [41/80], Step [400/500] Loss: 0.0613\nEpoch [41/80], Step [500/500] Loss: 0.0728\nEpoch [42/80], Step [100/500] Loss: 0.0703\nEpoch [42/80], Step [200/500] Loss: 0.0729\nEpoch [42/80], Step [300/500] Loss: 0.0782\nEpoch [42/80], Step [400/500] Loss: 0.0425\nEpoch [42/80], Step [500/500] Loss: 0.0287\nEpoch [43/80], Step [100/500] Loss: 0.0362\nEpoch [43/80], Step [200/500] Loss: 0.0398\nEpoch [43/80], Step [300/500] Loss: 0.0420\nEpoch [43/80], Step [400/500] Loss: 0.0630\nEpoch [43/80], Step [500/500] Loss: 0.0444\nEpoch [44/80], Step [100/500] Loss: 0.0672\nEpoch [44/80], Step [200/500] Loss: 0.1242\nEpoch [44/80], Step [300/500] Loss: 0.0759\nEpoch [44/80], Step [400/500] Loss: 0.0280\nEpoch [44/80], Step [500/500] Loss: 0.0600\nEpoch [45/80], Step [100/500] Loss: 0.0356\nEpoch [45/80], Step [200/500] Loss: 0.0428\nEpoch [45/80], Step [300/500] Loss: 0.0626\nEpoch [45/80], Step [400/500] Loss: 0.0387\nEpoch [45/80], Step [500/500] Loss: 0.0443\nEpoch [46/80], Step [100/500] Loss: 0.0627\nEpoch [46/80], Step [200/500] Loss: 0.0431\nEpoch [46/80], Step [300/500] Loss: 0.0359\nEpoch [46/80], Step [400/500] Loss: 0.0336\nEpoch [46/80], Step [500/500] Loss: 0.0403\nEpoch [47/80], Step [100/500] Loss: 0.0475\nEpoch [47/80], Step [200/500] Loss: 0.0560\nEpoch [47/80], Step [300/500] Loss: 0.0408\nEpoch [47/80], Step [400/500] Loss: 0.0268\nEpoch [47/80], Step [500/500] Loss: 0.0619\nEpoch [48/80], Step [100/500] Loss: 0.0554\nEpoch [48/80], Step [200/500] Loss: 0.0928\nEpoch [48/80], Step [300/500] Loss: 0.0597\nEpoch [48/80], Step [400/500] Loss: 0.0695\nEpoch [48/80], Step [500/500] Loss: 0.0784\nEpoch [49/80], Step [100/500] Loss: 0.0884\nEpoch [49/80], Step [200/500] Loss: 0.0324\nEpoch [49/80], Step [300/500] Loss: 0.0306\nEpoch [49/80], Step [400/500] Loss: 0.0856\nEpoch [49/80], Step [500/500] Loss: 0.1164\nEpoch [50/80], Step [100/500] Loss: 0.0511\nEpoch [50/80], Step [200/500] Loss: 0.0615\nEpoch [50/80], Step [300/500] Loss: 0.0546\nEpoch [50/80], Step [400/500] Loss: 0.0210\nEpoch [50/80], Step [500/500] Loss: 0.0659\nEpoch [51/80], Step [100/500] Loss: 0.0197\nEpoch [51/80], Step [200/500] Loss: 0.0861\nEpoch [51/80], Step [300/500] Loss: 0.0732\nEpoch [51/80], Step [400/500] Loss: 0.0665\nEpoch [51/80], Step [500/500] Loss: 0.0348\nEpoch [52/80], Step [100/500] Loss: 0.0356\nEpoch [52/80], Step [200/500] Loss: 0.0437\nEpoch [52/80], Step [300/500] Loss: 0.0327\nEpoch [52/80], Step [400/500] Loss: 0.0475\nEpoch [52/80], Step [500/500] Loss: 0.0677\nEpoch [53/80], Step [100/500] Loss: 0.0548\nEpoch [53/80], Step [200/500] Loss: 0.0173\nEpoch [53/80], Step [300/500] Loss: 0.0236\nEpoch [53/80], Step [400/500] Loss: 0.0407\nEpoch [53/80], Step [500/500] Loss: 0.1094\nEpoch [54/80], Step [100/500] Loss: 0.0669\nEpoch [54/80], Step [200/500] Loss: 0.0298\nEpoch [54/80], Step [300/500] Loss: 0.0201\nEpoch [54/80], Step [400/500] Loss: 0.0177\nEpoch [54/80], Step [500/500] Loss: 0.1085\nEpoch [55/80], Step [100/500] Loss: 0.0564\nEpoch [55/80], Step [200/500] Loss: 0.0451\nEpoch [55/80], Step [300/500] Loss: 0.0473\nEpoch [55/80], Step [400/500] Loss: 0.0239\nEpoch [55/80], Step [500/500] Loss: 0.0235\nEpoch [56/80], Step [100/500] Loss: 0.0577\nEpoch [56/80], Step [200/500] Loss: 0.0189\nEpoch [56/80], Step [300/500] Loss: 0.0227\nEpoch [56/80], Step [400/500] Loss: 0.0572\nEpoch [56/80], Step [500/500] Loss: 0.0357\nEpoch [57/80], Step [100/500] Loss: 0.0838\nEpoch [57/80], Step [200/500] Loss: 0.0406\nEpoch [57/80], Step [300/500] Loss: 0.0398\nEpoch [57/80], Step [400/500] Loss: 0.0731\nEpoch [57/80], Step [500/500] Loss: 0.0665\nEpoch [58/80], Step [100/500] Loss: 0.0670\nEpoch [58/80], Step [200/500] Loss: 0.0572\nEpoch [58/80], Step [300/500] Loss: 0.0367\nEpoch [58/80], Step [400/500] Loss: 0.0531\nEpoch [58/80], Step [500/500] Loss: 0.0297\nEpoch [59/80], Step [100/500] Loss: 0.0279\nEpoch [59/80], Step [200/500] Loss: 0.0717\nEpoch [59/80], Step [300/500] Loss: 0.0666\nEpoch [59/80], Step [400/500] Loss: 0.0381\nEpoch [59/80], Step [500/500] Loss: 0.0216\nEpoch [60/80], Step [100/500] Loss: 0.0549\nEpoch [60/80], Step [200/500] Loss: 0.0476\nEpoch [60/80], Step [300/500] Loss: 0.0656\nEpoch [60/80], Step [400/500] Loss: 0.0419\nEpoch [60/80], Step [500/500] Loss: 0.0245\nEpoch [61/80], Step [100/500] Loss: 0.0579\nEpoch [61/80], Step [200/500] Loss: 0.0115\nEpoch [61/80], Step [300/500] Loss: 0.0777\nEpoch [61/80], Step [400/500] Loss: 0.0232\nEpoch [61/80], Step [500/500] Loss: 0.0525\nEpoch [62/80], Step [100/500] Loss: 0.0821\nEpoch [62/80], Step [200/500] Loss: 0.1617\nEpoch [62/80], Step [300/500] Loss: 0.0466\nEpoch [62/80], Step [400/500] Loss: 0.0998\nEpoch [62/80], Step [500/500] Loss: 0.0432\nEpoch [63/80], Step [100/500] Loss: 0.0420\nEpoch [63/80], Step [200/500] Loss: 0.0662\nEpoch [63/80], Step [300/500] Loss: 0.0462\nEpoch [63/80], Step [400/500] Loss: 0.1460\nEpoch [63/80], Step [500/500] Loss: 0.0462\nEpoch [64/80], Step [100/500] Loss: 0.0552\nEpoch [64/80], Step [200/500] Loss: 0.0318\nEpoch [64/80], Step [300/500] Loss: 0.0370\nEpoch [64/80], Step [400/500] Loss: 0.0506\nEpoch [64/80], Step [500/500] Loss: 0.0598\nEpoch [65/80], Step [100/500] Loss: 0.0572\nEpoch [65/80], Step [200/500] Loss: 0.0390\nEpoch [65/80], Step [300/500] Loss: 0.0407\nEpoch [65/80], Step [400/500] Loss: 0.0220\nEpoch [65/80], Step [500/500] Loss: 0.0121\nEpoch [66/80], Step [100/500] Loss: 0.0123\nEpoch [66/80], Step [200/500] Loss: 0.0350\nEpoch [66/80], Step [300/500] Loss: 0.0410\nEpoch [66/80], Step [400/500] Loss: 0.0636\nEpoch [66/80], Step [500/500] Loss: 0.0765\nEpoch [67/80], Step [100/500] Loss: 0.0202\nEpoch [67/80], Step [200/500] Loss: 0.0360\nEpoch [67/80], Step [300/500] Loss: 0.0286\nEpoch [67/80], Step [400/500] Loss: 0.0430\nEpoch [67/80], Step [500/500] Loss: 0.0199\nEpoch [68/80], Step [100/500] Loss: 0.0240\nEpoch [68/80], Step [200/500] Loss: 0.0262\nEpoch [68/80], Step [300/500] Loss: 0.0281\nEpoch [68/80], Step [400/500] Loss: 0.0540\nEpoch [68/80], Step [500/500] Loss: 0.0549\nEpoch [69/80], Step [100/500] Loss: 0.0697\nEpoch [69/80], Step [200/500] Loss: 0.0666\nEpoch [69/80], Step [300/500] Loss: 0.0420\nEpoch [69/80], Step [400/500] Loss: 0.0353\nEpoch [69/80], Step [500/500] Loss: 0.0210\nEpoch [70/80], Step [100/500] Loss: 0.0212\nEpoch [70/80], Step [200/500] Loss: 0.0500\nEpoch [70/80], Step [300/500] Loss: 0.0723\nEpoch [70/80], Step [400/500] Loss: 0.0588\nEpoch [70/80], Step [500/500] Loss: 0.0917\nEpoch [71/80], Step [100/500] Loss: 0.0304\nEpoch [71/80], Step [200/500] Loss: 0.0775\nEpoch [71/80], Step [300/500] Loss: 0.0271\nEpoch [71/80], Step [400/500] Loss: 0.0531\nEpoch [71/80], Step [500/500] Loss: 0.0113\nEpoch [72/80], Step [100/500] Loss: 0.0190\nEpoch [72/80], Step [200/500] Loss: 0.0088\nEpoch [72/80], Step [300/500] Loss: 0.1110\nEpoch [72/80], Step [400/500] Loss: 0.0541\nEpoch [72/80], Step [500/500] Loss: 0.0120\nEpoch [73/80], Step [100/500] Loss: 0.0194\nEpoch [73/80], Step [200/500] Loss: 0.0886\nEpoch [73/80], Step [300/500] Loss: 0.0272\nEpoch [73/80], Step [400/500] Loss: 0.0902\nEpoch [73/80], Step [500/500] Loss: 0.0461\nEpoch [74/80], Step [100/500] Loss: 0.0344\nEpoch [74/80], Step [200/500] Loss: 0.0192\nEpoch [74/80], Step [300/500] Loss: 0.0350\nEpoch [74/80], Step [400/500] Loss: 0.0398\nEpoch [74/80], Step [500/500] Loss: 0.0507\nEpoch [75/80], Step [100/500] Loss: 0.0441\nEpoch [75/80], Step [200/500] Loss: 0.0725\nEpoch [75/80], Step [300/500] Loss: 0.0256\nEpoch [75/80], Step [400/500] Loss: 0.0704\nEpoch [75/80], Step [500/500] Loss: 0.0331\nEpoch [76/80], Step [100/500] Loss: 0.0251\nEpoch [76/80], Step [200/500] Loss: 0.0575\nEpoch [76/80], Step [300/500] Loss: 0.0641\nEpoch [76/80], Step [400/500] Loss: 0.0374\nEpoch [76/80], Step [500/500] Loss: 0.0575\nEpoch [77/80], Step [100/500] Loss: 0.0239\nEpoch [77/80], Step [200/500] Loss: 0.0624\nEpoch [77/80], Step [300/500] Loss: 0.0716\nEpoch [77/80], Step [400/500] Loss: 0.0303\nEpoch [77/80], Step [500/500] Loss: 0.0756\nEpoch [78/80], Step [100/500] Loss: 0.0765\nEpoch [78/80], Step [200/500] Loss: 0.0637\nEpoch [78/80], Step [300/500] Loss: 0.0381\nEpoch [78/80], Step [400/500] Loss: 0.0250\nEpoch [78/80], Step [500/500] Loss: 0.0511\nEpoch [79/80], Step [100/500] Loss: 0.0274\nEpoch [79/80], Step [200/500] Loss: 0.0730\nEpoch [79/80], Step [300/500] Loss: 0.0458\nEpoch [79/80], Step [400/500] Loss: 0.0739\nEpoch [79/80], Step [500/500] Loss: 0.0686\nEpoch [80/80], Step [100/500] Loss: 0.0431\nEpoch [80/80], Step [200/500] Loss: 0.0500\nEpoch [80/80], Step [300/500] Loss: 0.0134\nEpoch [80/80], Step [400/500] Loss: 0.0172\nEpoch [80/80], Step [500/500] Loss: 0.0304\n","output_type":"stream"}]},{"cell_type":"code","source":"# Test the model\nmodel.eval()\nwith torch.no_grad():\n    correct = 0\n    total = 0\n    for images, labels in test_loader:\n        images = images.to(device)\n        labels = labels.to(device)\n        outputs = model(images)\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\n    print('Accuracy of the model on the test images: {} %'.format(100 * correct / total))","metadata":{"execution":{"iopub.status.busy":"2021-09-08T12:00:14.080785Z","iopub.execute_input":"2021-09-08T12:00:14.081125Z","iopub.status.idle":"2021-09-08T12:00:15.358426Z","shell.execute_reply.started":"2021-09-08T12:00:14.081096Z","shell.execute_reply":"2021-09-08T12:00:15.357534Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Accuracy of the model on the test images: 89.05 %\n","output_type":"stream"}]},{"cell_type":"code","source":"# Save the model checkpoint\ntorch.save(model.state_dict(), 'resnet.ckpt')","metadata":{"execution":{"iopub.status.busy":"2021-09-08T12:00:42.174795Z","iopub.execute_input":"2021-09-08T12:00:42.175159Z","iopub.status.idle":"2021-09-08T12:00:42.192459Z","shell.execute_reply.started":"2021-09-08T12:00:42.175128Z","shell.execute_reply":"2021-09-08T12:00:42.191443Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}