{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# https://github.com/yunjey/pytorch-tutorial/blob/master/tutorials/01-basics/feedforward_neural_network/main.py#L37-L49","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-09-08T05:18:14.478048Z","iopub.execute_input":"2021-09-08T05:18:14.478573Z","iopub.status.idle":"2021-09-08T05:18:14.482772Z","shell.execute_reply.started":"2021-09-08T05:18:14.478476Z","shell.execute_reply":"2021-09-08T05:18:14.482148Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!pip uninstall torch -y\n!pip uninstall torchvision -y\n!pip install torch \n!pip install torchvision\nimport torch \nimport torchvision\nimport torch.nn as nn\nimport numpy as np\nimport torchvision.transforms as transforms","metadata":{"execution":{"iopub.status.busy":"2021-09-08T05:18:16.711772Z","iopub.execute_input":"2021-09-08T05:18:16.712270Z","iopub.status.idle":"2021-09-08T05:19:57.656731Z","shell.execute_reply.started":"2021-09-08T05:18:16.712237Z","shell.execute_reply":"2021-09-08T05:19:57.655737Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Found existing installation: torch 1.7.0\nUninstalling torch-1.7.0:\n  Successfully uninstalled torch-1.7.0\n\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\nFound existing installation: torchvision 0.8.1\nUninstalling torchvision-0.8.1:\n  Successfully uninstalled torchvision-0.8.1\n\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\nCollecting torch\n  Downloading torch-1.9.0-cp37-cp37m-manylinux1_x86_64.whl (831.4 MB)\n\u001b[K     |████████████████████████████████| 831.4 MB 2.0 kB/s eta 0:00:015   |█▉                              | 46.4 MB 3.5 MB/s eta 0:03:45     |█▉                              | 49.0 MB 3.5 MB/s eta 0:03:44     |████                            | 103.6 MB 3.1 MB/s eta 0:03:52     |██████▌                         | 169.8 MB 2.8 MB/s eta 0:03:56     |███████                         | 183.2 MB 2.8 MB/s eta 0:03:51     |█████████▋                      | 249.5 MB 3.6 MB/s eta 0:02:43     |██████████████▋                 | 379.2 MB 2.6 MB/s eta 0:02:51     |█████████████████▍              | 452.6 MB 3.1 MB/s eta 0:02:04     |██████████████████              | 465.7 MB 3.4 MB/s eta 0:01:49     |████████████████████▎           | 527.1 MB 51.5 MB/s eta 0:00:06     |██████████████████████▋         | 586.7 MB 46.8 MB/s eta 0:00:06\n\u001b[?25hRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch) (3.7.4.3)\nInstalling collected packages: torch\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nfastai 2.2.7 requires torchvision<0.9,>=0.8, which is not installed.\neasyocr 1.3.2 requires torchvision>=0.5, which is not installed.\nallennlp 2.5.0 requires torchvision<0.10.0,>=0.8.1, which is not installed.\nkornia 0.5.5 requires numpy<=1.19, but you have numpy 1.19.5 which is incompatible.\nfastai 2.2.7 requires torch<1.8,>=1.7.0, but you have torch 1.9.0 which is incompatible.\nallennlp 2.5.0 requires torch<1.9.0,>=1.6.0, but you have torch 1.9.0 which is incompatible.\u001b[0m\nSuccessfully installed torch-1.9.0\n\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\nCollecting torchvision\n  Downloading torchvision-0.10.0-cp37-cp37m-manylinux1_x86_64.whl (22.1 MB)\n\u001b[K     |████████████████████████████████| 22.1 MB 291 kB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torchvision) (1.19.5)\nRequirement already satisfied: pillow>=5.3.0 in /opt/conda/lib/python3.7/site-packages (from torchvision) (8.2.0)\nRequirement already satisfied: torch==1.9.0 in /opt/conda/lib/python3.7/site-packages (from torchvision) (1.9.0)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch==1.9.0->torchvision) (3.7.4.3)\nInstalling collected packages: torchvision\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nfastai 2.2.7 requires torch<1.8,>=1.7.0, but you have torch 1.9.0 which is incompatible.\nfastai 2.2.7 requires torchvision<0.9,>=0.8, but you have torchvision 0.10.0 which is incompatible.\nallennlp 2.5.0 requires torch<1.9.0,>=1.6.0, but you have torch 1.9.0 which is incompatible.\nallennlp 2.5.0 requires torchvision<0.10.0,>=0.8.1, but you have torchvision 0.10.0 which is incompatible.\u001b[0m\nSuccessfully installed torchvision-0.10.0\n\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torchvision\nimport torchvision.transforms as transforms","metadata":{"execution":{"iopub.status.busy":"2021-09-08T05:20:03.475573Z","iopub.execute_input":"2021-09-08T05:20:03.476005Z","iopub.status.idle":"2021-09-08T05:20:03.481267Z","shell.execute_reply.started":"2021-09-08T05:20:03.475966Z","shell.execute_reply":"2021-09-08T05:20:03.480191Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Device configuration\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"execution":{"iopub.status.busy":"2021-09-08T05:20:07.786676Z","iopub.execute_input":"2021-09-08T05:20:07.787104Z","iopub.status.idle":"2021-09-08T05:20:07.791768Z","shell.execute_reply.started":"2021-09-08T05:20:07.787069Z","shell.execute_reply":"2021-09-08T05:20:07.791079Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Hyper-parameters \ninput_size = 784\nhidden_size = 500\nnum_classes = 10\nnum_epochs = 5\nbatch_size = 100\nlearning_rate = 0.001","metadata":{"execution":{"iopub.status.busy":"2021-09-08T05:20:11.136212Z","iopub.execute_input":"2021-09-08T05:20:11.136716Z","iopub.status.idle":"2021-09-08T05:20:11.145975Z","shell.execute_reply.started":"2021-09-08T05:20:11.136667Z","shell.execute_reply":"2021-09-08T05:20:11.144929Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# MNIST dataset \ntrain_dataset = torchvision.datasets.MNIST(root='../../data', \n                                           train=True, \n                                           transform=transforms.ToTensor(),  \n                                           download=True)\n\ntest_dataset = torchvision.datasets.MNIST(root='../../data', \n                                          train=False, \n                                          transform=transforms.ToTensor())","metadata":{"execution":{"iopub.status.busy":"2021-09-08T05:20:16.504447Z","iopub.execute_input":"2021-09-08T05:20:16.504826Z","iopub.status.idle":"2021-09-08T05:20:18.654490Z","shell.execute_reply.started":"2021-09-08T05:20:16.504791Z","shell.execute_reply":"2021-09-08T05:20:18.653310Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\nDownloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ../../data/MNIST/raw/train-images-idx3-ubyte.gz\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/9912422 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a54e338c09b848168b463723488472e4"}},"metadata":{}},{"name":"stdout","text":"Extracting ../../data/MNIST/raw/train-images-idx3-ubyte.gz to ../../data/MNIST/raw\n\nDownloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\nDownloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ../../data/MNIST/raw/train-labels-idx1-ubyte.gz\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/28881 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3c3ed18bea824e5d8ff20073c99a675a"}},"metadata":{}},{"name":"stdout","text":"Extracting ../../data/MNIST/raw/train-labels-idx1-ubyte.gz to ../../data/MNIST/raw\n\nDownloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\nDownloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ../../data/MNIST/raw/t10k-images-idx3-ubyte.gz\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1648877 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b245781e928b40a785577e23d6550603"}},"metadata":{}},{"name":"stdout","text":"Extracting ../../data/MNIST/raw/t10k-images-idx3-ubyte.gz to ../../data/MNIST/raw\n\nDownloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\nDownloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ../../data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4542 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e671d238dd9341c4a014d4e73d01a48a"}},"metadata":{}},{"name":"stdout","text":"Extracting ../../data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ../../data/MNIST/raw\n\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:180.)\n  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n","output_type":"stream"}]},{"cell_type":"code","source":"# Data loader\ntrain_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n                                           batch_size=batch_size, \n                                           shuffle=True)\n\ntest_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n                                          batch_size=batch_size, \n                                          shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2021-09-08T05:20:23.173580Z","iopub.execute_input":"2021-09-08T05:20:23.173968Z","iopub.status.idle":"2021-09-08T05:20:23.179424Z","shell.execute_reply.started":"2021-09-08T05:20:23.173934Z","shell.execute_reply":"2021-09-08T05:20:23.178343Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Fully connected neural network with one hidden layer\nclass NeuralNet(nn.Module):\n    def __init__(self, input_size, hidden_size, num_classes):\n        super(NeuralNet, self).__init__()\n        self.fc1 = nn.Linear(input_size, hidden_size) \n        self.relu = nn.ReLU()\n        self.fc2 = nn.Linear(hidden_size, num_classes)  \n    \n    def forward(self, x):\n        out = self.fc1(x)\n        out = self.relu(out)\n        out = self.fc2(out)\n        return out","metadata":{"execution":{"iopub.status.busy":"2021-09-08T05:20:30.183896Z","iopub.execute_input":"2021-09-08T05:20:30.184228Z","iopub.status.idle":"2021-09-08T05:20:30.190601Z","shell.execute_reply.started":"2021-09-08T05:20:30.184199Z","shell.execute_reply":"2021-09-08T05:20:30.189561Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"model = NeuralNet(input_size, hidden_size, num_classes).to(device)","metadata":{"execution":{"iopub.status.busy":"2021-09-08T05:21:03.708366Z","iopub.execute_input":"2021-09-08T05:21:03.708718Z","iopub.status.idle":"2021-09-08T05:21:03.716810Z","shell.execute_reply.started":"2021-09-08T05:21:03.708691Z","shell.execute_reply":"2021-09-08T05:21:03.715958Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Loss and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)","metadata":{"execution":{"iopub.status.busy":"2021-09-08T05:21:05.916663Z","iopub.execute_input":"2021-09-08T05:21:05.917049Z","iopub.status.idle":"2021-09-08T05:21:05.921472Z","shell.execute_reply.started":"2021-09-08T05:21:05.917020Z","shell.execute_reply":"2021-09-08T05:21:05.920737Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# Train the model\ntotal_step = len(train_loader)\nfor epoch in range(num_epochs):\n    for i, (images, labels) in enumerate(train_loader):  \n        # Move tensors to the configured device\n        images = images.reshape(-1, 28*28).to(device)\n        labels = labels.to(device)\n        \n        # Forward pass\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        \n        # Backward and optimize\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        if (i+1) % 100 == 0:\n            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))","metadata":{"execution":{"iopub.status.busy":"2021-09-08T05:21:11.424713Z","iopub.execute_input":"2021-09-08T05:21:11.425278Z","iopub.status.idle":"2021-09-08T05:21:50.031718Z","shell.execute_reply.started":"2021-09-08T05:21:11.425230Z","shell.execute_reply":"2021-09-08T05:21:50.030645Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Epoch [1/5], Step [100/600], Loss: 0.3614\nEpoch [1/5], Step [200/600], Loss: 0.3131\nEpoch [1/5], Step [300/600], Loss: 0.1109\nEpoch [1/5], Step [400/600], Loss: 0.0885\nEpoch [1/5], Step [500/600], Loss: 0.1072\nEpoch [1/5], Step [600/600], Loss: 0.0935\nEpoch [2/5], Step [100/600], Loss: 0.0895\nEpoch [2/5], Step [200/600], Loss: 0.0845\nEpoch [2/5], Step [300/600], Loss: 0.1300\nEpoch [2/5], Step [400/600], Loss: 0.1400\nEpoch [2/5], Step [500/600], Loss: 0.0551\nEpoch [2/5], Step [600/600], Loss: 0.0883\nEpoch [3/5], Step [100/600], Loss: 0.0557\nEpoch [3/5], Step [200/600], Loss: 0.0948\nEpoch [3/5], Step [300/600], Loss: 0.0530\nEpoch [3/5], Step [400/600], Loss: 0.0185\nEpoch [3/5], Step [500/600], Loss: 0.1858\nEpoch [3/5], Step [600/600], Loss: 0.0725\nEpoch [4/5], Step [100/600], Loss: 0.0565\nEpoch [4/5], Step [200/600], Loss: 0.0224\nEpoch [4/5], Step [300/600], Loss: 0.0740\nEpoch [4/5], Step [400/600], Loss: 0.1536\nEpoch [4/5], Step [500/600], Loss: 0.0100\nEpoch [4/5], Step [600/600], Loss: 0.0727\nEpoch [5/5], Step [100/600], Loss: 0.0359\nEpoch [5/5], Step [200/600], Loss: 0.0526\nEpoch [5/5], Step [300/600], Loss: 0.0630\nEpoch [5/5], Step [400/600], Loss: 0.0568\nEpoch [5/5], Step [500/600], Loss: 0.0506\nEpoch [5/5], Step [600/600], Loss: 0.0379\n","output_type":"stream"}]},{"cell_type":"code","source":"# Test the model\n# In test phase, we don't need to compute gradients (for memory efficiency)\nwith torch.no_grad():\n    correct = 0\n    total = 0\n    for images, labels in test_loader:\n        images = images.reshape(-1, 28*28).to(device)\n        labels = labels.to(device)\n        outputs = model(images)\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\n    print('Accuracy of the network on the 10000 test images: {} %'.format(100 * correct / total))","metadata":{"execution":{"iopub.status.busy":"2021-09-08T05:21:59.448627Z","iopub.execute_input":"2021-09-08T05:21:59.449045Z","iopub.status.idle":"2021-09-08T05:22:00.423681Z","shell.execute_reply.started":"2021-09-08T05:21:59.449004Z","shell.execute_reply":"2021-09-08T05:22:00.422681Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Accuracy of the network on the 10000 test images: 97.78 %\n","output_type":"stream"}]},{"cell_type":"code","source":"# Save the model checkpoint\ntorch.save(model.state_dict(), 'model.ckpt')","metadata":{"execution":{"iopub.status.busy":"2021-09-08T05:22:02.956770Z","iopub.execute_input":"2021-09-08T05:22:02.957183Z","iopub.status.idle":"2021-09-08T05:22:02.964282Z","shell.execute_reply.started":"2021-09-08T05:22:02.957142Z","shell.execute_reply":"2021-09-08T05:22:02.963425Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}