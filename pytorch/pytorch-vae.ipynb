{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# https://github.com/yunjey/pytorch-tutorial/blob/master/tutorials/03-advanced/variational_autoencoder/main.py#L38-L65\n# https://towardsdatascience.com/understanding-variational-autoencoders-vaes-f70510919f73","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-09-09T18:31:45.895290Z","iopub.execute_input":"2021-09-09T18:31:45.895588Z","iopub.status.idle":"2021-09-09T18:31:45.899423Z","shell.execute_reply.started":"2021-09-09T18:31:45.895526Z","shell.execute_reply":"2021-09-09T18:31:45.898569Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!pip uninstall torch -y\n!pip uninstall torchvision -y\n!pip install torch \n!pip install torchvision\nimport torch \nimport torchvision\nimport torch.nn as nn\nimport numpy as np\nimport torchvision.transforms as transforms","metadata":{"execution":{"iopub.status.busy":"2021-09-09T18:33:28.885716Z","iopub.execute_input":"2021-09-09T18:33:28.886053Z","iopub.status.idle":"2021-09-09T18:34:53.747987Z","shell.execute_reply.started":"2021-09-09T18:33:28.886023Z","shell.execute_reply":"2021-09-09T18:34:53.747134Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Found existing installation: torch 1.7.0\nUninstalling torch-1.7.0:\n  Successfully uninstalled torch-1.7.0\n\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\nFound existing installation: torchvision 0.8.1\nUninstalling torchvision-0.8.1:\n  Successfully uninstalled torchvision-0.8.1\n\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\nCollecting torch\n  Downloading torch-1.9.0-cp37-cp37m-manylinux1_x86_64.whl (831.4 MB)\n\u001b[K     |████████████████████████████████| 831.4 MB 1.7 kB/s  eta 0:00:01�█████████▌                 | 377.3 MB 70.2 MB/s eta 0:00:07     |██████████████████████████      | 676.9 MB 61.0 MB/s eta 0:00:03     |██████████████████████████▏     | 680.8 MB 61.0 MB/s eta 0:00:03��██▍     | 686.0 MB 61.0 MB/s eta 0:00:03\n\u001b[?25hRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch) (3.7.4.3)\nInstalling collected packages: torch\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nfastai 2.2.7 requires torchvision<0.9,>=0.8, which is not installed.\neasyocr 1.3.2 requires torchvision>=0.5, which is not installed.\nallennlp 2.5.0 requires torchvision<0.10.0,>=0.8.1, which is not installed.\nkornia 0.5.5 requires numpy<=1.19, but you have numpy 1.19.5 which is incompatible.\nfastai 2.2.7 requires torch<1.8,>=1.7.0, but you have torch 1.9.0 which is incompatible.\nallennlp 2.5.0 requires torch<1.9.0,>=1.6.0, but you have torch 1.9.0 which is incompatible.\u001b[0m\nSuccessfully installed torch-1.9.0\n\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\nCollecting torchvision\n  Downloading torchvision-0.10.0-cp37-cp37m-manylinux1_x86_64.whl (22.1 MB)\n\u001b[K     |████████████████████████████████| 22.1 MB 5.0 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: pillow>=5.3.0 in /opt/conda/lib/python3.7/site-packages (from torchvision) (8.2.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torchvision) (1.19.5)\nRequirement already satisfied: torch==1.9.0 in /opt/conda/lib/python3.7/site-packages (from torchvision) (1.9.0)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch==1.9.0->torchvision) (3.7.4.3)\nInstalling collected packages: torchvision\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nfastai 2.2.7 requires torch<1.8,>=1.7.0, but you have torch 1.9.0 which is incompatible.\nfastai 2.2.7 requires torchvision<0.9,>=0.8, but you have torchvision 0.10.0 which is incompatible.\nallennlp 2.5.0 requires torch<1.9.0,>=1.6.0, but you have torch 1.9.0 which is incompatible.\nallennlp 2.5.0 requires torchvision<0.10.0,>=0.8.1, but you have torchvision 0.10.0 which is incompatible.\u001b[0m\nSuccessfully installed torchvision-0.10.0\n\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision\nfrom torchvision import transforms\nfrom torchvision.utils import save_image","metadata":{"execution":{"iopub.status.busy":"2021-09-09T18:40:50.323269Z","iopub.execute_input":"2021-09-09T18:40:50.323652Z","iopub.status.idle":"2021-09-09T18:40:50.328381Z","shell.execute_reply.started":"2021-09-09T18:40:50.323618Z","shell.execute_reply":"2021-09-09T18:40:50.327411Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Device configuration\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"execution":{"iopub.status.busy":"2021-09-09T18:40:59.792138Z","iopub.execute_input":"2021-09-09T18:40:59.792485Z","iopub.status.idle":"2021-09-09T18:40:59.838421Z","shell.execute_reply.started":"2021-09-09T18:40:59.792455Z","shell.execute_reply":"2021-09-09T18:40:59.837085Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Create a directory if not exists\nsample_dir = 'samples'\nif not os.path.exists(sample_dir):\n    os.makedirs(sample_dir)","metadata":{"execution":{"iopub.status.busy":"2021-09-09T18:41:10.409926Z","iopub.execute_input":"2021-09-09T18:41:10.410252Z","iopub.status.idle":"2021-09-09T18:41:10.414111Z","shell.execute_reply.started":"2021-09-09T18:41:10.410223Z","shell.execute_reply":"2021-09-09T18:41:10.413302Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Hyper-parameters\nimage_size = 784\nh_dim = 400\nz_dim = 20\nnum_epochs = 15\nbatch_size = 128\nlearning_rate = 1e-3","metadata":{"execution":{"iopub.status.busy":"2021-09-09T18:41:19.799077Z","iopub.execute_input":"2021-09-09T18:41:19.799417Z","iopub.status.idle":"2021-09-09T18:41:19.803877Z","shell.execute_reply.started":"2021-09-09T18:41:19.799366Z","shell.execute_reply":"2021-09-09T18:41:19.802790Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# MNIST dataset\ndataset = torchvision.datasets.MNIST(root='../../data',\n                                     train=True,\n                                     transform=transforms.ToTensor(),\n                                     download=True)\n\n# Data loader\ndata_loader = torch.utils.data.DataLoader(dataset=dataset,\n                                          batch_size=batch_size, \n                                          shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2021-09-09T18:41:28.584747Z","iopub.execute_input":"2021-09-09T18:41:28.585147Z","iopub.status.idle":"2021-09-09T18:41:29.709957Z","shell.execute_reply.started":"2021-09-09T18:41:28.585115Z","shell.execute_reply":"2021-09-09T18:41:29.708907Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\nDownloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ../../data/MNIST/raw/train-images-idx3-ubyte.gz\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/9912422 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5a3b1e31e23c42d78a7fe2d862cbda47"}},"metadata":{}},{"name":"stdout","text":"Extracting ../../data/MNIST/raw/train-images-idx3-ubyte.gz to ../../data/MNIST/raw\n\nDownloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\nDownloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ../../data/MNIST/raw/train-labels-idx1-ubyte.gz\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/28881 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"20cdd8fd595e4fee8a4e69b00cf2750c"}},"metadata":{}},{"name":"stdout","text":"Extracting ../../data/MNIST/raw/train-labels-idx1-ubyte.gz to ../../data/MNIST/raw\n\nDownloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\nDownloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ../../data/MNIST/raw/t10k-images-idx3-ubyte.gz\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1648877 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0f203fbe86554b84981a59435b470090"}},"metadata":{}},{"name":"stdout","text":"Extracting ../../data/MNIST/raw/t10k-images-idx3-ubyte.gz to ../../data/MNIST/raw\n\nDownloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\nDownloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ../../data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4542 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8f0a72fe77a64dfeac782ae3992f7ac4"}},"metadata":{}},{"name":"stdout","text":"Extracting ../../data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ../../data/MNIST/raw\n\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:180.)\n  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n","output_type":"stream"}]},{"cell_type":"code","source":"# VAE model\nclass VAE(nn.Module):\n    def __init__(self, image_size=784, h_dim=400, z_dim=20):\n        super(VAE, self).__init__()\n        self.fc1 = nn.Linear(image_size, h_dim)\n        self.fc2 = nn.Linear(h_dim, z_dim)\n        self.fc3 = nn.Linear(h_dim, z_dim)\n        self.fc4 = nn.Linear(z_dim, h_dim)\n        self.fc5 = nn.Linear(h_dim, image_size)\n        \n    def encode(self, x):\n        h = F.relu(self.fc1(x))\n        return self.fc2(h), self.fc3(h)\n    \n    def reparameterize(self, mu, log_var):\n        std = torch.exp(log_var/2)\n        eps = torch.randn_like(std)\n        return mu + eps * std\n\n    def decode(self, z):\n        h = F.relu(self.fc4(z))\n        return F.sigmoid(self.fc5(h))\n    \n    def forward(self, x):\n        mu, log_var = self.encode(x)\n        z = self.reparameterize(mu, log_var)\n        x_reconst = self.decode(z)\n        return x_reconst, mu, log_var","metadata":{"execution":{"iopub.status.busy":"2021-09-09T18:45:48.357872Z","iopub.execute_input":"2021-09-09T18:45:48.358319Z","iopub.status.idle":"2021-09-09T18:45:48.374726Z","shell.execute_reply.started":"2021-09-09T18:45:48.358282Z","shell.execute_reply":"2021-09-09T18:45:48.373937Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"model = VAE().to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)","metadata":{"execution":{"iopub.status.busy":"2021-09-09T18:45:57.492198Z","iopub.execute_input":"2021-09-09T18:45:57.492553Z","iopub.status.idle":"2021-09-09T18:46:00.177479Z","shell.execute_reply.started":"2021-09-09T18:45:57.492520Z","shell.execute_reply":"2021-09-09T18:46:00.176599Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Start training\nfor epoch in range(num_epochs):\n    for i, (x, _) in enumerate(data_loader):\n        # Forward pass\n        x = x.to(device).view(-1, image_size)\n        x_reconst, mu, log_var = model(x)\n        \n        # Compute reconstruction loss and kl divergence\n        # For KL divergence, see Appendix B in VAE paper or http://yunjey47.tistory.com/43\n        reconst_loss = F.binary_cross_entropy(x_reconst, x, size_average=False)\n        kl_div = - 0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n        \n        # Backprop and optimize\n        loss = reconst_loss + kl_div\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        if (i+1) % 10 == 0:\n            print (\"Epoch[{}/{}], Step [{}/{}], Reconst Loss: {:.4f}, KL Div: {:.4f}\" \n                   .format(epoch+1, num_epochs, i+1, len(data_loader), reconst_loss.item(), kl_div.item()))\n    \n    with torch.no_grad():\n        # Save the sampled images\n        z = torch.randn(batch_size, z_dim).to(device)\n        out = model.decode(z).view(-1, 1, 28, 28)\n        save_image(out, os.path.join(sample_dir, 'sampled-{}.png'.format(epoch+1)))\n\n        # Save the reconstructed images\n        out, _, _ = model(x)\n        x_concat = torch.cat([x.view(-1, 1, 28, 28), out.view(-1, 1, 28, 28)], dim=3)\n        save_image(x_concat, os.path.join(sample_dir, 'reconst-{}.png'.format(epoch+1)))","metadata":{"execution":{"iopub.status.busy":"2021-09-09T18:53:04.268762Z","iopub.execute_input":"2021-09-09T18:53:04.269095Z","iopub.status.idle":"2021-09-09T18:54:29.068953Z","shell.execute_reply.started":"2021-09-09T18:53:04.269068Z","shell.execute_reply":"2021-09-09T18:54:29.067926Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1805: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n/opt/conda/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n  warnings.warn(warning.format(ret))\n","output_type":"stream"},{"name":"stdout","text":"Epoch[1/15], Step [10/469], Reconst Loss: 35898.3477, KL Div: 4304.4009\nEpoch[1/15], Step [20/469], Reconst Loss: 29589.9531, KL Div: 1100.1121\nEpoch[1/15], Step [30/469], Reconst Loss: 25640.0996, KL Div: 1210.4563\nEpoch[1/15], Step [40/469], Reconst Loss: 28553.8711, KL Div: 652.1793\nEpoch[1/15], Step [50/469], Reconst Loss: 26070.4004, KL Div: 889.7828\nEpoch[1/15], Step [60/469], Reconst Loss: 26578.1094, KL Div: 834.9977\nEpoch[1/15], Step [70/469], Reconst Loss: 25280.0820, KL Div: 1051.3149\nEpoch[1/15], Step [80/469], Reconst Loss: 23267.6367, KL Div: 1220.6044\nEpoch[1/15], Step [90/469], Reconst Loss: 22913.7305, KL Div: 1309.2629\nEpoch[1/15], Step [100/469], Reconst Loss: 21890.8594, KL Div: 1396.3766\nEpoch[1/15], Step [110/469], Reconst Loss: 21182.1992, KL Div: 1716.4216\nEpoch[1/15], Step [120/469], Reconst Loss: 19754.9004, KL Div: 1742.4539\nEpoch[1/15], Step [130/469], Reconst Loss: 20081.3438, KL Div: 1813.8926\nEpoch[1/15], Step [140/469], Reconst Loss: 19328.5547, KL Div: 1783.1077\nEpoch[1/15], Step [150/469], Reconst Loss: 18525.2246, KL Div: 1807.5592\nEpoch[1/15], Step [160/469], Reconst Loss: 18326.5234, KL Div: 1979.9819\nEpoch[1/15], Step [170/469], Reconst Loss: 18554.4062, KL Div: 1759.7271\nEpoch[1/15], Step [180/469], Reconst Loss: 17782.5879, KL Div: 1871.7454\nEpoch[1/15], Step [190/469], Reconst Loss: 18561.1621, KL Div: 1884.0731\nEpoch[1/15], Step [200/469], Reconst Loss: 17414.9707, KL Div: 2084.6235\nEpoch[1/15], Step [210/469], Reconst Loss: 18165.7539, KL Div: 2197.7083\nEpoch[1/15], Step [220/469], Reconst Loss: 17288.1211, KL Div: 2102.3655\nEpoch[1/15], Step [230/469], Reconst Loss: 16989.7910, KL Div: 2246.5188\nEpoch[1/15], Step [240/469], Reconst Loss: 17175.3672, KL Div: 2092.0339\nEpoch[1/15], Step [250/469], Reconst Loss: 15932.0234, KL Div: 2300.3230\nEpoch[1/15], Step [260/469], Reconst Loss: 16553.4277, KL Div: 2130.2473\nEpoch[1/15], Step [270/469], Reconst Loss: 15705.0137, KL Div: 2254.9736\nEpoch[1/15], Step [280/469], Reconst Loss: 16492.7500, KL Div: 2293.8184\nEpoch[1/15], Step [290/469], Reconst Loss: 15193.9189, KL Div: 2254.5020\nEpoch[1/15], Step [300/469], Reconst Loss: 15573.5684, KL Div: 2385.2373\nEpoch[1/15], Step [310/469], Reconst Loss: 14877.8486, KL Div: 2288.6411\nEpoch[1/15], Step [320/469], Reconst Loss: 15094.0986, KL Div: 2463.2437\nEpoch[1/15], Step [330/469], Reconst Loss: 15267.4668, KL Div: 2323.0830\nEpoch[1/15], Step [340/469], Reconst Loss: 15325.3916, KL Div: 2370.6050\nEpoch[1/15], Step [350/469], Reconst Loss: 14632.7480, KL Div: 2496.7998\nEpoch[1/15], Step [360/469], Reconst Loss: 14495.5566, KL Div: 2461.4277\nEpoch[1/15], Step [370/469], Reconst Loss: 14882.0654, KL Div: 2441.1667\nEpoch[1/15], Step [380/469], Reconst Loss: 15822.3613, KL Div: 2433.6338\nEpoch[1/15], Step [390/469], Reconst Loss: 14542.1084, KL Div: 2596.4277\nEpoch[1/15], Step [400/469], Reconst Loss: 14662.2422, KL Div: 2398.0703\nEpoch[1/15], Step [410/469], Reconst Loss: 14357.0801, KL Div: 2472.6987\nEpoch[1/15], Step [420/469], Reconst Loss: 13419.0059, KL Div: 2650.5862\nEpoch[1/15], Step [430/469], Reconst Loss: 14410.8477, KL Div: 2482.5532\nEpoch[1/15], Step [440/469], Reconst Loss: 14949.2227, KL Div: 2706.5178\nEpoch[1/15], Step [450/469], Reconst Loss: 14042.5830, KL Div: 2611.8469\nEpoch[1/15], Step [460/469], Reconst Loss: 14311.9434, KL Div: 2555.6890\nEpoch[2/15], Step [10/469], Reconst Loss: 13024.3027, KL Div: 2715.3098\nEpoch[2/15], Step [20/469], Reconst Loss: 12845.6943, KL Div: 2601.1660\nEpoch[2/15], Step [30/469], Reconst Loss: 13118.6699, KL Div: 2649.1167\nEpoch[2/15], Step [40/469], Reconst Loss: 13647.5820, KL Div: 2736.5488\nEpoch[2/15], Step [50/469], Reconst Loss: 13351.1562, KL Div: 2828.4565\nEpoch[2/15], Step [60/469], Reconst Loss: 13430.4082, KL Div: 2630.3381\nEpoch[2/15], Step [70/469], Reconst Loss: 13399.6279, KL Div: 2910.5730\nEpoch[2/15], Step [80/469], Reconst Loss: 12707.5684, KL Div: 2665.3562\nEpoch[2/15], Step [90/469], Reconst Loss: 13669.4121, KL Div: 2794.6799\nEpoch[2/15], Step [100/469], Reconst Loss: 13580.5879, KL Div: 2782.1709\nEpoch[2/15], Step [110/469], Reconst Loss: 13416.2988, KL Div: 2884.9944\nEpoch[2/15], Step [120/469], Reconst Loss: 13599.4307, KL Div: 2759.3127\nEpoch[2/15], Step [130/469], Reconst Loss: 12933.3857, KL Div: 2806.6792\nEpoch[2/15], Step [140/469], Reconst Loss: 13254.7910, KL Div: 2792.5854\nEpoch[2/15], Step [150/469], Reconst Loss: 12511.8965, KL Div: 2731.5471\nEpoch[2/15], Step [160/469], Reconst Loss: 12897.2422, KL Div: 2848.0188\nEpoch[2/15], Step [170/469], Reconst Loss: 13030.3535, KL Div: 2862.0447\nEpoch[2/15], Step [180/469], Reconst Loss: 12525.8535, KL Div: 2849.5269\nEpoch[2/15], Step [190/469], Reconst Loss: 12406.9541, KL Div: 2817.7632\nEpoch[2/15], Step [200/469], Reconst Loss: 12440.7422, KL Div: 2963.0359\nEpoch[2/15], Step [210/469], Reconst Loss: 12852.1562, KL Div: 2911.2161\nEpoch[2/15], Step [220/469], Reconst Loss: 12408.8027, KL Div: 2812.4912\nEpoch[2/15], Step [230/469], Reconst Loss: 12501.0977, KL Div: 2860.0291\nEpoch[2/15], Step [240/469], Reconst Loss: 12487.9961, KL Div: 2925.1782\nEpoch[2/15], Step [250/469], Reconst Loss: 12468.1201, KL Div: 2889.7041\nEpoch[2/15], Step [260/469], Reconst Loss: 12474.2773, KL Div: 3005.0979\nEpoch[2/15], Step [270/469], Reconst Loss: 12155.2158, KL Div: 2932.0928\nEpoch[2/15], Step [280/469], Reconst Loss: 12349.7578, KL Div: 3004.4404\nEpoch[2/15], Step [290/469], Reconst Loss: 12227.0430, KL Div: 2860.8899\nEpoch[2/15], Step [300/469], Reconst Loss: 12366.0352, KL Div: 3045.4441\nEpoch[2/15], Step [310/469], Reconst Loss: 12824.3555, KL Div: 2978.3499\nEpoch[2/15], Step [320/469], Reconst Loss: 12212.2285, KL Div: 2910.6729\nEpoch[2/15], Step [330/469], Reconst Loss: 11494.8242, KL Div: 2914.4258\nEpoch[2/15], Step [340/469], Reconst Loss: 12430.1230, KL Div: 3002.2493\nEpoch[2/15], Step [350/469], Reconst Loss: 12184.8711, KL Div: 2973.7449\nEpoch[2/15], Step [360/469], Reconst Loss: 12181.6426, KL Div: 3003.9272\nEpoch[2/15], Step [370/469], Reconst Loss: 11821.1953, KL Div: 2970.1709\nEpoch[2/15], Step [380/469], Reconst Loss: 11920.4648, KL Div: 2894.4749\nEpoch[2/15], Step [390/469], Reconst Loss: 11897.1904, KL Div: 3076.9824\nEpoch[2/15], Step [400/469], Reconst Loss: 12376.8320, KL Div: 3080.3599\nEpoch[2/15], Step [410/469], Reconst Loss: 12019.1426, KL Div: 2835.6003\nEpoch[2/15], Step [420/469], Reconst Loss: 11693.2793, KL Div: 2998.8579\nEpoch[2/15], Step [430/469], Reconst Loss: 11923.6504, KL Div: 2969.6367\nEpoch[2/15], Step [440/469], Reconst Loss: 11841.0244, KL Div: 2968.6509\nEpoch[2/15], Step [450/469], Reconst Loss: 12169.4219, KL Div: 3085.5386\nEpoch[2/15], Step [460/469], Reconst Loss: 12330.8896, KL Div: 3151.9209\nEpoch[3/15], Step [10/469], Reconst Loss: 11683.3652, KL Div: 3022.1948\nEpoch[3/15], Step [20/469], Reconst Loss: 12412.6924, KL Div: 2919.9478\nEpoch[3/15], Step [30/469], Reconst Loss: 11766.4766, KL Div: 3005.0059\nEpoch[3/15], Step [40/469], Reconst Loss: 12128.4697, KL Div: 3008.0957\nEpoch[3/15], Step [50/469], Reconst Loss: 10902.5332, KL Div: 2975.7017\nEpoch[3/15], Step [60/469], Reconst Loss: 11844.0762, KL Div: 3211.4937\nEpoch[3/15], Step [70/469], Reconst Loss: 11931.9258, KL Div: 3012.3589\nEpoch[3/15], Step [80/469], Reconst Loss: 11981.5234, KL Div: 3258.6450\nEpoch[3/15], Step [90/469], Reconst Loss: 11925.9590, KL Div: 3104.3784\nEpoch[3/15], Step [100/469], Reconst Loss: 11966.2764, KL Div: 3195.8059\nEpoch[3/15], Step [110/469], Reconst Loss: 11697.2109, KL Div: 3015.0039\nEpoch[3/15], Step [120/469], Reconst Loss: 11133.5840, KL Div: 3072.4580\nEpoch[3/15], Step [130/469], Reconst Loss: 11948.2256, KL Div: 3056.0288\nEpoch[3/15], Step [140/469], Reconst Loss: 11232.6260, KL Div: 3177.6665\nEpoch[3/15], Step [150/469], Reconst Loss: 11333.1934, KL Div: 3142.3315\nEpoch[3/15], Step [160/469], Reconst Loss: 11785.0381, KL Div: 2960.0010\nEpoch[3/15], Step [170/469], Reconst Loss: 12142.8555, KL Div: 3115.0342\nEpoch[3/15], Step [180/469], Reconst Loss: 11689.6055, KL Div: 2995.7061\nEpoch[3/15], Step [190/469], Reconst Loss: 11238.7910, KL Div: 2930.9902\nEpoch[3/15], Step [200/469], Reconst Loss: 11685.7324, KL Div: 3035.6787\nEpoch[3/15], Step [210/469], Reconst Loss: 11228.7617, KL Div: 3053.7651\nEpoch[3/15], Step [220/469], Reconst Loss: 11547.3027, KL Div: 3109.3730\nEpoch[3/15], Step [230/469], Reconst Loss: 11662.7393, KL Div: 2945.1353\nEpoch[3/15], Step [240/469], Reconst Loss: 10903.0264, KL Div: 3182.7441\nEpoch[3/15], Step [250/469], Reconst Loss: 11396.3320, KL Div: 3026.1758\nEpoch[3/15], Step [260/469], Reconst Loss: 11280.7432, KL Div: 3006.3369\nEpoch[3/15], Step [270/469], Reconst Loss: 11332.4688, KL Div: 3259.1719\nEpoch[3/15], Step [280/469], Reconst Loss: 11249.0332, KL Div: 3027.3438\nEpoch[3/15], Step [290/469], Reconst Loss: 12061.0996, KL Div: 3204.8037\nEpoch[3/15], Step [300/469], Reconst Loss: 11498.6592, KL Div: 3038.2661\nEpoch[3/15], Step [310/469], Reconst Loss: 11741.3105, KL Div: 3105.6182\nEpoch[3/15], Step [320/469], Reconst Loss: 11660.2285, KL Div: 3187.2666\nEpoch[3/15], Step [330/469], Reconst Loss: 11079.9883, KL Div: 3021.1943\nEpoch[3/15], Step [340/469], Reconst Loss: 11440.1689, KL Div: 3134.4248\nEpoch[3/15], Step [350/469], Reconst Loss: 11504.2520, KL Div: 3019.5503\nEpoch[3/15], Step [360/469], Reconst Loss: 11840.8311, KL Div: 3153.6592\nEpoch[3/15], Step [370/469], Reconst Loss: 11484.5059, KL Div: 3095.5024\nEpoch[3/15], Step [380/469], Reconst Loss: 11569.9189, KL Div: 3086.2993\nEpoch[3/15], Step [390/469], Reconst Loss: 11358.1240, KL Div: 3158.5540\nEpoch[3/15], Step [400/469], Reconst Loss: 11596.1113, KL Div: 3095.1226\nEpoch[3/15], Step [410/469], Reconst Loss: 11714.9707, KL Div: 3099.9756\nEpoch[3/15], Step [420/469], Reconst Loss: 11201.2656, KL Div: 3051.3735\nEpoch[3/15], Step [430/469], Reconst Loss: 10671.0273, KL Div: 3065.3662\nEpoch[3/15], Step [440/469], Reconst Loss: 11664.3906, KL Div: 3138.3354\nEpoch[3/15], Step [450/469], Reconst Loss: 11087.3818, KL Div: 3023.3596\nEpoch[3/15], Step [460/469], Reconst Loss: 11313.0127, KL Div: 3252.6152\nEpoch[4/15], Step [10/469], Reconst Loss: 11268.8984, KL Div: 3140.4009\nEpoch[4/15], Step [20/469], Reconst Loss: 10928.9297, KL Div: 3208.2744\nEpoch[4/15], Step [30/469], Reconst Loss: 11092.9590, KL Div: 3074.9099\nEpoch[4/15], Step [40/469], Reconst Loss: 11519.7949, KL Div: 3232.5752\nEpoch[4/15], Step [50/469], Reconst Loss: 11519.5879, KL Div: 3130.3115\nEpoch[4/15], Step [60/469], Reconst Loss: 11090.9600, KL Div: 3163.9829\nEpoch[4/15], Step [70/469], Reconst Loss: 11728.6992, KL Div: 3155.8577\nEpoch[4/15], Step [80/469], Reconst Loss: 11064.7666, KL Div: 3142.8608\nEpoch[4/15], Step [90/469], Reconst Loss: 11149.4648, KL Div: 3137.0005\nEpoch[4/15], Step [100/469], Reconst Loss: 11083.8340, KL Div: 3132.9067\nEpoch[4/15], Step [110/469], Reconst Loss: 11123.6768, KL Div: 3114.1648\nEpoch[4/15], Step [120/469], Reconst Loss: 11446.2852, KL Div: 3205.9634\nEpoch[4/15], Step [130/469], Reconst Loss: 11339.0430, KL Div: 3196.5078\nEpoch[4/15], Step [140/469], Reconst Loss: 11190.1699, KL Div: 3159.5908\nEpoch[4/15], Step [150/469], Reconst Loss: 10885.1621, KL Div: 3144.3115\nEpoch[4/15], Step [160/469], Reconst Loss: 10982.5293, KL Div: 3100.3179\nEpoch[4/15], Step [170/469], Reconst Loss: 11822.6367, KL Div: 3225.7998\nEpoch[4/15], Step [180/469], Reconst Loss: 11280.9746, KL Div: 3105.7720\nEpoch[4/15], Step [190/469], Reconst Loss: 10703.9473, KL Div: 3208.1619\nEpoch[4/15], Step [200/469], Reconst Loss: 10801.4248, KL Div: 2879.2229\nEpoch[4/15], Step [210/469], Reconst Loss: 10885.1309, KL Div: 3139.1567\nEpoch[4/15], Step [220/469], Reconst Loss: 11373.8770, KL Div: 3210.0869\nEpoch[4/15], Step [230/469], Reconst Loss: 11013.1758, KL Div: 3163.4941\nEpoch[4/15], Step [240/469], Reconst Loss: 12089.8691, KL Div: 3147.9707\nEpoch[4/15], Step [250/469], Reconst Loss: 10772.6484, KL Div: 3162.6343\nEpoch[4/15], Step [260/469], Reconst Loss: 10812.1211, KL Div: 3163.0667\nEpoch[4/15], Step [270/469], Reconst Loss: 11159.9424, KL Div: 3177.9548\nEpoch[4/15], Step [280/469], Reconst Loss: 11454.4023, KL Div: 3151.4580\nEpoch[4/15], Step [290/469], Reconst Loss: 10950.9844, KL Div: 3196.3438\nEpoch[4/15], Step [300/469], Reconst Loss: 11407.5801, KL Div: 3141.7380\nEpoch[4/15], Step [310/469], Reconst Loss: 10798.8545, KL Div: 3142.5278\nEpoch[4/15], Step [320/469], Reconst Loss: 10863.3643, KL Div: 3056.7053\nEpoch[4/15], Step [330/469], Reconst Loss: 11508.6826, KL Div: 3202.5806\nEpoch[4/15], Step [340/469], Reconst Loss: 11107.4551, KL Div: 3242.6880\nEpoch[4/15], Step [350/469], Reconst Loss: 10845.3818, KL Div: 3121.9641\nEpoch[4/15], Step [360/469], Reconst Loss: 11340.6924, KL Div: 3235.7283\nEpoch[4/15], Step [370/469], Reconst Loss: 11322.7129, KL Div: 3268.9526\nEpoch[4/15], Step [380/469], Reconst Loss: 10733.2168, KL Div: 3117.2705\nEpoch[4/15], Step [390/469], Reconst Loss: 10873.5195, KL Div: 3063.9209\nEpoch[4/15], Step [400/469], Reconst Loss: 11320.4512, KL Div: 3210.9656\nEpoch[4/15], Step [410/469], Reconst Loss: 11161.4375, KL Div: 3192.6357\nEpoch[4/15], Step [420/469], Reconst Loss: 11285.4326, KL Div: 3204.3098\nEpoch[4/15], Step [430/469], Reconst Loss: 10868.2256, KL Div: 3199.1089\nEpoch[4/15], Step [440/469], Reconst Loss: 11727.2197, KL Div: 3203.4053\nEpoch[4/15], Step [450/469], Reconst Loss: 11289.1621, KL Div: 3124.4155\nEpoch[4/15], Step [460/469], Reconst Loss: 10475.8262, KL Div: 3093.4192\nEpoch[5/15], Step [10/469], Reconst Loss: 11231.6367, KL Div: 3173.6746\nEpoch[5/15], Step [20/469], Reconst Loss: 10913.1523, KL Div: 3182.4761\nEpoch[5/15], Step [30/469], Reconst Loss: 11260.3223, KL Div: 3175.0249\nEpoch[5/15], Step [40/469], Reconst Loss: 10922.2881, KL Div: 3132.2849\nEpoch[5/15], Step [50/469], Reconst Loss: 10634.2393, KL Div: 3037.6577\nEpoch[5/15], Step [60/469], Reconst Loss: 11559.5840, KL Div: 3204.4551\nEpoch[5/15], Step [70/469], Reconst Loss: 10654.5000, KL Div: 3229.9067\nEpoch[5/15], Step [80/469], Reconst Loss: 10727.7559, KL Div: 3013.0166\nEpoch[5/15], Step [90/469], Reconst Loss: 11474.2578, KL Div: 3297.3030\nEpoch[5/15], Step [100/469], Reconst Loss: 11273.7480, KL Div: 3148.9612\nEpoch[5/15], Step [110/469], Reconst Loss: 10759.1553, KL Div: 3249.7947\nEpoch[5/15], Step [120/469], Reconst Loss: 11045.9609, KL Div: 3156.0457\nEpoch[5/15], Step [130/469], Reconst Loss: 10681.9688, KL Div: 3178.2085\nEpoch[5/15], Step [140/469], Reconst Loss: 10777.0137, KL Div: 3178.6938\nEpoch[5/15], Step [150/469], Reconst Loss: 10471.6484, KL Div: 3114.4795\nEpoch[5/15], Step [160/469], Reconst Loss: 10730.2334, KL Div: 3163.5942\nEpoch[5/15], Step [170/469], Reconst Loss: 10750.6758, KL Div: 3104.2839\nEpoch[5/15], Step [180/469], Reconst Loss: 11110.2910, KL Div: 3312.8643\nEpoch[5/15], Step [190/469], Reconst Loss: 11380.1445, KL Div: 3237.3633\nEpoch[5/15], Step [200/469], Reconst Loss: 10950.7910, KL Div: 3213.3213\nEpoch[5/15], Step [210/469], Reconst Loss: 10814.7363, KL Div: 3199.5396\nEpoch[5/15], Step [220/469], Reconst Loss: 11056.0107, KL Div: 3247.6851\nEpoch[5/15], Step [230/469], Reconst Loss: 10931.9355, KL Div: 3117.1345\nEpoch[5/15], Step [240/469], Reconst Loss: 10468.5273, KL Div: 3232.2874\nEpoch[5/15], Step [250/469], Reconst Loss: 11081.2891, KL Div: 3203.6006\nEpoch[5/15], Step [260/469], Reconst Loss: 11331.0801, KL Div: 3172.6418\nEpoch[5/15], Step [270/469], Reconst Loss: 10995.4150, KL Div: 3197.5522\nEpoch[5/15], Step [280/469], Reconst Loss: 10791.3896, KL Div: 3262.3550\nEpoch[5/15], Step [290/469], Reconst Loss: 10563.2627, KL Div: 3047.4592\nEpoch[5/15], Step [300/469], Reconst Loss: 10075.3457, KL Div: 3177.6077\nEpoch[5/15], Step [310/469], Reconst Loss: 11030.3691, KL Div: 3172.4336\nEpoch[5/15], Step [320/469], Reconst Loss: 10059.6953, KL Div: 3116.0291\nEpoch[5/15], Step [330/469], Reconst Loss: 10367.8311, KL Div: 3163.5566\nEpoch[5/15], Step [340/469], Reconst Loss: 11022.2969, KL Div: 3251.8918\nEpoch[5/15], Step [350/469], Reconst Loss: 10530.0996, KL Div: 3085.6990\nEpoch[5/15], Step [360/469], Reconst Loss: 10594.8340, KL Div: 3274.9595\nEpoch[5/15], Step [370/469], Reconst Loss: 11123.7979, KL Div: 3208.9087\nEpoch[5/15], Step [380/469], Reconst Loss: 10746.2344, KL Div: 3321.8928\nEpoch[5/15], Step [390/469], Reconst Loss: 10687.7109, KL Div: 3252.9155\nEpoch[5/15], Step [400/469], Reconst Loss: 10400.5352, KL Div: 3249.9360\nEpoch[5/15], Step [410/469], Reconst Loss: 10829.1426, KL Div: 3092.2588\nEpoch[5/15], Step [420/469], Reconst Loss: 11018.5879, KL Div: 3338.3594\nEpoch[5/15], Step [430/469], Reconst Loss: 11343.9199, KL Div: 3193.8181\nEpoch[5/15], Step [440/469], Reconst Loss: 11236.7246, KL Div: 3177.1089\nEpoch[5/15], Step [450/469], Reconst Loss: 10919.0020, KL Div: 3312.0107\nEpoch[5/15], Step [460/469], Reconst Loss: 11040.4668, KL Div: 3236.9448\nEpoch[6/15], Step [10/469], Reconst Loss: 10570.7422, KL Div: 3087.5066\nEpoch[6/15], Step [20/469], Reconst Loss: 10522.0508, KL Div: 3181.3933\nEpoch[6/15], Step [30/469], Reconst Loss: 10505.8203, KL Div: 3163.6328\nEpoch[6/15], Step [40/469], Reconst Loss: 11324.6494, KL Div: 3331.7383\nEpoch[6/15], Step [50/469], Reconst Loss: 10523.0771, KL Div: 3177.5879\nEpoch[6/15], Step [60/469], Reconst Loss: 10828.8057, KL Div: 3229.6621\nEpoch[6/15], Step [70/469], Reconst Loss: 10598.2148, KL Div: 3293.6865\nEpoch[6/15], Step [80/469], Reconst Loss: 11125.7832, KL Div: 3094.7563\nEpoch[6/15], Step [90/469], Reconst Loss: 10751.0107, KL Div: 3254.4785\nEpoch[6/15], Step [100/469], Reconst Loss: 10679.0400, KL Div: 3184.8521\nEpoch[6/15], Step [110/469], Reconst Loss: 10475.4160, KL Div: 3221.7822\nEpoch[6/15], Step [120/469], Reconst Loss: 10730.0898, KL Div: 3137.7883\nEpoch[6/15], Step [130/469], Reconst Loss: 10365.4434, KL Div: 3046.9900\nEpoch[6/15], Step [140/469], Reconst Loss: 10753.0371, KL Div: 3141.8091\nEpoch[6/15], Step [150/469], Reconst Loss: 10774.4961, KL Div: 3052.0796\nEpoch[6/15], Step [160/469], Reconst Loss: 10520.8516, KL Div: 3173.5925\nEpoch[6/15], Step [170/469], Reconst Loss: 10993.3945, KL Div: 3167.6260\nEpoch[6/15], Step [180/469], Reconst Loss: 10783.0176, KL Div: 3166.6499\nEpoch[6/15], Step [190/469], Reconst Loss: 10721.2051, KL Div: 3124.2202\nEpoch[6/15], Step [200/469], Reconst Loss: 10698.6729, KL Div: 3195.7275\nEpoch[6/15], Step [210/469], Reconst Loss: 10542.5176, KL Div: 3234.5095\nEpoch[6/15], Step [220/469], Reconst Loss: 10882.8457, KL Div: 3125.4260\nEpoch[6/15], Step [230/469], Reconst Loss: 11132.2930, KL Div: 3210.7017\nEpoch[6/15], Step [240/469], Reconst Loss: 10618.7734, KL Div: 3258.1694\nEpoch[6/15], Step [250/469], Reconst Loss: 10544.3789, KL Div: 3145.1255\nEpoch[6/15], Step [260/469], Reconst Loss: 10969.6543, KL Div: 3202.5637\nEpoch[6/15], Step [270/469], Reconst Loss: 11094.2256, KL Div: 3317.5718\nEpoch[6/15], Step [280/469], Reconst Loss: 10896.8037, KL Div: 3203.9565\nEpoch[6/15], Step [290/469], Reconst Loss: 11011.5918, KL Div: 3231.8660\nEpoch[6/15], Step [300/469], Reconst Loss: 10454.5908, KL Div: 3214.5559\nEpoch[6/15], Step [310/469], Reconst Loss: 10689.1104, KL Div: 3193.3796\nEpoch[6/15], Step [320/469], Reconst Loss: 10834.5674, KL Div: 3218.7397\nEpoch[6/15], Step [330/469], Reconst Loss: 10665.1387, KL Div: 3151.5898\nEpoch[6/15], Step [340/469], Reconst Loss: 10363.7227, KL Div: 3129.8340\nEpoch[6/15], Step [350/469], Reconst Loss: 10691.6221, KL Div: 3328.5132\nEpoch[6/15], Step [360/469], Reconst Loss: 10813.1113, KL Div: 3166.4175\nEpoch[6/15], Step [370/469], Reconst Loss: 10437.0371, KL Div: 3158.4036\nEpoch[6/15], Step [380/469], Reconst Loss: 10655.0039, KL Div: 3224.7676\nEpoch[6/15], Step [390/469], Reconst Loss: 10107.7715, KL Div: 3261.2827\nEpoch[6/15], Step [400/469], Reconst Loss: 10772.0820, KL Div: 3181.5601\nEpoch[6/15], Step [410/469], Reconst Loss: 10747.9492, KL Div: 3246.8545\nEpoch[6/15], Step [420/469], Reconst Loss: 10522.3877, KL Div: 3208.7366\nEpoch[6/15], Step [430/469], Reconst Loss: 10671.6270, KL Div: 3304.4868\nEpoch[6/15], Step [440/469], Reconst Loss: 11187.6221, KL Div: 3322.2231\nEpoch[6/15], Step [450/469], Reconst Loss: 10501.1152, KL Div: 3191.7764\nEpoch[6/15], Step [460/469], Reconst Loss: 10741.4600, KL Div: 3340.4697\nEpoch[7/15], Step [10/469], Reconst Loss: 10536.8154, KL Div: 3119.1841\nEpoch[7/15], Step [20/469], Reconst Loss: 10702.4678, KL Div: 3305.5942\nEpoch[7/15], Step [30/469], Reconst Loss: 10787.9727, KL Div: 3276.0610\nEpoch[7/15], Step [40/469], Reconst Loss: 10813.7715, KL Div: 3303.7734\nEpoch[7/15], Step [50/469], Reconst Loss: 10839.6816, KL Div: 3181.3320\nEpoch[7/15], Step [60/469], Reconst Loss: 10634.5879, KL Div: 3180.8408\nEpoch[7/15], Step [70/469], Reconst Loss: 10656.8770, KL Div: 3197.1953\nEpoch[7/15], Step [80/469], Reconst Loss: 10737.7715, KL Div: 3174.9829\nEpoch[7/15], Step [90/469], Reconst Loss: 10760.0811, KL Div: 3171.2646\nEpoch[7/15], Step [100/469], Reconst Loss: 11133.2656, KL Div: 3213.5254\nEpoch[7/15], Step [110/469], Reconst Loss: 10576.8809, KL Div: 3161.7969\nEpoch[7/15], Step [120/469], Reconst Loss: 10774.0566, KL Div: 3224.9729\nEpoch[7/15], Step [130/469], Reconst Loss: 10949.3438, KL Div: 3292.0225\nEpoch[7/15], Step [140/469], Reconst Loss: 10513.3740, KL Div: 3248.7114\nEpoch[7/15], Step [150/469], Reconst Loss: 10717.2402, KL Div: 3263.2556\nEpoch[7/15], Step [160/469], Reconst Loss: 11020.5537, KL Div: 3137.7258\nEpoch[7/15], Step [170/469], Reconst Loss: 10283.7275, KL Div: 3284.6162\nEpoch[7/15], Step [180/469], Reconst Loss: 10906.0918, KL Div: 3228.0859\nEpoch[7/15], Step [190/469], Reconst Loss: 11045.7422, KL Div: 3136.3931\nEpoch[7/15], Step [200/469], Reconst Loss: 11237.6621, KL Div: 3379.6973\nEpoch[7/15], Step [210/469], Reconst Loss: 10395.4414, KL Div: 3087.6172\nEpoch[7/15], Step [220/469], Reconst Loss: 10980.1504, KL Div: 3222.7544\nEpoch[7/15], Step [230/469], Reconst Loss: 10545.4990, KL Div: 3223.2632\nEpoch[7/15], Step [240/469], Reconst Loss: 10975.4902, KL Div: 3223.8411\nEpoch[7/15], Step [250/469], Reconst Loss: 10852.4531, KL Div: 3282.3286\nEpoch[7/15], Step [260/469], Reconst Loss: 10507.4199, KL Div: 3217.7026\nEpoch[7/15], Step [270/469], Reconst Loss: 10553.2354, KL Div: 3155.3838\nEpoch[7/15], Step [280/469], Reconst Loss: 10321.6973, KL Div: 3176.3843\nEpoch[7/15], Step [290/469], Reconst Loss: 10820.3535, KL Div: 3284.1553\nEpoch[7/15], Step [300/469], Reconst Loss: 10879.6074, KL Div: 3226.5439\nEpoch[7/15], Step [310/469], Reconst Loss: 10476.0576, KL Div: 3201.1738\nEpoch[7/15], Step [320/469], Reconst Loss: 10297.1787, KL Div: 3282.7500\nEpoch[7/15], Step [330/469], Reconst Loss: 10373.0088, KL Div: 3094.4761\nEpoch[7/15], Step [340/469], Reconst Loss: 10967.8066, KL Div: 3187.0532\nEpoch[7/15], Step [350/469], Reconst Loss: 11085.9980, KL Div: 3258.9314\nEpoch[7/15], Step [360/469], Reconst Loss: 10885.3711, KL Div: 3262.3376\nEpoch[7/15], Step [370/469], Reconst Loss: 10186.3564, KL Div: 3324.4709\nEpoch[7/15], Step [380/469], Reconst Loss: 10647.6572, KL Div: 3398.0625\nEpoch[7/15], Step [390/469], Reconst Loss: 10572.6436, KL Div: 3160.7117\nEpoch[7/15], Step [400/469], Reconst Loss: 10385.1025, KL Div: 3183.8530\nEpoch[7/15], Step [410/469], Reconst Loss: 10749.6621, KL Div: 3194.0918\nEpoch[7/15], Step [420/469], Reconst Loss: 10583.7148, KL Div: 3217.5435\nEpoch[7/15], Step [430/469], Reconst Loss: 10918.3965, KL Div: 3275.9927\nEpoch[7/15], Step [440/469], Reconst Loss: 10424.9141, KL Div: 3150.3481\nEpoch[7/15], Step [450/469], Reconst Loss: 10415.4551, KL Div: 3236.8464\nEpoch[7/15], Step [460/469], Reconst Loss: 11397.3008, KL Div: 3324.9644\nEpoch[8/15], Step [10/469], Reconst Loss: 10241.7002, KL Div: 3126.8486\nEpoch[8/15], Step [20/469], Reconst Loss: 10523.0029, KL Div: 3272.2083\nEpoch[8/15], Step [30/469], Reconst Loss: 10846.4453, KL Div: 3230.4453\nEpoch[8/15], Step [40/469], Reconst Loss: 10656.4033, KL Div: 3201.8667\nEpoch[8/15], Step [50/469], Reconst Loss: 10343.6885, KL Div: 3191.9824\nEpoch[8/15], Step [60/469], Reconst Loss: 10534.0918, KL Div: 3143.6069\nEpoch[8/15], Step [70/469], Reconst Loss: 10783.3877, KL Div: 3305.1362\nEpoch[8/15], Step [80/469], Reconst Loss: 10535.5391, KL Div: 3278.6274\nEpoch[8/15], Step [90/469], Reconst Loss: 10964.6621, KL Div: 3306.8921\nEpoch[8/15], Step [100/469], Reconst Loss: 10720.6582, KL Div: 3258.8921\nEpoch[8/15], Step [110/469], Reconst Loss: 10645.3066, KL Div: 3220.5928\nEpoch[8/15], Step [120/469], Reconst Loss: 10457.7100, KL Div: 3253.6582\nEpoch[8/15], Step [130/469], Reconst Loss: 10521.3770, KL Div: 3150.2295\nEpoch[8/15], Step [140/469], Reconst Loss: 10907.7549, KL Div: 3351.2427\nEpoch[8/15], Step [150/469], Reconst Loss: 10847.4863, KL Div: 3257.8982\nEpoch[8/15], Step [160/469], Reconst Loss: 10414.6475, KL Div: 3150.6121\nEpoch[8/15], Step [170/469], Reconst Loss: 10735.0312, KL Div: 3190.8384\nEpoch[8/15], Step [180/469], Reconst Loss: 10494.6572, KL Div: 3253.6765\nEpoch[8/15], Step [190/469], Reconst Loss: 10554.2236, KL Div: 3157.6147\nEpoch[8/15], Step [200/469], Reconst Loss: 10454.0010, KL Div: 3194.0498\nEpoch[8/15], Step [210/469], Reconst Loss: 10545.7188, KL Div: 3261.9463\nEpoch[8/15], Step [220/469], Reconst Loss: 10015.8584, KL Div: 3246.3872\nEpoch[8/15], Step [230/469], Reconst Loss: 10283.1221, KL Div: 3171.3508\nEpoch[8/15], Step [240/469], Reconst Loss: 10203.3535, KL Div: 3120.3037\nEpoch[8/15], Step [250/469], Reconst Loss: 10243.6641, KL Div: 3146.2329\nEpoch[8/15], Step [260/469], Reconst Loss: 10618.6924, KL Div: 3050.8335\nEpoch[8/15], Step [270/469], Reconst Loss: 10769.0010, KL Div: 3188.8110\nEpoch[8/15], Step [280/469], Reconst Loss: 10298.1729, KL Div: 3316.2476\nEpoch[8/15], Step [290/469], Reconst Loss: 10847.1123, KL Div: 3205.9209\nEpoch[8/15], Step [300/469], Reconst Loss: 10283.6123, KL Div: 3087.1323\nEpoch[8/15], Step [310/469], Reconst Loss: 10056.9141, KL Div: 3209.5645\nEpoch[8/15], Step [320/469], Reconst Loss: 10463.1797, KL Div: 3186.9314\nEpoch[8/15], Step [330/469], Reconst Loss: 10786.6631, KL Div: 3278.5630\nEpoch[8/15], Step [340/469], Reconst Loss: 10606.7861, KL Div: 3204.2378\nEpoch[8/15], Step [350/469], Reconst Loss: 10386.0615, KL Div: 3206.1904\nEpoch[8/15], Step [360/469], Reconst Loss: 11137.8223, KL Div: 3251.9585\nEpoch[8/15], Step [370/469], Reconst Loss: 10233.5586, KL Div: 3313.1738\nEpoch[8/15], Step [380/469], Reconst Loss: 10429.2354, KL Div: 3271.9275\nEpoch[8/15], Step [390/469], Reconst Loss: 10391.5820, KL Div: 3243.4014\nEpoch[8/15], Step [400/469], Reconst Loss: 10165.4688, KL Div: 3240.1616\nEpoch[8/15], Step [410/469], Reconst Loss: 10641.9199, KL Div: 3241.1914\nEpoch[8/15], Step [420/469], Reconst Loss: 10500.2969, KL Div: 3203.1497\nEpoch[8/15], Step [430/469], Reconst Loss: 10631.5234, KL Div: 3268.2207\nEpoch[8/15], Step [440/469], Reconst Loss: 10589.1094, KL Div: 3336.8188\nEpoch[8/15], Step [450/469], Reconst Loss: 10821.9150, KL Div: 3211.7817\nEpoch[8/15], Step [460/469], Reconst Loss: 10662.3906, KL Div: 3336.3682\nEpoch[9/15], Step [10/469], Reconst Loss: 10593.5625, KL Div: 3207.7988\nEpoch[9/15], Step [20/469], Reconst Loss: 11123.3545, KL Div: 3309.8296\nEpoch[9/15], Step [30/469], Reconst Loss: 10758.9180, KL Div: 3242.4614\nEpoch[9/15], Step [40/469], Reconst Loss: 10605.0625, KL Div: 3149.5361\nEpoch[9/15], Step [50/469], Reconst Loss: 10535.1240, KL Div: 3343.7925\nEpoch[9/15], Step [60/469], Reconst Loss: 10695.6016, KL Div: 3233.8777\nEpoch[9/15], Step [70/469], Reconst Loss: 10559.2227, KL Div: 3275.9487\nEpoch[9/15], Step [80/469], Reconst Loss: 10014.2705, KL Div: 3281.9365\nEpoch[9/15], Step [90/469], Reconst Loss: 10259.4395, KL Div: 3149.4497\nEpoch[9/15], Step [100/469], Reconst Loss: 10185.7773, KL Div: 3266.4414\nEpoch[9/15], Step [110/469], Reconst Loss: 10772.6357, KL Div: 3220.1663\nEpoch[9/15], Step [120/469], Reconst Loss: 9975.5615, KL Div: 3160.1279\nEpoch[9/15], Step [130/469], Reconst Loss: 10342.4766, KL Div: 3362.5361\nEpoch[9/15], Step [140/469], Reconst Loss: 10597.9150, KL Div: 3252.0444\nEpoch[9/15], Step [150/469], Reconst Loss: 10027.7432, KL Div: 3090.3604\nEpoch[9/15], Step [160/469], Reconst Loss: 10235.1953, KL Div: 3204.0933\nEpoch[9/15], Step [170/469], Reconst Loss: 10229.7656, KL Div: 3149.2393\nEpoch[9/15], Step [180/469], Reconst Loss: 10164.6680, KL Div: 3345.3503\nEpoch[9/15], Step [190/469], Reconst Loss: 10500.6855, KL Div: 3188.5615\nEpoch[9/15], Step [200/469], Reconst Loss: 10256.3301, KL Div: 3307.2173\nEpoch[9/15], Step [210/469], Reconst Loss: 10836.6934, KL Div: 3257.5120\nEpoch[9/15], Step [220/469], Reconst Loss: 10784.5225, KL Div: 3282.5000\nEpoch[9/15], Step [230/469], Reconst Loss: 10462.0801, KL Div: 3193.7935\nEpoch[9/15], Step [240/469], Reconst Loss: 10142.8213, KL Div: 3276.5020\nEpoch[9/15], Step [250/469], Reconst Loss: 10227.0098, KL Div: 3170.9614\nEpoch[9/15], Step [260/469], Reconst Loss: 10705.3008, KL Div: 3297.6577\nEpoch[9/15], Step [270/469], Reconst Loss: 10402.9648, KL Div: 3250.9551\nEpoch[9/15], Step [280/469], Reconst Loss: 10176.8037, KL Div: 3180.2500\nEpoch[9/15], Step [290/469], Reconst Loss: 10208.7559, KL Div: 3284.5010\nEpoch[9/15], Step [300/469], Reconst Loss: 10791.1172, KL Div: 3377.4963\nEpoch[9/15], Step [310/469], Reconst Loss: 10174.0020, KL Div: 3025.7964\nEpoch[9/15], Step [320/469], Reconst Loss: 10598.6445, KL Div: 3260.9243\nEpoch[9/15], Step [330/469], Reconst Loss: 10256.1406, KL Div: 3303.9712\nEpoch[9/15], Step [340/469], Reconst Loss: 11017.5234, KL Div: 3220.3770\nEpoch[9/15], Step [350/469], Reconst Loss: 10286.4385, KL Div: 3265.3081\nEpoch[9/15], Step [360/469], Reconst Loss: 10481.3672, KL Div: 3256.0059\nEpoch[9/15], Step [370/469], Reconst Loss: 10402.5830, KL Div: 3310.6501\nEpoch[9/15], Step [380/469], Reconst Loss: 10666.0527, KL Div: 3220.0317\nEpoch[9/15], Step [390/469], Reconst Loss: 10540.2754, KL Div: 3306.4419\nEpoch[9/15], Step [400/469], Reconst Loss: 10290.4609, KL Div: 3178.2717\nEpoch[9/15], Step [410/469], Reconst Loss: 10370.4688, KL Div: 3286.8013\nEpoch[9/15], Step [420/469], Reconst Loss: 10233.3057, KL Div: 3123.5430\nEpoch[9/15], Step [430/469], Reconst Loss: 10133.4629, KL Div: 3261.1719\nEpoch[9/15], Step [440/469], Reconst Loss: 10507.8154, KL Div: 3203.9387\nEpoch[9/15], Step [450/469], Reconst Loss: 10768.0020, KL Div: 3234.9038\nEpoch[9/15], Step [460/469], Reconst Loss: 10236.5547, KL Div: 3221.4995\nEpoch[10/15], Step [10/469], Reconst Loss: 10278.3652, KL Div: 3134.6426\nEpoch[10/15], Step [20/469], Reconst Loss: 10138.2402, KL Div: 3297.5366\nEpoch[10/15], Step [30/469], Reconst Loss: 10555.4688, KL Div: 3204.7373\nEpoch[10/15], Step [40/469], Reconst Loss: 10606.1709, KL Div: 3269.1860\nEpoch[10/15], Step [50/469], Reconst Loss: 10599.1582, KL Div: 3273.7134\nEpoch[10/15], Step [60/469], Reconst Loss: 10307.7227, KL Div: 3111.1621\nEpoch[10/15], Step [70/469], Reconst Loss: 10104.8105, KL Div: 3294.0359\nEpoch[10/15], Step [80/469], Reconst Loss: 10066.8320, KL Div: 3181.5811\nEpoch[10/15], Step [90/469], Reconst Loss: 10725.5684, KL Div: 3298.1604\nEpoch[10/15], Step [100/469], Reconst Loss: 10803.8184, KL Div: 3116.2654\nEpoch[10/15], Step [110/469], Reconst Loss: 10107.2637, KL Div: 3218.5552\nEpoch[10/15], Step [120/469], Reconst Loss: 10023.3984, KL Div: 3175.0198\nEpoch[10/15], Step [130/469], Reconst Loss: 10174.0039, KL Div: 3258.2646\nEpoch[10/15], Step [140/469], Reconst Loss: 10564.8281, KL Div: 3256.6697\nEpoch[10/15], Step [150/469], Reconst Loss: 10294.1250, KL Div: 3141.7729\nEpoch[10/15], Step [160/469], Reconst Loss: 10629.6914, KL Div: 3344.0579\nEpoch[10/15], Step [170/469], Reconst Loss: 10306.5254, KL Div: 3166.7842\nEpoch[10/15], Step [180/469], Reconst Loss: 10320.6660, KL Div: 3264.9683\nEpoch[10/15], Step [190/469], Reconst Loss: 10297.4258, KL Div: 3187.7791\nEpoch[10/15], Step [200/469], Reconst Loss: 10145.5527, KL Div: 3098.5610\nEpoch[10/15], Step [210/469], Reconst Loss: 10137.5527, KL Div: 3324.4321\nEpoch[10/15], Step [220/469], Reconst Loss: 10083.4727, KL Div: 3100.3022\nEpoch[10/15], Step [230/469], Reconst Loss: 10356.3047, KL Div: 3308.6665\nEpoch[10/15], Step [240/469], Reconst Loss: 10373.8906, KL Div: 3207.2261\nEpoch[10/15], Step [250/469], Reconst Loss: 10438.4053, KL Div: 3235.5500\nEpoch[10/15], Step [260/469], Reconst Loss: 10829.0283, KL Div: 3294.6836\nEpoch[10/15], Step [270/469], Reconst Loss: 10109.8672, KL Div: 3247.3772\nEpoch[10/15], Step [280/469], Reconst Loss: 9973.0000, KL Div: 3111.8628\nEpoch[10/15], Step [290/469], Reconst Loss: 10222.1641, KL Div: 3201.0234\nEpoch[10/15], Step [300/469], Reconst Loss: 10462.1152, KL Div: 3105.6636\nEpoch[10/15], Step [310/469], Reconst Loss: 10504.4609, KL Div: 3400.2642\nEpoch[10/15], Step [320/469], Reconst Loss: 10305.5088, KL Div: 3212.8491\nEpoch[10/15], Step [330/469], Reconst Loss: 10650.4033, KL Div: 3257.0745\nEpoch[10/15], Step [340/469], Reconst Loss: 9703.5518, KL Div: 3264.7256\nEpoch[10/15], Step [350/469], Reconst Loss: 10122.6670, KL Div: 3199.3081\nEpoch[10/15], Step [360/469], Reconst Loss: 10051.5352, KL Div: 3287.8315\nEpoch[10/15], Step [370/469], Reconst Loss: 10301.3477, KL Div: 3235.8826\nEpoch[10/15], Step [380/469], Reconst Loss: 10237.6133, KL Div: 3159.7742\nEpoch[10/15], Step [390/469], Reconst Loss: 10604.2422, KL Div: 3365.5361\nEpoch[10/15], Step [400/469], Reconst Loss: 10677.0166, KL Div: 3275.3518\nEpoch[10/15], Step [410/469], Reconst Loss: 10425.7734, KL Div: 3313.8892\nEpoch[10/15], Step [420/469], Reconst Loss: 10383.2354, KL Div: 3258.1721\nEpoch[10/15], Step [430/469], Reconst Loss: 10578.1699, KL Div: 3231.6077\nEpoch[10/15], Step [440/469], Reconst Loss: 10244.5244, KL Div: 3214.7397\nEpoch[10/15], Step [450/469], Reconst Loss: 10395.4072, KL Div: 3258.1301\nEpoch[10/15], Step [460/469], Reconst Loss: 10301.2471, KL Div: 3130.8550\nEpoch[11/15], Step [10/469], Reconst Loss: 10550.7627, KL Div: 3293.4009\nEpoch[11/15], Step [20/469], Reconst Loss: 10382.1660, KL Div: 3171.1660\nEpoch[11/15], Step [30/469], Reconst Loss: 10414.3535, KL Div: 3367.9790\nEpoch[11/15], Step [40/469], Reconst Loss: 10701.2070, KL Div: 3263.0830\nEpoch[11/15], Step [50/469], Reconst Loss: 10290.9434, KL Div: 3230.1199\nEpoch[11/15], Step [60/469], Reconst Loss: 10122.2930, KL Div: 3277.6743\nEpoch[11/15], Step [70/469], Reconst Loss: 9939.9609, KL Div: 3194.2346\nEpoch[11/15], Step [80/469], Reconst Loss: 10452.5518, KL Div: 3198.1177\nEpoch[11/15], Step [90/469], Reconst Loss: 10573.0664, KL Div: 3245.1348\nEpoch[11/15], Step [100/469], Reconst Loss: 10413.8525, KL Div: 3229.2871\nEpoch[11/15], Step [110/469], Reconst Loss: 10572.3682, KL Div: 3196.1201\nEpoch[11/15], Step [120/469], Reconst Loss: 10279.0488, KL Div: 3190.4849\nEpoch[11/15], Step [130/469], Reconst Loss: 10288.2119, KL Div: 3433.7170\nEpoch[11/15], Step [140/469], Reconst Loss: 9949.9502, KL Div: 3228.3789\nEpoch[11/15], Step [150/469], Reconst Loss: 10172.9688, KL Div: 3168.0337\nEpoch[11/15], Step [160/469], Reconst Loss: 10292.1475, KL Div: 3280.3135\nEpoch[11/15], Step [170/469], Reconst Loss: 10572.0537, KL Div: 3305.3423\nEpoch[11/15], Step [180/469], Reconst Loss: 10281.3242, KL Div: 3284.3691\nEpoch[11/15], Step [190/469], Reconst Loss: 10373.4209, KL Div: 3339.7988\nEpoch[11/15], Step [200/469], Reconst Loss: 10228.2539, KL Div: 3147.1670\nEpoch[11/15], Step [210/469], Reconst Loss: 10481.6777, KL Div: 3278.9609\nEpoch[11/15], Step [220/469], Reconst Loss: 10491.8574, KL Div: 3431.9448\nEpoch[11/15], Step [230/469], Reconst Loss: 10386.9062, KL Div: 3171.6682\nEpoch[11/15], Step [240/469], Reconst Loss: 10096.0371, KL Div: 3226.6924\nEpoch[11/15], Step [250/469], Reconst Loss: 10189.3672, KL Div: 3251.1965\nEpoch[11/15], Step [260/469], Reconst Loss: 10005.5215, KL Div: 3164.1057\nEpoch[11/15], Step [270/469], Reconst Loss: 10724.4199, KL Div: 3329.8484\nEpoch[11/15], Step [280/469], Reconst Loss: 10204.7822, KL Div: 3199.9556\nEpoch[11/15], Step [290/469], Reconst Loss: 10520.0195, KL Div: 3351.9185\nEpoch[11/15], Step [300/469], Reconst Loss: 10802.0596, KL Div: 3357.0107\nEpoch[11/15], Step [310/469], Reconst Loss: 10387.7666, KL Div: 3160.1440\nEpoch[11/15], Step [320/469], Reconst Loss: 10645.6689, KL Div: 3333.6118\nEpoch[11/15], Step [330/469], Reconst Loss: 10297.8867, KL Div: 3217.6047\nEpoch[11/15], Step [340/469], Reconst Loss: 10406.5430, KL Div: 3196.0125\nEpoch[11/15], Step [350/469], Reconst Loss: 10393.7441, KL Div: 3179.0212\nEpoch[11/15], Step [360/469], Reconst Loss: 10669.6406, KL Div: 3387.3960\nEpoch[11/15], Step [370/469], Reconst Loss: 10079.6670, KL Div: 3287.7373\nEpoch[11/15], Step [380/469], Reconst Loss: 10074.4131, KL Div: 3386.1528\nEpoch[11/15], Step [390/469], Reconst Loss: 10291.2754, KL Div: 3138.8789\nEpoch[11/15], Step [400/469], Reconst Loss: 10775.9160, KL Div: 3295.2979\nEpoch[11/15], Step [410/469], Reconst Loss: 10286.4873, KL Div: 3255.4519\nEpoch[11/15], Step [420/469], Reconst Loss: 10193.2637, KL Div: 3161.9956\nEpoch[11/15], Step [430/469], Reconst Loss: 10192.5840, KL Div: 3252.1160\nEpoch[11/15], Step [440/469], Reconst Loss: 10163.3701, KL Div: 3138.7646\nEpoch[11/15], Step [450/469], Reconst Loss: 10236.7852, KL Div: 3344.0620\nEpoch[11/15], Step [460/469], Reconst Loss: 10140.5195, KL Div: 3220.0544\nEpoch[12/15], Step [10/469], Reconst Loss: 10391.8730, KL Div: 3183.2788\nEpoch[12/15], Step [20/469], Reconst Loss: 10723.2725, KL Div: 3368.3623\nEpoch[12/15], Step [30/469], Reconst Loss: 10869.2305, KL Div: 3436.2974\nEpoch[12/15], Step [40/469], Reconst Loss: 10277.1562, KL Div: 3172.3420\nEpoch[12/15], Step [50/469], Reconst Loss: 9891.3438, KL Div: 3213.6968\nEpoch[12/15], Step [60/469], Reconst Loss: 10099.0117, KL Div: 3178.6362\nEpoch[12/15], Step [70/469], Reconst Loss: 10202.9746, KL Div: 3207.2188\nEpoch[12/15], Step [80/469], Reconst Loss: 10723.0635, KL Div: 3296.7883\nEpoch[12/15], Step [90/469], Reconst Loss: 10208.9189, KL Div: 3225.9287\nEpoch[12/15], Step [100/469], Reconst Loss: 10258.2871, KL Div: 3359.0439\nEpoch[12/15], Step [110/469], Reconst Loss: 9884.7988, KL Div: 3182.6995\nEpoch[12/15], Step [120/469], Reconst Loss: 10594.2285, KL Div: 3263.9175\nEpoch[12/15], Step [130/469], Reconst Loss: 10134.9297, KL Div: 3202.2080\nEpoch[12/15], Step [140/469], Reconst Loss: 10522.1582, KL Div: 3231.9717\nEpoch[12/15], Step [150/469], Reconst Loss: 10462.9463, KL Div: 3331.5669\nEpoch[12/15], Step [160/469], Reconst Loss: 10513.7852, KL Div: 3359.3872\nEpoch[12/15], Step [170/469], Reconst Loss: 10575.7832, KL Div: 3265.3535\nEpoch[12/15], Step [180/469], Reconst Loss: 10155.1152, KL Div: 3257.7915\nEpoch[12/15], Step [190/469], Reconst Loss: 10328.2090, KL Div: 3239.1631\nEpoch[12/15], Step [200/469], Reconst Loss: 10215.1045, KL Div: 3244.5171\nEpoch[12/15], Step [210/469], Reconst Loss: 10209.0234, KL Div: 3227.5098\nEpoch[12/15], Step [220/469], Reconst Loss: 9896.7344, KL Div: 3257.5967\nEpoch[12/15], Step [230/469], Reconst Loss: 10008.0840, KL Div: 3157.6526\nEpoch[12/15], Step [240/469], Reconst Loss: 10094.1094, KL Div: 3367.3022\nEpoch[12/15], Step [250/469], Reconst Loss: 10427.0098, KL Div: 3218.5073\nEpoch[12/15], Step [260/469], Reconst Loss: 10291.5625, KL Div: 3277.2021\nEpoch[12/15], Step [270/469], Reconst Loss: 10636.2891, KL Div: 3346.0503\nEpoch[12/15], Step [280/469], Reconst Loss: 10264.2324, KL Div: 3125.5596\nEpoch[12/15], Step [290/469], Reconst Loss: 10129.7773, KL Div: 3149.8491\nEpoch[12/15], Step [300/469], Reconst Loss: 10834.1270, KL Div: 3300.8860\nEpoch[12/15], Step [310/469], Reconst Loss: 10359.1904, KL Div: 3214.8389\nEpoch[12/15], Step [320/469], Reconst Loss: 10475.3018, KL Div: 3213.5698\nEpoch[12/15], Step [330/469], Reconst Loss: 9982.4336, KL Div: 3298.3164\nEpoch[12/15], Step [340/469], Reconst Loss: 10297.4658, KL Div: 3300.6270\nEpoch[12/15], Step [350/469], Reconst Loss: 10299.7920, KL Div: 3170.7085\nEpoch[12/15], Step [360/469], Reconst Loss: 10215.0811, KL Div: 3279.3438\nEpoch[12/15], Step [370/469], Reconst Loss: 10415.4336, KL Div: 3239.7856\nEpoch[12/15], Step [380/469], Reconst Loss: 10317.1270, KL Div: 3238.4922\nEpoch[12/15], Step [390/469], Reconst Loss: 9990.7500, KL Div: 3248.8594\nEpoch[12/15], Step [400/469], Reconst Loss: 10128.8379, KL Div: 3236.8264\nEpoch[12/15], Step [410/469], Reconst Loss: 10890.0566, KL Div: 3381.0020\nEpoch[12/15], Step [420/469], Reconst Loss: 10132.2422, KL Div: 3093.5027\nEpoch[12/15], Step [430/469], Reconst Loss: 10137.1211, KL Div: 3287.8218\nEpoch[12/15], Step [440/469], Reconst Loss: 10180.0039, KL Div: 3267.8237\nEpoch[12/15], Step [450/469], Reconst Loss: 10219.5195, KL Div: 3236.4697\nEpoch[12/15], Step [460/469], Reconst Loss: 10425.7988, KL Div: 3290.2163\nEpoch[13/15], Step [10/469], Reconst Loss: 10276.2168, KL Div: 3266.3125\nEpoch[13/15], Step [20/469], Reconst Loss: 10322.6846, KL Div: 3294.5645\nEpoch[13/15], Step [30/469], Reconst Loss: 10121.8193, KL Div: 3250.8005\nEpoch[13/15], Step [40/469], Reconst Loss: 10183.6475, KL Div: 3240.7979\nEpoch[13/15], Step [50/469], Reconst Loss: 10039.1699, KL Div: 3304.7451\nEpoch[13/15], Step [60/469], Reconst Loss: 10563.5127, KL Div: 3283.2341\nEpoch[13/15], Step [70/469], Reconst Loss: 10404.6582, KL Div: 3246.5630\nEpoch[13/15], Step [80/469], Reconst Loss: 10343.1445, KL Div: 3225.2842\nEpoch[13/15], Step [90/469], Reconst Loss: 10110.7715, KL Div: 3259.2021\nEpoch[13/15], Step [100/469], Reconst Loss: 10554.5830, KL Div: 3260.7280\nEpoch[13/15], Step [110/469], Reconst Loss: 9867.9648, KL Div: 3278.1670\nEpoch[13/15], Step [120/469], Reconst Loss: 10531.2295, KL Div: 3225.3765\nEpoch[13/15], Step [130/469], Reconst Loss: 10333.6494, KL Div: 3228.6633\nEpoch[13/15], Step [140/469], Reconst Loss: 10084.8818, KL Div: 3361.7122\nEpoch[13/15], Step [150/469], Reconst Loss: 9976.2295, KL Div: 3171.9097\nEpoch[13/15], Step [160/469], Reconst Loss: 10116.3340, KL Div: 3287.1602\nEpoch[13/15], Step [170/469], Reconst Loss: 9816.5391, KL Div: 3261.4172\nEpoch[13/15], Step [180/469], Reconst Loss: 10156.5596, KL Div: 3340.2222\nEpoch[13/15], Step [190/469], Reconst Loss: 10177.9336, KL Div: 3177.4053\nEpoch[13/15], Step [200/469], Reconst Loss: 10409.8320, KL Div: 3288.2622\nEpoch[13/15], Step [210/469], Reconst Loss: 10005.9258, KL Div: 3330.6855\nEpoch[13/15], Step [220/469], Reconst Loss: 10260.8398, KL Div: 3289.3074\nEpoch[13/15], Step [230/469], Reconst Loss: 10546.3418, KL Div: 3278.4167\nEpoch[13/15], Step [240/469], Reconst Loss: 10240.8975, KL Div: 3210.1621\nEpoch[13/15], Step [250/469], Reconst Loss: 10600.0000, KL Div: 3259.4268\nEpoch[13/15], Step [260/469], Reconst Loss: 10447.1338, KL Div: 3274.6470\nEpoch[13/15], Step [270/469], Reconst Loss: 10486.0723, KL Div: 3297.9939\nEpoch[13/15], Step [280/469], Reconst Loss: 10652.1797, KL Div: 3374.2896\nEpoch[13/15], Step [290/469], Reconst Loss: 10781.2256, KL Div: 3256.0603\nEpoch[13/15], Step [300/469], Reconst Loss: 10102.8115, KL Div: 3221.9287\nEpoch[13/15], Step [310/469], Reconst Loss: 10659.6289, KL Div: 3354.2908\nEpoch[13/15], Step [320/469], Reconst Loss: 9847.3164, KL Div: 3104.2114\nEpoch[13/15], Step [330/469], Reconst Loss: 9995.2822, KL Div: 3240.5649\nEpoch[13/15], Step [340/469], Reconst Loss: 10493.3418, KL Div: 3320.5879\nEpoch[13/15], Step [350/469], Reconst Loss: 10215.3291, KL Div: 3119.4500\nEpoch[13/15], Step [360/469], Reconst Loss: 10121.9873, KL Div: 3234.3496\nEpoch[13/15], Step [370/469], Reconst Loss: 9874.8906, KL Div: 3207.3992\nEpoch[13/15], Step [380/469], Reconst Loss: 10010.9668, KL Div: 3204.8699\nEpoch[13/15], Step [390/469], Reconst Loss: 10609.8828, KL Div: 3308.7998\nEpoch[13/15], Step [400/469], Reconst Loss: 10612.7715, KL Div: 3260.9119\nEpoch[13/15], Step [410/469], Reconst Loss: 10383.2197, KL Div: 3288.6758\nEpoch[13/15], Step [420/469], Reconst Loss: 10129.9658, KL Div: 3157.6765\nEpoch[13/15], Step [430/469], Reconst Loss: 10505.2402, KL Div: 3321.6553\nEpoch[13/15], Step [440/469], Reconst Loss: 10499.2852, KL Div: 3281.5652\nEpoch[13/15], Step [450/469], Reconst Loss: 10176.3633, KL Div: 3158.0901\nEpoch[13/15], Step [460/469], Reconst Loss: 10181.7490, KL Div: 3358.6162\nEpoch[14/15], Step [10/469], Reconst Loss: 10437.2852, KL Div: 3346.0935\nEpoch[14/15], Step [20/469], Reconst Loss: 10301.3594, KL Div: 3155.4346\nEpoch[14/15], Step [30/469], Reconst Loss: 10509.1934, KL Div: 3342.2344\nEpoch[14/15], Step [40/469], Reconst Loss: 10226.9414, KL Div: 3117.9382\nEpoch[14/15], Step [50/469], Reconst Loss: 10404.2168, KL Div: 3236.2881\nEpoch[14/15], Step [60/469], Reconst Loss: 10634.1836, KL Div: 3280.0840\nEpoch[14/15], Step [70/469], Reconst Loss: 9971.3945, KL Div: 3246.7097\nEpoch[14/15], Step [80/469], Reconst Loss: 10087.8262, KL Div: 3169.3027\nEpoch[14/15], Step [90/469], Reconst Loss: 10012.5840, KL Div: 3265.5837\nEpoch[14/15], Step [100/469], Reconst Loss: 10001.3750, KL Div: 3270.9282\nEpoch[14/15], Step [110/469], Reconst Loss: 10751.5918, KL Div: 3346.0684\nEpoch[14/15], Step [120/469], Reconst Loss: 10196.3848, KL Div: 3180.9756\nEpoch[14/15], Step [130/469], Reconst Loss: 10345.9561, KL Div: 3332.9019\nEpoch[14/15], Step [140/469], Reconst Loss: 10319.2344, KL Div: 3214.0186\nEpoch[14/15], Step [150/469], Reconst Loss: 10313.5488, KL Div: 3347.6267\nEpoch[14/15], Step [160/469], Reconst Loss: 10505.1396, KL Div: 3194.8115\nEpoch[14/15], Step [170/469], Reconst Loss: 10644.9365, KL Div: 3350.1431\nEpoch[14/15], Step [180/469], Reconst Loss: 9825.5986, KL Div: 3237.7202\nEpoch[14/15], Step [190/469], Reconst Loss: 10150.5576, KL Div: 3199.4380\nEpoch[14/15], Step [200/469], Reconst Loss: 10261.5908, KL Div: 3298.3787\nEpoch[14/15], Step [210/469], Reconst Loss: 10259.2012, KL Div: 3268.8735\nEpoch[14/15], Step [220/469], Reconst Loss: 10455.2344, KL Div: 3233.1743\nEpoch[14/15], Step [230/469], Reconst Loss: 10422.1064, KL Div: 3282.0652\nEpoch[14/15], Step [240/469], Reconst Loss: 10109.3438, KL Div: 3248.2881\nEpoch[14/15], Step [250/469], Reconst Loss: 10319.7578, KL Div: 3246.1243\nEpoch[14/15], Step [260/469], Reconst Loss: 10179.3848, KL Div: 3238.3970\nEpoch[14/15], Step [270/469], Reconst Loss: 9931.8760, KL Div: 3065.6606\nEpoch[14/15], Step [280/469], Reconst Loss: 9987.7539, KL Div: 3240.6821\nEpoch[14/15], Step [290/469], Reconst Loss: 10133.2246, KL Div: 3233.2637\nEpoch[14/15], Step [300/469], Reconst Loss: 10071.8242, KL Div: 3263.5483\nEpoch[14/15], Step [310/469], Reconst Loss: 10335.7285, KL Div: 3269.2583\nEpoch[14/15], Step [320/469], Reconst Loss: 9629.9824, KL Div: 3188.0674\nEpoch[14/15], Step [330/469], Reconst Loss: 10541.1260, KL Div: 3347.1091\nEpoch[14/15], Step [340/469], Reconst Loss: 10107.2100, KL Div: 3065.1475\nEpoch[14/15], Step [350/469], Reconst Loss: 10423.1631, KL Div: 3204.9980\nEpoch[14/15], Step [360/469], Reconst Loss: 10242.4863, KL Div: 3332.4319\nEpoch[14/15], Step [370/469], Reconst Loss: 10304.3965, KL Div: 3240.3018\nEpoch[14/15], Step [380/469], Reconst Loss: 10351.7910, KL Div: 3223.5044\nEpoch[14/15], Step [390/469], Reconst Loss: 10391.8105, KL Div: 3301.8494\nEpoch[14/15], Step [400/469], Reconst Loss: 10396.3799, KL Div: 3300.9507\nEpoch[14/15], Step [410/469], Reconst Loss: 10178.6074, KL Div: 3319.1714\nEpoch[14/15], Step [420/469], Reconst Loss: 10212.1543, KL Div: 3230.0566\nEpoch[14/15], Step [430/469], Reconst Loss: 9913.7754, KL Div: 3272.8545\nEpoch[14/15], Step [440/469], Reconst Loss: 10110.6943, KL Div: 3220.7925\nEpoch[14/15], Step [450/469], Reconst Loss: 9726.5293, KL Div: 3310.6230\nEpoch[14/15], Step [460/469], Reconst Loss: 10329.2266, KL Div: 3233.2542\nEpoch[15/15], Step [10/469], Reconst Loss: 9956.3906, KL Div: 3303.7549\nEpoch[15/15], Step [20/469], Reconst Loss: 10128.7695, KL Div: 3218.7075\nEpoch[15/15], Step [30/469], Reconst Loss: 9765.0947, KL Div: 3180.1074\nEpoch[15/15], Step [40/469], Reconst Loss: 10495.0059, KL Div: 3238.1729\nEpoch[15/15], Step [50/469], Reconst Loss: 10402.9570, KL Div: 3300.7026\nEpoch[15/15], Step [60/469], Reconst Loss: 9984.0352, KL Div: 3205.8521\nEpoch[15/15], Step [70/469], Reconst Loss: 9862.6416, KL Div: 3260.2832\nEpoch[15/15], Step [80/469], Reconst Loss: 10130.9658, KL Div: 3181.0134\nEpoch[15/15], Step [90/469], Reconst Loss: 10729.2002, KL Div: 3296.9727\nEpoch[15/15], Step [100/469], Reconst Loss: 9921.4326, KL Div: 3205.4121\nEpoch[15/15], Step [110/469], Reconst Loss: 10358.0215, KL Div: 3248.1614\nEpoch[15/15], Step [120/469], Reconst Loss: 10747.4746, KL Div: 3411.3071\nEpoch[15/15], Step [130/469], Reconst Loss: 10289.2012, KL Div: 3160.4336\nEpoch[15/15], Step [140/469], Reconst Loss: 9631.7207, KL Div: 3146.0400\nEpoch[15/15], Step [150/469], Reconst Loss: 9770.8594, KL Div: 3256.9243\nEpoch[15/15], Step [160/469], Reconst Loss: 10104.4346, KL Div: 3235.6885\nEpoch[15/15], Step [170/469], Reconst Loss: 10084.0684, KL Div: 3317.0200\nEpoch[15/15], Step [180/469], Reconst Loss: 10181.4424, KL Div: 3238.8455\nEpoch[15/15], Step [190/469], Reconst Loss: 10316.0391, KL Div: 3271.3916\nEpoch[15/15], Step [200/469], Reconst Loss: 10177.1895, KL Div: 3184.6428\nEpoch[15/15], Step [210/469], Reconst Loss: 10252.4902, KL Div: 3175.6289\nEpoch[15/15], Step [220/469], Reconst Loss: 9916.5869, KL Div: 3222.7217\nEpoch[15/15], Step [230/469], Reconst Loss: 9842.9062, KL Div: 3265.2400\nEpoch[15/15], Step [240/469], Reconst Loss: 10546.1240, KL Div: 3287.5830\nEpoch[15/15], Step [250/469], Reconst Loss: 9987.7305, KL Div: 3106.9780\nEpoch[15/15], Step [260/469], Reconst Loss: 10419.3945, KL Div: 3338.4685\nEpoch[15/15], Step [270/469], Reconst Loss: 10065.2715, KL Div: 3282.5073\nEpoch[15/15], Step [280/469], Reconst Loss: 10025.3350, KL Div: 3086.6611\nEpoch[15/15], Step [290/469], Reconst Loss: 9886.2422, KL Div: 3362.5464\nEpoch[15/15], Step [300/469], Reconst Loss: 9564.3242, KL Div: 3190.0862\nEpoch[15/15], Step [310/469], Reconst Loss: 10339.8984, KL Div: 3274.0613\nEpoch[15/15], Step [320/469], Reconst Loss: 10226.8867, KL Div: 3324.5327\nEpoch[15/15], Step [330/469], Reconst Loss: 10191.3984, KL Div: 3193.2117\nEpoch[15/15], Step [340/469], Reconst Loss: 10483.7930, KL Div: 3330.7703\nEpoch[15/15], Step [350/469], Reconst Loss: 10101.3828, KL Div: 3306.9001\nEpoch[15/15], Step [360/469], Reconst Loss: 10038.2930, KL Div: 3265.2124\nEpoch[15/15], Step [370/469], Reconst Loss: 10334.6172, KL Div: 3382.0498\nEpoch[15/15], Step [380/469], Reconst Loss: 10172.0625, KL Div: 3244.6907\nEpoch[15/15], Step [390/469], Reconst Loss: 9643.6543, KL Div: 3217.6306\nEpoch[15/15], Step [400/469], Reconst Loss: 10006.9062, KL Div: 3331.5508\nEpoch[15/15], Step [410/469], Reconst Loss: 10263.5137, KL Div: 3298.3147\nEpoch[15/15], Step [420/469], Reconst Loss: 10380.5430, KL Div: 3261.8140\nEpoch[15/15], Step [430/469], Reconst Loss: 10222.9805, KL Div: 3212.0979\nEpoch[15/15], Step [440/469], Reconst Loss: 10487.6064, KL Div: 3334.3384\nEpoch[15/15], Step [450/469], Reconst Loss: 10090.8320, KL Div: 3220.9924\nEpoch[15/15], Step [460/469], Reconst Loss: 10343.3145, KL Div: 3155.5571\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}