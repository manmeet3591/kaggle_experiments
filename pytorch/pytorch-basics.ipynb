{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip uninstall torch -y\n!pip uninstall torchvision -y\n!pip install torch \n!pip install torchvision\nimport torch \nimport torchvision\nimport torch.nn as nn\nimport numpy as np\nimport torchvision.transforms as transforms","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-09-06T07:31:25.717484Z","iopub.execute_input":"2021-09-06T07:31:25.717925Z","iopub.status.idle":"2021-09-06T07:32:15.693337Z","shell.execute_reply.started":"2021-09-06T07:31:25.717891Z","shell.execute_reply":"2021-09-06T07:32:15.692215Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Found existing installation: torch 1.9.0\nUninstalling torch-1.9.0:\n  Successfully uninstalled torch-1.9.0\n\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\nFound existing installation: torchvision 0.10.0\nUninstalling torchvision-0.10.0:\n  Successfully uninstalled torchvision-0.10.0\n\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\nCollecting torch\n  Using cached torch-1.9.0-cp37-cp37m-manylinux1_x86_64.whl (831.4 MB)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch) (3.7.4.3)\nInstalling collected packages: torch\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nfastai 2.2.7 requires torchvision<0.9,>=0.8, which is not installed.\neasyocr 1.3.2 requires torchvision>=0.5, which is not installed.\nallennlp 2.5.0 requires torchvision<0.10.0,>=0.8.1, which is not installed.\nkornia 0.5.5 requires numpy<=1.19, but you have numpy 1.19.5 which is incompatible.\nfastai 2.2.7 requires torch<1.8,>=1.7.0, but you have torch 1.9.0 which is incompatible.\nallennlp 2.5.0 requires torch<1.9.0,>=1.6.0, but you have torch 1.9.0 which is incompatible.\u001b[0m\nSuccessfully installed torch-1.9.0\n\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\nCollecting torchvision\n  Using cached torchvision-0.10.0-cp37-cp37m-manylinux1_x86_64.whl (22.1 MB)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torchvision) (1.19.5)\nRequirement already satisfied: pillow>=5.3.0 in /opt/conda/lib/python3.7/site-packages (from torchvision) (8.2.0)\nRequirement already satisfied: torch==1.9.0 in /opt/conda/lib/python3.7/site-packages (from torchvision) (1.9.0)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch==1.9.0->torchvision) (3.7.4.3)\nInstalling collected packages: torchvision\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nfastai 2.2.7 requires torch<1.8,>=1.7.0, but you have torch 1.9.0 which is incompatible.\nfastai 2.2.7 requires torchvision<0.9,>=0.8, but you have torchvision 0.10.0 which is incompatible.\nallennlp 2.5.0 requires torch<1.9.0,>=1.6.0, but you have torch 1.9.0 which is incompatible.\nallennlp 2.5.0 requires torchvision<0.10.0,>=0.8.1, but you have torchvision 0.10.0 which is incompatible.\u001b[0m\nSuccessfully installed torchvision-0.10.0\n\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"# ================================================================== #\n#                         Table of Contents                          #\n# ================================================================== #\n\n# 1. Basic autograd example 1               (Line 25 to 39)\n# 2. Basic autograd example 2               (Line 46 to 83)\n# 3. Loading data from numpy                (Line 90 to 97)\n# 4. Input pipline                          (Line 104 to 129)\n# 5. Input pipline for custom dataset       (Line 136 to 156)\n# 6. Pretrained model                       (Line 163 to 176)\n# 7. Save and load model                    (Line 183 to 189) \n\n\n# ================================================================== #\n#                     1. Basic autograd example 1                    #\n# ================================================================== #","metadata":{"execution":{"iopub.status.busy":"2021-09-06T07:32:21.105708Z","iopub.execute_input":"2021-09-06T07:32:21.106119Z","iopub.status.idle":"2021-09-06T07:32:21.109949Z","shell.execute_reply.started":"2021-09-06T07:32:21.106080Z","shell.execute_reply":"2021-09-06T07:32:21.108960Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Create tensors.\nx = torch.tensor(1., requires_grad=True)\nw = torch.tensor(2., requires_grad=True)\nb = torch.tensor(3., requires_grad=True)","metadata":{"execution":{"iopub.status.busy":"2021-09-06T07:32:21.548599Z","iopub.execute_input":"2021-09-06T07:32:21.548968Z","iopub.status.idle":"2021-09-06T07:32:21.554548Z","shell.execute_reply.started":"2021-09-06T07:32:21.548936Z","shell.execute_reply":"2021-09-06T07:32:21.553325Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Build a computational graph.\ny = w * x + b    # y = 2 * x + 3","metadata":{"execution":{"iopub.status.busy":"2021-09-06T07:32:22.944606Z","iopub.execute_input":"2021-09-06T07:32:22.945015Z","iopub.status.idle":"2021-09-06T07:32:22.949908Z","shell.execute_reply.started":"2021-09-06T07:32:22.944981Z","shell.execute_reply":"2021-09-06T07:32:22.948765Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"print(w,x,b,y)","metadata":{"execution":{"iopub.status.busy":"2021-09-06T07:32:23.728959Z","iopub.execute_input":"2021-09-06T07:32:23.729316Z","iopub.status.idle":"2021-09-06T07:32:23.738462Z","shell.execute_reply.started":"2021-09-06T07:32:23.729284Z","shell.execute_reply":"2021-09-06T07:32:23.737648Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"tensor(2., requires_grad=True) tensor(1., requires_grad=True) tensor(3., requires_grad=True) tensor(5., grad_fn=<AddBackward0>)\n","output_type":"stream"}]},{"cell_type":"code","source":"# Compute gradients.\ny.backward()","metadata":{"execution":{"iopub.status.busy":"2021-09-06T07:32:24.609900Z","iopub.execute_input":"2021-09-06T07:32:24.610252Z","iopub.status.idle":"2021-09-06T07:32:24.616019Z","shell.execute_reply.started":"2021-09-06T07:32:24.610223Z","shell.execute_reply":"2021-09-06T07:32:24.615050Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Print out the gradients.\nprint(x.grad)    # x.grad = 2 \nprint(w.grad)    # w.grad = 1 \nprint(b.grad)    # b.grad = 1 \n","metadata":{"execution":{"iopub.status.busy":"2021-09-06T07:32:25.384784Z","iopub.execute_input":"2021-09-06T07:32:25.385152Z","iopub.status.idle":"2021-09-06T07:32:25.393388Z","shell.execute_reply.started":"2021-09-06T07:32:25.385120Z","shell.execute_reply":"2021-09-06T07:32:25.392331Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"tensor(2.)\ntensor(1.)\ntensor(1.)\n","output_type":"stream"}]},{"cell_type":"code","source":"# ================================================================== #\n#                    2. Basic autograd example 2                     #\n# ================================================================== #\n\n# Create tensors of shape (10, 3) and (10, 2).\nx = torch.randn(10, 3)\ny = torch.randn(10, 2)","metadata":{"execution":{"iopub.status.busy":"2021-09-06T07:32:26.404255Z","iopub.execute_input":"2021-09-06T07:32:26.404588Z","iopub.status.idle":"2021-09-06T07:32:26.409125Z","shell.execute_reply.started":"2021-09-06T07:32:26.404559Z","shell.execute_reply":"2021-09-06T07:32:26.408224Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"print(x, x.shape)","metadata":{"execution":{"iopub.status.busy":"2021-09-06T07:32:27.399827Z","iopub.execute_input":"2021-09-06T07:32:27.400205Z","iopub.status.idle":"2021-09-06T07:32:27.406599Z","shell.execute_reply.started":"2021-09-06T07:32:27.400170Z","shell.execute_reply":"2021-09-06T07:32:27.405700Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"tensor([[-2.7870,  1.7598,  0.1187],\n        [ 0.6955, -0.7327, -0.1147],\n        [-1.9928,  1.4445,  1.5361],\n        [-0.5014, -0.5999,  0.8899],\n        [ 1.0245,  0.2452, -0.2114],\n        [ 0.6274, -0.0285,  0.9297],\n        [ 0.0291, -0.5591, -1.9504],\n        [ 2.8186, -0.4835, -0.2441],\n        [-0.9032,  0.8295, -0.7762],\n        [ 1.3787,  0.1821,  0.4072]]) torch.Size([10, 3])\n","output_type":"stream"}]},{"cell_type":"code","source":"# Build a fully connected layer.\nlinear = nn.Linear(3, 2)\nprint ('w: ', linear.weight)\nprint ('b: ', linear.bias)","metadata":{"execution":{"iopub.status.busy":"2021-09-06T07:32:28.164897Z","iopub.execute_input":"2021-09-06T07:32:28.165251Z","iopub.status.idle":"2021-09-06T07:32:28.172414Z","shell.execute_reply.started":"2021-09-06T07:32:28.165213Z","shell.execute_reply":"2021-09-06T07:32:28.171755Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"w:  Parameter containing:\ntensor([[-0.5200, -0.0766,  0.3555],\n        [ 0.0157,  0.0779, -0.2214]], requires_grad=True)\nb:  Parameter containing:\ntensor([-0.2400,  0.0429], requires_grad=True)\n","output_type":"stream"}]},{"cell_type":"code","source":"# Build loss function and optimizer.\ncriterion = nn.MSELoss()\noptimizer = torch.optim.SGD(linear.parameters(), lr=0.01)","metadata":{"execution":{"iopub.status.busy":"2021-09-06T07:32:28.785023Z","iopub.execute_input":"2021-09-06T07:32:28.785690Z","iopub.status.idle":"2021-09-06T07:32:28.791272Z","shell.execute_reply.started":"2021-09-06T07:32:28.785616Z","shell.execute_reply":"2021-09-06T07:32:28.790272Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# Forward pass.\npred = linear(x)","metadata":{"execution":{"iopub.status.busy":"2021-09-06T07:32:29.784450Z","iopub.execute_input":"2021-09-06T07:32:29.784792Z","iopub.status.idle":"2021-09-06T07:32:29.789544Z","shell.execute_reply.started":"2021-09-06T07:32:29.784761Z","shell.execute_reply":"2021-09-06T07:32:29.788425Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# Compute loss.\nloss = criterion(pred, y)\nprint('loss: ', loss.item())","metadata":{"execution":{"iopub.status.busy":"2021-09-06T07:32:30.578968Z","iopub.execute_input":"2021-09-06T07:32:30.579302Z","iopub.status.idle":"2021-09-06T07:32:30.585115Z","shell.execute_reply.started":"2021-09-06T07:32:30.579273Z","shell.execute_reply":"2021-09-06T07:32:30.584081Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"loss:  1.760976791381836\n","output_type":"stream"}]},{"cell_type":"code","source":"# Backward pass.\nloss.backward()","metadata":{"execution":{"iopub.status.busy":"2021-09-06T07:32:31.610015Z","iopub.execute_input":"2021-09-06T07:32:31.610511Z","iopub.status.idle":"2021-09-06T07:32:31.614461Z","shell.execute_reply.started":"2021-09-06T07:32:31.610477Z","shell.execute_reply":"2021-09-06T07:32:31.613720Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# Print out the gradients.\nprint ('dL/dw: ', linear.weight.grad) \nprint ('dL/db: ', linear.bias.grad)","metadata":{"execution":{"iopub.status.busy":"2021-09-06T07:32:32.409688Z","iopub.execute_input":"2021-09-06T07:32:32.410036Z","iopub.status.idle":"2021-09-06T07:32:32.417006Z","shell.execute_reply.started":"2021-09-06T07:32:32.410005Z","shell.execute_reply":"2021-09-06T07:32:32.416337Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"dL/dw:  tensor([[-1.2300, -0.1489,  0.2041],\n        [-0.1537,  0.1380, -0.1021]])\ndL/db:  tensor([-0.8278,  0.0200])\n","output_type":"stream"}]},{"cell_type":"code","source":"# 1-step gradient descent.\noptimizer.step()","metadata":{"execution":{"iopub.status.busy":"2021-09-06T07:32:33.698784Z","iopub.execute_input":"2021-09-06T07:32:33.699320Z","iopub.status.idle":"2021-09-06T07:32:33.703176Z","shell.execute_reply.started":"2021-09-06T07:32:33.699271Z","shell.execute_reply":"2021-09-06T07:32:33.702557Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# You can also perform gradient descent at the low level.\n# linear.weight.data.sub_(0.01 * linear.weight.grad.data)\n# linear.bias.data.sub_(0.01 * linear.bias.grad.data)\n\n# Print out the loss after 1-step gradient descent.\npred = linear(x)\nloss = criterion(pred, y)\nprint('loss after 1 step optimization: ', loss.item())","metadata":{"execution":{"iopub.status.busy":"2021-09-06T07:32:34.509694Z","iopub.execute_input":"2021-09-06T07:32:34.510245Z","iopub.status.idle":"2021-09-06T07:32:34.515259Z","shell.execute_reply.started":"2021-09-06T07:32:34.510195Z","shell.execute_reply":"2021-09-06T07:32:34.514601Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"loss after 1 step optimization:  1.7380443811416626\n","output_type":"stream"}]},{"cell_type":"code","source":"# ================================================================== #\n#                     3. Loading data from numpy                     #\n# ================================================================== #\n\n# Create a numpy array.\nx = np.array([[1, 2], [3, 4]])\n\n# Convert the numpy array to a torch tensor.\ny = torch.from_numpy(x)\n\n# Convert the torch tensor to a numpy array.\nz = y.numpy()","metadata":{"execution":{"iopub.status.busy":"2021-09-06T07:32:35.690112Z","iopub.execute_input":"2021-09-06T07:32:35.690462Z","iopub.status.idle":"2021-09-06T07:32:35.695393Z","shell.execute_reply.started":"2021-09-06T07:32:35.690433Z","shell.execute_reply":"2021-09-06T07:32:35.694304Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"print(y, y.shape)","metadata":{"execution":{"iopub.status.busy":"2021-09-06T07:32:36.729257Z","iopub.execute_input":"2021-09-06T07:32:36.729819Z","iopub.status.idle":"2021-09-06T07:32:36.735401Z","shell.execute_reply.started":"2021-09-06T07:32:36.729775Z","shell.execute_reply":"2021-09-06T07:32:36.734402Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"tensor([[1, 2],\n        [3, 4]]) torch.Size([2, 2])\n","output_type":"stream"}]},{"cell_type":"code","source":"# ================================================================== #\n#                         4. Input pipeline                           #\n# ================================================================== #\n\n# Download and construct CIFAR-10 dataset.\ntrain_dataset = torchvision.datasets.CIFAR10(root='../../data/',\n                                             train=True, \n                                             transform=transforms.ToTensor(),\n                                             download=True)","metadata":{"execution":{"iopub.status.busy":"2021-09-06T07:32:39.209141Z","iopub.execute_input":"2021-09-06T07:32:39.209828Z","iopub.status.idle":"2021-09-06T07:32:54.995055Z","shell.execute_reply.started":"2021-09-06T07:32:39.209772Z","shell.execute_reply":"2021-09-06T07:32:54.994281Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ../../data/cifar-10-python.tar.gz\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/170498071 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e49a7c1fd1314bef84ca03d296abf3c7"}},"metadata":{}},{"name":"stdout","text":"Extracting ../../data/cifar-10-python.tar.gz to ../../data/\n","output_type":"stream"}]},{"cell_type":"code","source":"print(train_dataset, len(train_dataset), type(train_dataset))","metadata":{"execution":{"iopub.status.busy":"2021-09-06T07:32:54.996196Z","iopub.execute_input":"2021-09-06T07:32:54.996579Z","iopub.status.idle":"2021-09-06T07:32:55.001448Z","shell.execute_reply.started":"2021-09-06T07:32:54.996550Z","shell.execute_reply":"2021-09-06T07:32:55.000522Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"Dataset CIFAR10\n    Number of datapoints: 50000\n    Root location: ../../data/\n    Split: Train\n    StandardTransform\nTransform: ToTensor() 50000 <class 'torchvision.datasets.cifar.CIFAR10'>\n","output_type":"stream"}]},{"cell_type":"code","source":"# Fetch one data pair (read data from disk).\nimage, label = train_dataset[0]\nprint (image.size())\nprint (label)","metadata":{"execution":{"iopub.status.busy":"2021-09-06T07:34:33.718347Z","iopub.execute_input":"2021-09-06T07:34:33.718740Z","iopub.status.idle":"2021-09-06T07:34:33.725745Z","shell.execute_reply.started":"2021-09-06T07:34:33.718708Z","shell.execute_reply":"2021-09-06T07:34:33.724683Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"torch.Size([3, 32, 32])\n6\n","output_type":"stream"}]},{"cell_type":"code","source":"# Data loader (this provides queues and threads in a very simple way).\ntrain_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n                                           batch_size=64, \n                                           shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2021-09-06T07:34:34.521271Z","iopub.execute_input":"2021-09-06T07:34:34.521981Z","iopub.status.idle":"2021-09-06T07:34:34.527714Z","shell.execute_reply.started":"2021-09-06T07:34:34.521923Z","shell.execute_reply":"2021-09-06T07:34:34.526688Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"train_loader","metadata":{"execution":{"iopub.status.busy":"2021-09-06T07:35:59.732995Z","iopub.execute_input":"2021-09-06T07:35:59.733346Z","iopub.status.idle":"2021-09-06T07:35:59.738968Z","shell.execute_reply.started":"2021-09-06T07:35:59.733317Z","shell.execute_reply":"2021-09-06T07:35:59.738006Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"<torch.utils.data.dataloader.DataLoader at 0x7f3d266230d0>"},"metadata":{}}]},{"cell_type":"code","source":"# When iteration starts, queue and thread start to load data from files.\ndata_iter = iter(train_loader)","metadata":{"execution":{"iopub.status.busy":"2021-09-06T07:34:55.217358Z","iopub.execute_input":"2021-09-06T07:34:55.217729Z","iopub.status.idle":"2021-09-06T07:34:55.221854Z","shell.execute_reply.started":"2021-09-06T07:34:55.217698Z","shell.execute_reply":"2021-09-06T07:34:55.220783Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"data_iter","metadata":{"execution":{"iopub.status.busy":"2021-09-06T07:35:14.727141Z","iopub.execute_input":"2021-09-06T07:35:14.727474Z","iopub.status.idle":"2021-09-06T07:35:14.735670Z","shell.execute_reply.started":"2021-09-06T07:35:14.727444Z","shell.execute_reply":"2021-09-06T07:35:14.734976Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"<torch.utils.data.dataloader._SingleProcessDataLoaderIter at 0x7f3d26623f50>"},"metadata":{}}]},{"cell_type":"code","source":"# Actual usage of the data loader is as below.\ncnt = 0\nfor images, labels in train_loader:\n    # Training code should be written here.\n    if cnt==0:\n        print(images.shape, labels.shape, type(images), type(labels))\n        print(labels)\n    cnt=cnt+1\n    pass","metadata":{"execution":{"iopub.status.busy":"2021-09-06T07:38:10.178764Z","iopub.execute_input":"2021-09-06T07:38:10.179102Z","iopub.status.idle":"2021-09-06T07:38:15.883554Z","shell.execute_reply.started":"2021-09-06T07:38:10.179071Z","shell.execute_reply":"2021-09-06T07:38:15.882610Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"torch.Size([64, 3, 32, 32]) torch.Size([64]) <class 'torch.Tensor'> <class 'torch.Tensor'>\ntensor([9, 1, 7, 8, 7, 1, 6, 8, 7, 2, 2, 8, 7, 8, 6, 5, 3, 4, 5, 4, 1, 8, 6, 8,\n        7, 4, 4, 7, 8, 0, 0, 4, 2, 0, 3, 5, 6, 7, 8, 4, 9, 7, 2, 6, 6, 4, 7, 6,\n        6, 0, 9, 8, 7, 7, 7, 7, 7, 4, 9, 3, 9, 8, 0, 9])\n","output_type":"stream"}]},{"cell_type":"code","source":"# ================================================================== #\n#                5. Input pipeline for custom dataset                 #\n# ================================================================== #\n\n# You should build your custom dataset as below.\nclass CustomDataset(torch.utils.data.Dataset):\n    def __init__(self):\n        # TODO\n        # 1. Initialize file paths or a list of file names. \n        pass\n    def __getitem__(self, index):\n        # TODO\n        # 1. Read one data from file (e.g. using numpy.fromfile, PIL.Image.open).\n        # 2. Preprocess the data (e.g. torchvision.Transform).\n        # 3. Return a data pair (e.g. image and label).\n        pass\n    def __len__(self):\n        # You should change 0 to the total size of your dataset.\n        return 0 \n","metadata":{"execution":{"iopub.status.busy":"2021-09-06T07:38:51.869939Z","iopub.execute_input":"2021-09-06T07:38:51.870612Z","iopub.status.idle":"2021-09-06T07:38:51.877497Z","shell.execute_reply.started":"2021-09-06T07:38:51.870568Z","shell.execute_reply":"2021-09-06T07:38:51.876686Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"# You can then use the prebuilt data loader. \n# custom_dataset = CustomDataset()\n# train_loader = torch.utils.data.DataLoader(dataset=custom_dataset,\n#                                            batch_size=64, \n#                                            shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2021-09-06T07:39:34.560937Z","iopub.execute_input":"2021-09-06T07:39:34.561410Z","iopub.status.idle":"2021-09-06T07:39:34.565017Z","shell.execute_reply.started":"2021-09-06T07:39:34.561380Z","shell.execute_reply":"2021-09-06T07:39:34.564036Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"# ================================================================== #\n#                        6. Pretrained model                         #\n# ================================================================== #\n\n# Download and load the pretrained ResNet-18.\nresnet = torchvision.models.resnet18(pretrained=True)","metadata":{"execution":{"iopub.status.busy":"2021-09-06T07:40:04.412353Z","iopub.execute_input":"2021-09-06T07:40:04.412899Z","iopub.status.idle":"2021-09-06T07:40:09.113932Z","shell.execute_reply.started":"2021-09-06T07:40:04.412853Z","shell.execute_reply":"2021-09-06T07:40:09.113006Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0.00/44.7M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b209245ab6ad48689a8652a65ff14c79"}},"metadata":{}}]},{"cell_type":"code","source":"# If you want to finetune only the top layer of the model, set as below.\nfor param in resnet.parameters():\n    param.requires_grad = False","metadata":{"execution":{"iopub.status.busy":"2021-09-06T07:41:30.338700Z","iopub.execute_input":"2021-09-06T07:41:30.339075Z","iopub.status.idle":"2021-09-06T07:41:30.343999Z","shell.execute_reply.started":"2021-09-06T07:41:30.339044Z","shell.execute_reply":"2021-09-06T07:41:30.342855Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"resnet","metadata":{"execution":{"iopub.status.busy":"2021-09-06T07:42:13.661778Z","iopub.execute_input":"2021-09-06T07:42:13.662104Z","iopub.status.idle":"2021-09-06T07:42:13.669164Z","shell.execute_reply.started":"2021-09-06T07:42:13.662078Z","shell.execute_reply":"2021-09-06T07:42:13.668168Z"},"trusted":true},"execution_count":38,"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"ResNet(\n  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu): ReLU(inplace=True)\n  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (layer1): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer2): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer3): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer4): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n  (fc): Linear(in_features=512, out_features=1000, bias=True)\n)"},"metadata":{}}]},{"cell_type":"code","source":"# Replace the top layer for finetuning.\nresnet.fc = nn.Linear(resnet.fc.in_features, 100)  # 100 is an example.","metadata":{"execution":{"iopub.status.busy":"2021-09-06T07:43:10.050985Z","iopub.execute_input":"2021-09-06T07:43:10.051307Z","iopub.status.idle":"2021-09-06T07:43:10.056010Z","shell.execute_reply.started":"2021-09-06T07:43:10.051278Z","shell.execute_reply":"2021-09-06T07:43:10.055327Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"resnet","metadata":{"execution":{"iopub.status.busy":"2021-09-06T07:43:13.003018Z","iopub.execute_input":"2021-09-06T07:43:13.003516Z","iopub.status.idle":"2021-09-06T07:43:13.010363Z","shell.execute_reply.started":"2021-09-06T07:43:13.003475Z","shell.execute_reply":"2021-09-06T07:43:13.009709Z"},"trusted":true},"execution_count":40,"outputs":[{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"ResNet(\n  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu): ReLU(inplace=True)\n  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (layer1): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer2): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer3): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer4): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n  (fc): Linear(in_features=512, out_features=100, bias=True)\n)"},"metadata":{}}]},{"cell_type":"code","source":"# Forward pass.\nimages = torch.randn(64, 3, 224, 224)\noutputs = resnet(images)\nprint (outputs.size())     # (64, 100)","metadata":{"execution":{"iopub.status.busy":"2021-09-06T07:44:11.214397Z","iopub.execute_input":"2021-09-06T07:44:11.215029Z","iopub.status.idle":"2021-09-06T07:44:14.511217Z","shell.execute_reply.started":"2021-09-06T07:44:11.214991Z","shell.execute_reply":"2021-09-06T07:44:14.510414Z"},"trusted":true},"execution_count":41,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n","output_type":"stream"},{"name":"stdout","text":"torch.Size([64, 100])\n","output_type":"stream"}]},{"cell_type":"code","source":"# ================================================================== #\n#                      7. Save and load the model                    #\n# ================================================================== #\n\n# Save and load the entire model.\ntorch.save(resnet, 'model.ckpt')\nmodel = torch.load('model.ckpt')","metadata":{"execution":{"iopub.status.busy":"2021-09-06T07:44:43.814305Z","iopub.execute_input":"2021-09-06T07:44:43.814799Z","iopub.status.idle":"2021-09-06T07:44:43.919983Z","shell.execute_reply.started":"2021-09-06T07:44:43.814755Z","shell.execute_reply":"2021-09-06T07:44:43.919204Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"# Save and load only the model parameters (recommended).\ntorch.save(resnet.state_dict(), 'params.ckpt')\nresnet.load_state_dict(torch.load('params.ckpt'))","metadata":{"execution":{"iopub.status.busy":"2021-09-06T07:44:54.944995Z","iopub.execute_input":"2021-09-06T07:44:54.945537Z","iopub.status.idle":"2021-09-06T07:44:55.062122Z","shell.execute_reply.started":"2021-09-06T07:44:54.945493Z","shell.execute_reply":"2021-09-06T07:44:55.061210Z"},"trusted":true},"execution_count":43,"outputs":[{"execution_count":43,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}