{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# https://github.com/manmeet3591/kaggle_experiments/tree/main/pytorch","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-09-08T10:26:04.744883Z","iopub.execute_input":"2021-09-08T10:26:04.745187Z","iopub.status.idle":"2021-09-08T10:26:04.749204Z","shell.execute_reply.started":"2021-09-08T10:26:04.745120Z","shell.execute_reply":"2021-09-08T10:26:04.748416Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!pip uninstall torch -y\n!pip uninstall torchvision -y\n!pip install torch \n!pip install torchvision\nimport torch \nimport torchvision\nimport torch.nn as nn\nimport numpy as np\nimport torchvision.transforms as transforms","metadata":{"execution":{"iopub.status.busy":"2021-09-08T10:26:06.038845Z","iopub.execute_input":"2021-09-08T10:26:06.039169Z","iopub.status.idle":"2021-09-08T10:27:25.611801Z","shell.execute_reply.started":"2021-09-08T10:26:06.039139Z","shell.execute_reply":"2021-09-08T10:27:25.610928Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Found existing installation: torch 1.7.0\nUninstalling torch-1.7.0:\n  Successfully uninstalled torch-1.7.0\n\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\nFound existing installation: torchvision 0.8.1\nUninstalling torchvision-0.8.1:\n  Successfully uninstalled torchvision-0.8.1\n\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\nCollecting torch\n  Downloading torch-1.9.0-cp37-cp37m-manylinux1_x86_64.whl (831.4 MB)\n\u001b[K     |████████████████████████████████| 831.4 MB 1.8 kB/s  eta 0:00:01     |█████▋                          | 145.6 MB 61.4 MB/s eta 0:00:12��█▊            | 512.3 MB 63.2 MB/s eta 0:00:06\n\u001b[?25hRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch) (3.7.4.3)\nInstalling collected packages: torch\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nfastai 2.2.7 requires torchvision<0.9,>=0.8, which is not installed.\neasyocr 1.3.2 requires torchvision>=0.5, which is not installed.\nallennlp 2.5.0 requires torchvision<0.10.0,>=0.8.1, which is not installed.\nkornia 0.5.5 requires numpy<=1.19, but you have numpy 1.19.5 which is incompatible.\nfastai 2.2.7 requires torch<1.8,>=1.7.0, but you have torch 1.9.0 which is incompatible.\nallennlp 2.5.0 requires torch<1.9.0,>=1.6.0, but you have torch 1.9.0 which is incompatible.\u001b[0m\nSuccessfully installed torch-1.9.0\n\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\nCollecting torchvision\n  Downloading torchvision-0.10.0-cp37-cp37m-manylinux1_x86_64.whl (22.1 MB)\n\u001b[K     |████████████████████████████████| 22.1 MB 2.1 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torchvision) (1.19.5)\nRequirement already satisfied: torch==1.9.0 in /opt/conda/lib/python3.7/site-packages (from torchvision) (1.9.0)\nRequirement already satisfied: pillow>=5.3.0 in /opt/conda/lib/python3.7/site-packages (from torchvision) (8.2.0)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch==1.9.0->torchvision) (3.7.4.3)\nInstalling collected packages: torchvision\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nfastai 2.2.7 requires torch<1.8,>=1.7.0, but you have torch 1.9.0 which is incompatible.\nfastai 2.2.7 requires torchvision<0.9,>=0.8, but you have torchvision 0.10.0 which is incompatible.\nallennlp 2.5.0 requires torch<1.9.0,>=1.6.0, but you have torch 1.9.0 which is incompatible.\nallennlp 2.5.0 requires torchvision<0.10.0,>=0.8.1, but you have torchvision 0.10.0 which is incompatible.\u001b[0m\nSuccessfully installed torchvision-0.10.0\n\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch \nimport torch.nn as nn\nimport torchvision\nimport torchvision.transforms as transforms","metadata":{"execution":{"iopub.status.busy":"2021-09-08T10:29:06.985987Z","iopub.execute_input":"2021-09-08T10:29:06.986370Z","iopub.status.idle":"2021-09-08T10:29:06.991295Z","shell.execute_reply.started":"2021-09-08T10:29:06.986340Z","shell.execute_reply":"2021-09-08T10:29:06.990268Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Device configuration\ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')","metadata":{"execution":{"iopub.status.busy":"2021-09-08T10:29:07.837281Z","iopub.execute_input":"2021-09-08T10:29:07.837634Z","iopub.status.idle":"2021-09-08T10:29:07.887373Z","shell.execute_reply.started":"2021-09-08T10:29:07.837601Z","shell.execute_reply":"2021-09-08T10:29:07.886497Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Hyper parameters\nnum_epochs = 5\nnum_classes = 10\nbatch_size = 100\nlearning_rate = 0.001","metadata":{"execution":{"iopub.status.busy":"2021-09-08T10:29:09.238679Z","iopub.execute_input":"2021-09-08T10:29:09.239050Z","iopub.status.idle":"2021-09-08T10:29:09.243493Z","shell.execute_reply.started":"2021-09-08T10:29:09.239022Z","shell.execute_reply":"2021-09-08T10:29:09.242318Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# MNIST dataset\ntrain_dataset = torchvision.datasets.MNIST(root='../../data/',\n                                           train=True, \n                                           transform=transforms.ToTensor(),\n                                           download=True)\n\ntest_dataset = torchvision.datasets.MNIST(root='../../data/',\n                                          train=False, \n                                          transform=transforms.ToTensor())","metadata":{"execution":{"iopub.status.busy":"2021-09-08T10:29:09.957590Z","iopub.execute_input":"2021-09-08T10:29:09.958028Z","iopub.status.idle":"2021-09-08T10:29:11.318058Z","shell.execute_reply.started":"2021-09-08T10:29:09.957986Z","shell.execute_reply":"2021-09-08T10:29:11.317181Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\nDownloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ../../data/MNIST/raw/train-images-idx3-ubyte.gz\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/9912422 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6b436e7a1e39485aa514071437b426ff"}},"metadata":{}},{"name":"stdout","text":"Extracting ../../data/MNIST/raw/train-images-idx3-ubyte.gz to ../../data/MNIST/raw\n\nDownloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\nDownloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ../../data/MNIST/raw/train-labels-idx1-ubyte.gz\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/28881 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7601ad01d1bf4a7597f286a3912e787a"}},"metadata":{}},{"name":"stdout","text":"Extracting ../../data/MNIST/raw/train-labels-idx1-ubyte.gz to ../../data/MNIST/raw\n\nDownloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\nDownloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ../../data/MNIST/raw/t10k-images-idx3-ubyte.gz\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1648877 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c7a3f62da485413f94791fcbcb4a4c06"}},"metadata":{}},{"name":"stdout","text":"Extracting ../../data/MNIST/raw/t10k-images-idx3-ubyte.gz to ../../data/MNIST/raw\n\nDownloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\nDownloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ../../data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4542 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bf89275dd8eb4393b05cd211fcdb371e"}},"metadata":{}},{"name":"stdout","text":"Extracting ../../data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ../../data/MNIST/raw\n\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:180.)\n  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n","output_type":"stream"}]},{"cell_type":"code","source":"# Data loader\ntrain_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n                                           batch_size=batch_size, \n                                           shuffle=True)\n\ntest_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n                                          batch_size=batch_size, \n                                          shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2021-09-08T10:29:11.319647Z","iopub.execute_input":"2021-09-08T10:29:11.320218Z","iopub.status.idle":"2021-09-08T10:29:11.325679Z","shell.execute_reply.started":"2021-09-08T10:29:11.320177Z","shell.execute_reply":"2021-09-08T10:29:11.324885Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Convolutional neural network (two convolutional layers)\nclass ConvNet(nn.Module):\n    def __init__(self, num_classes=10):\n        super(ConvNet, self).__init__()\n        self.layer1 = nn.Sequential(\n            nn.Conv2d(1, 16, kernel_size=5, stride=1, padding=2),\n            # https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html\n            nn.BatchNorm2d(16),\n            # https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm2d.html\n            nn.ReLU(),\n            # https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html\n            nn.MaxPool2d(kernel_size=2, stride=2))\n            # https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html\n        self.layer2 = nn.Sequential(\n            nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=2),\n            nn.BatchNorm2d(32),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2))\n        self.fc = nn.Linear(7*7*32, num_classes)\n        \n    def forward(self, x):\n        out = self.layer1(x)\n        out = self.layer2(out)\n        out = out.reshape(out.size(0), -1)\n        out = self.fc(out)\n        return out","metadata":{"execution":{"iopub.status.busy":"2021-09-08T10:29:11.802401Z","iopub.execute_input":"2021-09-08T10:29:11.802679Z","iopub.status.idle":"2021-09-08T10:29:11.811414Z","shell.execute_reply.started":"2021-09-08T10:29:11.802653Z","shell.execute_reply":"2021-09-08T10:29:11.810294Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"model = ConvNet(num_classes).to(device)","metadata":{"execution":{"iopub.status.busy":"2021-09-08T10:29:12.559122Z","iopub.execute_input":"2021-09-08T10:29:12.559430Z","iopub.status.idle":"2021-09-08T10:29:15.058081Z","shell.execute_reply.started":"2021-09-08T10:29:12.559403Z","shell.execute_reply":"2021-09-08T10:29:15.057189Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Loss and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)","metadata":{"execution":{"iopub.status.busy":"2021-09-08T10:29:15.870172Z","iopub.execute_input":"2021-09-08T10:29:15.870527Z","iopub.status.idle":"2021-09-08T10:29:15.876820Z","shell.execute_reply.started":"2021-09-08T10:29:15.870491Z","shell.execute_reply":"2021-09-08T10:29:15.876069Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# Train the model\ntotal_step = len(train_loader)\nfor epoch in range(num_epochs):\n    for i, (images, labels) in enumerate(train_loader):\n        images = images.to(device)\n        labels = labels.to(device)\n        \n        # Forward pass\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        \n        # Backward and optimize\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        if (i+1) % 100 == 0:\n            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))","metadata":{"execution":{"iopub.status.busy":"2021-09-08T10:29:16.683575Z","iopub.execute_input":"2021-09-08T10:29:16.683961Z","iopub.status.idle":"2021-09-08T10:29:46.488597Z","shell.execute_reply.started":"2021-09-08T10:29:16.683927Z","shell.execute_reply":"2021-09-08T10:29:46.487229Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n","output_type":"stream"},{"name":"stdout","text":"Epoch [1/5], Step [100/600], Loss: 0.1196\nEpoch [1/5], Step [200/600], Loss: 0.0819\nEpoch [1/5], Step [300/600], Loss: 0.0759\nEpoch [1/5], Step [400/600], Loss: 0.0340\nEpoch [1/5], Step [500/600], Loss: 0.0314\nEpoch [1/5], Step [600/600], Loss: 0.0456\nEpoch [2/5], Step [100/600], Loss: 0.0127\nEpoch [2/5], Step [200/600], Loss: 0.0712\nEpoch [2/5], Step [300/600], Loss: 0.0228\nEpoch [2/5], Step [400/600], Loss: 0.0739\nEpoch [2/5], Step [500/600], Loss: 0.0466\nEpoch [2/5], Step [600/600], Loss: 0.0196\nEpoch [3/5], Step [100/600], Loss: 0.0121\nEpoch [3/5], Step [200/600], Loss: 0.0255\nEpoch [3/5], Step [300/600], Loss: 0.0441\nEpoch [3/5], Step [400/600], Loss: 0.0237\nEpoch [3/5], Step [500/600], Loss: 0.0625\nEpoch [3/5], Step [600/600], Loss: 0.0100\nEpoch [4/5], Step [100/600], Loss: 0.0026\nEpoch [4/5], Step [200/600], Loss: 0.0019\nEpoch [4/5], Step [300/600], Loss: 0.0587\nEpoch [4/5], Step [400/600], Loss: 0.0677\nEpoch [4/5], Step [500/600], Loss: 0.0296\nEpoch [4/5], Step [600/600], Loss: 0.0014\nEpoch [5/5], Step [100/600], Loss: 0.0208\nEpoch [5/5], Step [200/600], Loss: 0.0585\nEpoch [5/5], Step [300/600], Loss: 0.0411\nEpoch [5/5], Step [400/600], Loss: 0.0094\nEpoch [5/5], Step [500/600], Loss: 0.0028\nEpoch [5/5], Step [600/600], Loss: 0.0023\n","output_type":"stream"}]},{"cell_type":"code","source":"# Test the model\n# https://discuss.pytorch.org/t/model-eval-vs-with-torch-no-grad/19615\nmodel.eval()  # eval mode (batchnorm uses moving mean/variance instead of mini-batch mean/variance)","metadata":{"execution":{"iopub.status.busy":"2021-09-08T10:36:38.980305Z","iopub.execute_input":"2021-09-08T10:36:38.980754Z","iopub.status.idle":"2021-09-08T10:36:38.989149Z","shell.execute_reply.started":"2021-09-08T10:36:38.980713Z","shell.execute_reply":"2021-09-08T10:36:38.987569Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"ConvNet(\n  (layer1): Sequential(\n    (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU()\n    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (layer2): Sequential(\n    (0): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU()\n    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (fc): Linear(in_features=1568, out_features=10, bias=True)\n)"},"metadata":{}}]},{"cell_type":"code","source":"with torch.no_grad():\n    correct = 0\n    total = 0\n    print(len(test_loader))\n    for images, labels in test_loader:\n        images = images.to(device)\n        labels = labels.to(device)\n        #print(labels)\n        outputs = model(images)\n        #print(torch.max(outputs.data))\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\n    print('Test Accuracy of the model on the 10000 test images: {} %'.format(100 * correct / total))","metadata":{"execution":{"iopub.status.busy":"2021-09-08T10:40:10.385222Z","iopub.execute_input":"2021-09-08T10:40:10.385557Z","iopub.status.idle":"2021-09-08T10:40:11.153067Z","shell.execute_reply.started":"2021-09-08T10:40:10.385524Z","shell.execute_reply":"2021-09-08T10:40:11.152051Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"100\nTest Accuracy of the model on the 10000 test images: 98.97 %\n","output_type":"stream"}]},{"cell_type":"code","source":"# Save the model checkpoint\ntorch.save(model.state_dict(), 'model.ckpt')","metadata":{"execution":{"iopub.status.busy":"2021-09-08T10:40:58.811523Z","iopub.execute_input":"2021-09-08T10:40:58.811898Z","iopub.status.idle":"2021-09-08T10:40:58.821029Z","shell.execute_reply.started":"2021-09-08T10:40:58.811862Z","shell.execute_reply":"2021-09-08T10:40:58.820058Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}