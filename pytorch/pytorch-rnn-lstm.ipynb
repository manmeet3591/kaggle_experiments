{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# https://github.com/yunjey/pytorch-tutorial/blob/master/tutorials/02-intermediate/recurrent_neural_network/main.py#L39-L58","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-09-09T04:38:22.082852Z","iopub.execute_input":"2021-09-09T04:38:22.083220Z","iopub.status.idle":"2021-09-09T04:38:22.088416Z","shell.execute_reply.started":"2021-09-09T04:38:22.083139Z","shell.execute_reply":"2021-09-09T04:38:22.087562Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!pip uninstall torch -y\n!pip uninstall torchvision -y\n!pip install torch \n!pip install torchvision\nimport torch \nimport torchvision\nimport torch.nn as nn\nimport numpy as np\nimport torchvision.transforms as transforms","metadata":{"execution":{"iopub.status.busy":"2021-09-09T04:38:22.699661Z","iopub.execute_input":"2021-09-09T04:38:22.699976Z","iopub.status.idle":"2021-09-09T04:39:50.147286Z","shell.execute_reply.started":"2021-09-09T04:38:22.699946Z","shell.execute_reply":"2021-09-09T04:39:50.146256Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Found existing installation: torch 1.7.0\nUninstalling torch-1.7.0:\n  Successfully uninstalled torch-1.7.0\n\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\nFound existing installation: torchvision 0.8.1\nUninstalling torchvision-0.8.1:\n  Successfully uninstalled torchvision-0.8.1\n\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\nCollecting torch\n  Downloading torch-1.9.0-cp37-cp37m-manylinux1_x86_64.whl (831.4 MB)\n\u001b[K     |████████████████████████████████| 831.4 MB 1.7 kB/s  eta 0:00:01     |███████▉                        | 203.8 MB 56.1 MB/s eta 0:00:12     |█████████                       | 235.5 MB 43.4 MB/s eta 0:00:14     |██████████▉                     | 281.2 MB 69.5 MB/s eta 0:00:08     |████████████▏                   | 315.1 MB 69.5 MB/s eta 0:00:08     |█████████████████████           | 544.2 MB 63.5 MB/s eta 0:00:05     |██████████████████████████      | 675.9 MB 63.2 MB/s eta 0:00:03     |██████████████████████████▎     | 684.0 MB 63.2 MB/s eta 0:00:03     |███████████████████████████▋    | 717.9 MB 43.0 MB/s eta 0:00:03     |████████████████████████████▍   | 738.7 MB 63.7 MB/s eta 0:00:02     |█████████████████████████████   | 754.6 MB 63.7 MB/s eta 0:00:02\n\u001b[?25hRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch) (3.7.4.3)\nInstalling collected packages: torch\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nfastai 2.2.7 requires torchvision<0.9,>=0.8, which is not installed.\neasyocr 1.3.2 requires torchvision>=0.5, which is not installed.\nallennlp 2.5.0 requires torchvision<0.10.0,>=0.8.1, which is not installed.\nkornia 0.5.5 requires numpy<=1.19, but you have numpy 1.19.5 which is incompatible.\nfastai 2.2.7 requires torch<1.8,>=1.7.0, but you have torch 1.9.0 which is incompatible.\nallennlp 2.5.0 requires torch<1.9.0,>=1.6.0, but you have torch 1.9.0 which is incompatible.\u001b[0m\nSuccessfully installed torch-1.9.0\n\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\nCollecting torchvision\n  Downloading torchvision-0.10.0-cp37-cp37m-manylinux1_x86_64.whl (22.1 MB)\n\u001b[K     |████████████████████████████████| 22.1 MB 4.4 MB/s eta 0:00:01     |██████████████████▌             | 12.8 MB 4.4 MB/s eta 0:00:03\n\u001b[?25hRequirement already satisfied: torch==1.9.0 in /opt/conda/lib/python3.7/site-packages (from torchvision) (1.9.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torchvision) (1.19.5)\nRequirement already satisfied: pillow>=5.3.0 in /opt/conda/lib/python3.7/site-packages (from torchvision) (8.2.0)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch==1.9.0->torchvision) (3.7.4.3)\nInstalling collected packages: torchvision\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nfastai 2.2.7 requires torch<1.8,>=1.7.0, but you have torch 1.9.0 which is incompatible.\nfastai 2.2.7 requires torchvision<0.9,>=0.8, but you have torchvision 0.10.0 which is incompatible.\nallennlp 2.5.0 requires torch<1.9.0,>=1.6.0, but you have torch 1.9.0 which is incompatible.\nallennlp 2.5.0 requires torchvision<0.10.0,>=0.8.1, but you have torchvision 0.10.0 which is incompatible.\u001b[0m\nSuccessfully installed torchvision-0.10.0\n\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch \nimport torch.nn as nn\nimport torchvision\nimport torchvision.transforms as transforms","metadata":{"execution":{"iopub.status.busy":"2021-09-09T04:39:50.148792Z","iopub.execute_input":"2021-09-09T04:39:50.149171Z","iopub.status.idle":"2021-09-09T04:39:50.156178Z","shell.execute_reply.started":"2021-09-09T04:39:50.149128Z","shell.execute_reply":"2021-09-09T04:39:50.154997Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Device configuration\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"execution":{"iopub.status.busy":"2021-09-09T04:39:50.158652Z","iopub.execute_input":"2021-09-09T04:39:50.159252Z","iopub.status.idle":"2021-09-09T04:39:50.207061Z","shell.execute_reply.started":"2021-09-09T04:39:50.159212Z","shell.execute_reply":"2021-09-09T04:39:50.205836Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Hyper-parameters\nsequence_length = 28\ninput_size = 28\nhidden_size = 128\nnum_layers = 2\nnum_classes = 10\nbatch_size = 100\nnum_epochs = 2\nlearning_rate = 0.01","metadata":{"execution":{"iopub.status.busy":"2021-09-09T04:39:50.210722Z","iopub.execute_input":"2021-09-09T04:39:50.211040Z","iopub.status.idle":"2021-09-09T04:39:50.217839Z","shell.execute_reply.started":"2021-09-09T04:39:50.211014Z","shell.execute_reply":"2021-09-09T04:39:50.216943Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# MNIST dataset\ntrain_dataset = torchvision.datasets.MNIST(root='../../data/',\n                                           train=True, \n                                           transform=transforms.ToTensor(),\n                                           download=True)\n\ntest_dataset = torchvision.datasets.MNIST(root='../../data/',\n                                          train=False, \n                                          transform=transforms.ToTensor())\n\n# Data loader\ntrain_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n                                           batch_size=batch_size, \n                                           shuffle=True)\n\ntest_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n                                          batch_size=batch_size, \n                                          shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2021-09-09T04:39:50.219060Z","iopub.execute_input":"2021-09-09T04:39:50.219568Z","iopub.status.idle":"2021-09-09T04:39:51.348655Z","shell.execute_reply.started":"2021-09-09T04:39:50.219526Z","shell.execute_reply":"2021-09-09T04:39:51.347684Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\nDownloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ../../data/MNIST/raw/train-images-idx3-ubyte.gz\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/9912422 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7dad2bf7c5ba481e984cbba9f1e087fa"}},"metadata":{}},{"name":"stdout","text":"Extracting ../../data/MNIST/raw/train-images-idx3-ubyte.gz to ../../data/MNIST/raw\n\nDownloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\nDownloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ../../data/MNIST/raw/train-labels-idx1-ubyte.gz\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/28881 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bf08ce0e3d2e426daa29c792e4c8a5e5"}},"metadata":{}},{"name":"stdout","text":"Extracting ../../data/MNIST/raw/train-labels-idx1-ubyte.gz to ../../data/MNIST/raw\n\nDownloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\nDownloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ../../data/MNIST/raw/t10k-images-idx3-ubyte.gz\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1648877 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c48ac878cb304be2b013c794d622701f"}},"metadata":{}},{"name":"stdout","text":"Extracting ../../data/MNIST/raw/t10k-images-idx3-ubyte.gz to ../../data/MNIST/raw\n\nDownloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\nDownloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ../../data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4542 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b433c98de8974e8caf5f01a530014ca2"}},"metadata":{}},{"name":"stdout","text":"Extracting ../../data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ../../data/MNIST/raw\n\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:180.)\n  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n","output_type":"stream"}]},{"cell_type":"code","source":"# Recurrent neural network (many-to-one)\nclass RNN(nn.Module):\n    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n        super(RNN, self).__init__()\n        self.hidden_size = hidden_size\n        self.num_layers = num_layers\n        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n        # https://adventuresinmachinelearning.com/keras-lstm-tutorial/\n        # input_size – The number of expected features in the input x\n        # hidden_size – The number of features in the hidden state \n        # num_layers – Number of recurrent layers. E.g., setting num_layers=2 would mean stacking two LSTMs together to form a stacked LSTM, with the second LSTM taking in outputs of the first LSTM and computing the final results. Default: 1\n        # https://adventuresinmachinelearning.com/keras-lstm-tutorial/\n        # \n        self.fc = nn.Linear(hidden_size, num_classes)\n    \n    def forward(self, x):\n        # Set initial hidden and cell states \n        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) \n        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n        \n        # Forward propagate LSTM\n        out, _ = self.lstm(x, (h0, c0))  # out: tensor of shape (batch_size, seq_length, hidden_size)\n        \n        # Decode the hidden state of the last time step\n        out = self.fc(out[:, -1, :])\n        return out","metadata":{"execution":{"iopub.status.busy":"2021-09-09T04:39:51.350194Z","iopub.execute_input":"2021-09-09T04:39:51.350664Z","iopub.status.idle":"2021-09-09T04:39:51.358692Z","shell.execute_reply.started":"2021-09-09T04:39:51.350626Z","shell.execute_reply":"2021-09-09T04:39:51.357897Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"model = RNN(input_size, hidden_size, num_layers, num_classes).to(device)","metadata":{"execution":{"iopub.status.busy":"2021-09-09T04:39:51.359974Z","iopub.execute_input":"2021-09-09T04:39:51.360526Z","iopub.status.idle":"2021-09-09T04:39:53.956214Z","shell.execute_reply.started":"2021-09-09T04:39:51.360491Z","shell.execute_reply":"2021-09-09T04:39:53.955367Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Loss and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)","metadata":{"execution":{"iopub.status.busy":"2021-09-09T04:39:53.958043Z","iopub.execute_input":"2021-09-09T04:39:53.958346Z","iopub.status.idle":"2021-09-09T04:39:53.962034Z","shell.execute_reply.started":"2021-09-09T04:39:53.958316Z","shell.execute_reply":"2021-09-09T04:39:53.961261Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Train the model\ntotal_step = len(train_loader)\nfor epoch in range(num_epochs):\n    for i, (images, labels) in enumerate(train_loader):\n        images = images.reshape(-1, sequence_length, input_size).to(device)\n        labels = labels.to(device)\n        \n        # Forward pass\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        \n        # Backward and optimize\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        if (i+1) % 100 == 0:\n            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))","metadata":{"execution":{"iopub.status.busy":"2021-09-09T04:43:18.792911Z","iopub.execute_input":"2021-09-09T04:43:18.793261Z","iopub.status.idle":"2021-09-09T04:43:32.329845Z","shell.execute_reply.started":"2021-09-09T04:43:18.793230Z","shell.execute_reply":"2021-09-09T04:43:32.329086Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Epoch [1/2], Step [100/600], Loss: 0.5033\nEpoch [1/2], Step [200/600], Loss: 0.3397\nEpoch [1/2], Step [300/600], Loss: 0.1725\nEpoch [1/2], Step [400/600], Loss: 0.0467\nEpoch [1/2], Step [500/600], Loss: 0.0944\nEpoch [1/2], Step [600/600], Loss: 0.0649\nEpoch [2/2], Step [100/600], Loss: 0.1007\nEpoch [2/2], Step [200/600], Loss: 0.0695\nEpoch [2/2], Step [300/600], Loss: 0.1296\nEpoch [2/2], Step [400/600], Loss: 0.1223\nEpoch [2/2], Step [500/600], Loss: 0.0959\nEpoch [2/2], Step [600/600], Loss: 0.0757\n","output_type":"stream"}]},{"cell_type":"code","source":"# Save the model checkpoint\ntorch.save(model.state_dict(), 'model.ckpt')","metadata":{"execution":{"iopub.status.busy":"2021-09-09T04:44:35.402954Z","iopub.execute_input":"2021-09-09T04:44:35.403303Z","iopub.status.idle":"2021-09-09T04:44:35.412540Z","shell.execute_reply.started":"2021-09-09T04:44:35.403273Z","shell.execute_reply":"2021-09-09T04:44:35.411356Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}