{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# https://github.com/yunjey/pytorch-tutorial/blob/master/tutorials/01-basics/logistic_regression/main.py#L33-L34","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-09-08T02:40:50.326014Z","iopub.execute_input":"2021-09-08T02:40:50.326411Z","iopub.status.idle":"2021-09-08T02:40:50.332067Z","shell.execute_reply.started":"2021-09-08T02:40:50.326323Z","shell.execute_reply":"2021-09-08T02:40:50.331065Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!pip uninstall torch -y\n!pip uninstall torchvision -y\n!pip install torch \n!pip install torchvision\nimport torch \nimport torchvision\nimport torch.nn as nn\nimport numpy as np\nimport torchvision.transforms as transforms","metadata":{"execution":{"iopub.status.busy":"2021-09-08T02:40:57.801252Z","iopub.execute_input":"2021-09-08T02:40:57.801648Z","iopub.status.idle":"2021-09-08T02:42:34.633459Z","shell.execute_reply.started":"2021-09-08T02:40:57.801612Z","shell.execute_reply":"2021-09-08T02:42:34.632643Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Found existing installation: torch 1.7.0\nUninstalling torch-1.7.0:\n  Successfully uninstalled torch-1.7.0\n\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\nFound existing installation: torchvision 0.8.1\nUninstalling torchvision-0.8.1:\n  Successfully uninstalled torchvision-0.8.1\n\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\nCollecting torch\n  Downloading torch-1.9.0-cp37-cp37m-manylinux1_x86_64.whl (831.4 MB)\n\u001b[K     |████████████████████████████████| 831.4 MB 2.2 kB/s  eta 0:00:01     |█████████▊                      | 252.1 MB 59.0 MB/s eta 0:00:10     |█████████▊                      | 253.8 MB 59.0 MB/s eta 0:00:10     |██████████                      | 260.9 MB 59.0 MB/s eta 0:00:10     |███████████████▊                | 407.3 MB 6.6 MB/s eta 0:01:05�██████████▊        | 616.2 MB 22.9 MB/s eta 0:00:10     |███████████████████████▉        | 618.2 MB 1.7 MB/s eta 0:02:03     |███████████████████████▉        | 619.0 MB 1.7 MB/s eta 0:02:03��██████████████████████▉        | 619.3 MB 1.7 MB/s eta 0:02:03     |████████████████████████        | 621.3 MB 1.7 MB/s eta 0:02:01     |████████████████████████        | 621.9 MB 1.7 MB/s eta 0:02:01     |████████████████████████        | 622.5 MB 1.7 MB/s eta 0:02:01     |████████████████████████▏       | 628.1 MB 1.7 MB/s eta 0:01:58     |████████████████████████▎       | 629.4 MB 1.7 MB/s eta 0:01:57     |████████████████████████▎       | 631.8 MB 1.7 MB/s eta 0:01:55     |████████████████████████████▌   | 740.4 MB 54.1 MB/s eta 0:00:02\n\u001b[?25hRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch) (3.7.4.3)\nInstalling collected packages: torch\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nfastai 2.2.7 requires torchvision<0.9,>=0.8, which is not installed.\neasyocr 1.3.2 requires torchvision>=0.5, which is not installed.\nallennlp 2.5.0 requires torchvision<0.10.0,>=0.8.1, which is not installed.\nkornia 0.5.5 requires numpy<=1.19, but you have numpy 1.19.5 which is incompatible.\nfastai 2.2.7 requires torch<1.8,>=1.7.0, but you have torch 1.9.0 which is incompatible.\nallennlp 2.5.0 requires torch<1.9.0,>=1.6.0, but you have torch 1.9.0 which is incompatible.\u001b[0m\nSuccessfully installed torch-1.9.0\n\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\nCollecting torchvision\n  Downloading torchvision-0.10.0-cp37-cp37m-manylinux1_x86_64.whl (22.1 MB)\n\u001b[K     |████████████████████████████████| 22.1 MB 290 kB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torchvision) (1.19.5)\nRequirement already satisfied: torch==1.9.0 in /opt/conda/lib/python3.7/site-packages (from torchvision) (1.9.0)\nRequirement already satisfied: pillow>=5.3.0 in /opt/conda/lib/python3.7/site-packages (from torchvision) (8.2.0)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch==1.9.0->torchvision) (3.7.4.3)\nInstalling collected packages: torchvision\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nfastai 2.2.7 requires torch<1.8,>=1.7.0, but you have torch 1.9.0 which is incompatible.\nfastai 2.2.7 requires torchvision<0.9,>=0.8, but you have torchvision 0.10.0 which is incompatible.\nallennlp 2.5.0 requires torch<1.9.0,>=1.6.0, but you have torch 1.9.0 which is incompatible.\nallennlp 2.5.0 requires torchvision<0.10.0,>=0.8.1, but you have torchvision 0.10.0 which is incompatible.\u001b[0m\nSuccessfully installed torchvision-0.10.0\n\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torchvision\nimport torchvision.transforms as transforms","metadata":{"execution":{"iopub.status.busy":"2021-09-08T02:43:16.730722Z","iopub.execute_input":"2021-09-08T02:43:16.731074Z","iopub.status.idle":"2021-09-08T02:43:16.735535Z","shell.execute_reply.started":"2021-09-08T02:43:16.731042Z","shell.execute_reply":"2021-09-08T02:43:16.734724Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Hyper-parameters \ninput_size = 28 * 28    # 784\nnum_classes = 10\nnum_epochs = 5\nbatch_size = 100\nlearning_rate = 0.001","metadata":{"execution":{"iopub.status.busy":"2021-09-08T02:43:18.064275Z","iopub.execute_input":"2021-09-08T02:43:18.064639Z","iopub.status.idle":"2021-09-08T02:43:18.069477Z","shell.execute_reply.started":"2021-09-08T02:43:18.064608Z","shell.execute_reply":"2021-09-08T02:43:18.068639Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# MNIST dataset (images and labels)\ntrain_dataset = torchvision.datasets.MNIST(root='../../data', \n                                           train=True, \n                                           transform=transforms.ToTensor(),\n                                           download=True)\n\ntest_dataset = torchvision.datasets.MNIST(root='../../data', \n                                          train=False, \n                                          transform=transforms.ToTensor())","metadata":{"execution":{"iopub.status.busy":"2021-09-08T02:44:38.147169Z","iopub.execute_input":"2021-09-08T02:44:38.147500Z","iopub.status.idle":"2021-09-08T02:44:40.135370Z","shell.execute_reply.started":"2021-09-08T02:44:38.147469Z","shell.execute_reply":"2021-09-08T02:44:40.134415Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\nDownloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ../../data/MNIST/raw/train-images-idx3-ubyte.gz\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/9912422 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cf0d1b9d36464a638dd6e872e3d73c03"}},"metadata":{}},{"name":"stdout","text":"Extracting ../../data/MNIST/raw/train-images-idx3-ubyte.gz to ../../data/MNIST/raw\n\nDownloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\nDownloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ../../data/MNIST/raw/train-labels-idx1-ubyte.gz\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/28881 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eafceda1aec24f69b41c5615f407663f"}},"metadata":{}},{"name":"stdout","text":"Extracting ../../data/MNIST/raw/train-labels-idx1-ubyte.gz to ../../data/MNIST/raw\n\nDownloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\nDownloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ../../data/MNIST/raw/t10k-images-idx3-ubyte.gz\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1648877 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4b972df098e349dbb81b680daecb1995"}},"metadata":{}},{"name":"stdout","text":"Extracting ../../data/MNIST/raw/t10k-images-idx3-ubyte.gz to ../../data/MNIST/raw\n\nDownloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\nDownloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ../../data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4542 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ba79ff0d706b42f4b7f11adc73aca2bb"}},"metadata":{}},{"name":"stdout","text":"Extracting ../../data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ../../data/MNIST/raw\n\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:180.)\n  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n","output_type":"stream"}]},{"cell_type":"code","source":"# Data loader (input pipeline)\ntrain_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n                                           batch_size=batch_size, \n                                           shuffle=True)\n\ntest_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n                                          batch_size=batch_size, \n                                          shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2021-09-08T02:44:43.307587Z","iopub.execute_input":"2021-09-08T02:44:43.307950Z","iopub.status.idle":"2021-09-08T02:44:43.313169Z","shell.execute_reply.started":"2021-09-08T02:44:43.307919Z","shell.execute_reply":"2021-09-08T02:44:43.312203Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Logistic regression model\nmodel = nn.Linear(input_size, num_classes)","metadata":{"execution":{"iopub.status.busy":"2021-09-08T02:44:44.887248Z","iopub.execute_input":"2021-09-08T02:44:44.887570Z","iopub.status.idle":"2021-09-08T02:44:44.892395Z","shell.execute_reply.started":"2021-09-08T02:44:44.887540Z","shell.execute_reply":"2021-09-08T02:44:44.891437Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Loss and optimizer\n# nn.CrossEntropyLoss() computes softmax internally\ncriterion = nn.CrossEntropyLoss()  \noptimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)  ","metadata":{"execution":{"iopub.status.busy":"2021-09-08T02:44:46.056220Z","iopub.execute_input":"2021-09-08T02:44:46.056543Z","iopub.status.idle":"2021-09-08T02:44:46.060563Z","shell.execute_reply.started":"2021-09-08T02:44:46.056513Z","shell.execute_reply":"2021-09-08T02:44:46.059792Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Train the model\ntotal_step = len(train_loader)\nfor epoch in range(num_epochs):\n    for i, (images, labels) in enumerate(train_loader):\n        if i==0 and epoch==0:\n            print(images,labels, images.shape,labels.shape)\n        # Reshape images to (batch_size, input_size)\n        images = images.reshape(-1, input_size)\n        if i==0 and epoch==0:\n            print(images,labels, images.shape,labels.shape)\n        # Forward pass\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        \n        # Backward and optimize\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        if (i+1) % 100 == 0:\n            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))","metadata":{"execution":{"iopub.status.busy":"2021-09-08T02:44:53.492936Z","iopub.execute_input":"2021-09-08T02:44:53.493258Z","iopub.status.idle":"2021-09-08T02:45:16.058409Z","shell.execute_reply.started":"2021-09-08T02:44:53.493230Z","shell.execute_reply":"2021-09-08T02:45:16.057446Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n          [0., 0., 0.,  ..., 0., 0., 0.],\n          [0., 0., 0.,  ..., 0., 0., 0.],\n          ...,\n          [0., 0., 0.,  ..., 0., 0., 0.],\n          [0., 0., 0.,  ..., 0., 0., 0.],\n          [0., 0., 0.,  ..., 0., 0., 0.]]],\n\n\n        [[[0., 0., 0.,  ..., 0., 0., 0.],\n          [0., 0., 0.,  ..., 0., 0., 0.],\n          [0., 0., 0.,  ..., 0., 0., 0.],\n          ...,\n          [0., 0., 0.,  ..., 0., 0., 0.],\n          [0., 0., 0.,  ..., 0., 0., 0.],\n          [0., 0., 0.,  ..., 0., 0., 0.]]],\n\n\n        [[[0., 0., 0.,  ..., 0., 0., 0.],\n          [0., 0., 0.,  ..., 0., 0., 0.],\n          [0., 0., 0.,  ..., 0., 0., 0.],\n          ...,\n          [0., 0., 0.,  ..., 0., 0., 0.],\n          [0., 0., 0.,  ..., 0., 0., 0.],\n          [0., 0., 0.,  ..., 0., 0., 0.]]],\n\n\n        ...,\n\n\n        [[[0., 0., 0.,  ..., 0., 0., 0.],\n          [0., 0., 0.,  ..., 0., 0., 0.],\n          [0., 0., 0.,  ..., 0., 0., 0.],\n          ...,\n          [0., 0., 0.,  ..., 0., 0., 0.],\n          [0., 0., 0.,  ..., 0., 0., 0.],\n          [0., 0., 0.,  ..., 0., 0., 0.]]],\n\n\n        [[[0., 0., 0.,  ..., 0., 0., 0.],\n          [0., 0., 0.,  ..., 0., 0., 0.],\n          [0., 0., 0.,  ..., 0., 0., 0.],\n          ...,\n          [0., 0., 0.,  ..., 0., 0., 0.],\n          [0., 0., 0.,  ..., 0., 0., 0.],\n          [0., 0., 0.,  ..., 0., 0., 0.]]],\n\n\n        [[[0., 0., 0.,  ..., 0., 0., 0.],\n          [0., 0., 0.,  ..., 0., 0., 0.],\n          [0., 0., 0.,  ..., 0., 0., 0.],\n          ...,\n          [0., 0., 0.,  ..., 0., 0., 0.],\n          [0., 0., 0.,  ..., 0., 0., 0.],\n          [0., 0., 0.,  ..., 0., 0., 0.]]]]) tensor([4, 7, 8, 7, 6, 6, 0, 6, 4, 5, 6, 2, 6, 2, 6, 1, 7, 0, 5, 6, 0, 4, 0, 4,\n        8, 7, 7, 4, 4, 7, 7, 8, 9, 9, 5, 1, 8, 5, 1, 1, 9, 6, 2, 5, 1, 3, 3, 4,\n        2, 9, 4, 7, 2, 8, 0, 0, 8, 5, 3, 1, 3, 8, 2, 4, 1, 7, 9, 1, 2, 1, 9, 2,\n        7, 2, 2, 5, 9, 2, 3, 6, 0, 7, 3, 0, 1, 9, 8, 3, 4, 4, 6, 9, 1, 0, 8, 2,\n        9, 6, 8, 1]) torch.Size([100, 1, 28, 28]) torch.Size([100])\ntensor([[0., 0., 0.,  ..., 0., 0., 0.],\n        [0., 0., 0.,  ..., 0., 0., 0.],\n        [0., 0., 0.,  ..., 0., 0., 0.],\n        ...,\n        [0., 0., 0.,  ..., 0., 0., 0.],\n        [0., 0., 0.,  ..., 0., 0., 0.],\n        [0., 0., 0.,  ..., 0., 0., 0.]]) tensor([4, 7, 8, 7, 6, 6, 0, 6, 4, 5, 6, 2, 6, 2, 6, 1, 7, 0, 5, 6, 0, 4, 0, 4,\n        8, 7, 7, 4, 4, 7, 7, 8, 9, 9, 5, 1, 8, 5, 1, 1, 9, 6, 2, 5, 1, 3, 3, 4,\n        2, 9, 4, 7, 2, 8, 0, 0, 8, 5, 3, 1, 3, 8, 2, 4, 1, 7, 9, 1, 2, 1, 9, 2,\n        7, 2, 2, 5, 9, 2, 3, 6, 0, 7, 3, 0, 1, 9, 8, 3, 4, 4, 6, 9, 1, 0, 8, 2,\n        9, 6, 8, 1]) torch.Size([100, 784]) torch.Size([100])\nEpoch [1/5], Step [100/600], Loss: 2.2497\nEpoch [1/5], Step [200/600], Loss: 2.1364\nEpoch [1/5], Step [300/600], Loss: 2.0507\nEpoch [1/5], Step [400/600], Loss: 1.9360\nEpoch [1/5], Step [500/600], Loss: 1.8457\nEpoch [1/5], Step [600/600], Loss: 1.7552\nEpoch [2/5], Step [100/600], Loss: 1.7538\nEpoch [2/5], Step [200/600], Loss: 1.7109\nEpoch [2/5], Step [300/600], Loss: 1.5759\nEpoch [2/5], Step [400/600], Loss: 1.5742\nEpoch [2/5], Step [500/600], Loss: 1.5269\nEpoch [2/5], Step [600/600], Loss: 1.5405\nEpoch [3/5], Step [100/600], Loss: 1.3868\nEpoch [3/5], Step [200/600], Loss: 1.4044\nEpoch [3/5], Step [300/600], Loss: 1.3773\nEpoch [3/5], Step [400/600], Loss: 1.3772\nEpoch [3/5], Step [500/600], Loss: 1.2727\nEpoch [3/5], Step [600/600], Loss: 1.3349\nEpoch [4/5], Step [100/600], Loss: 1.2753\nEpoch [4/5], Step [200/600], Loss: 1.2182\nEpoch [4/5], Step [300/600], Loss: 1.1243\nEpoch [4/5], Step [400/600], Loss: 1.1769\nEpoch [4/5], Step [500/600], Loss: 1.0740\nEpoch [4/5], Step [600/600], Loss: 1.1888\nEpoch [5/5], Step [100/600], Loss: 1.0602\nEpoch [5/5], Step [200/600], Loss: 1.0825\nEpoch [5/5], Step [300/600], Loss: 1.0673\nEpoch [5/5], Step [400/600], Loss: 1.0706\nEpoch [5/5], Step [500/600], Loss: 1.0583\nEpoch [5/5], Step [600/600], Loss: 0.8901\n","output_type":"stream"}]},{"cell_type":"code","source":"# Test the model\n# In test phase, we don't need to compute gradients (for memory efficiency)\nwith torch.no_grad():\n    correct = 0\n    total = 0\n    for images, labels in test_loader:\n        images = images.reshape(-1, input_size)\n        outputs = model(images)\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum()\n\n    print('Accuracy of the model on the 10000 test images: {} %'.format(100 * correct / total))","metadata":{"execution":{"iopub.status.busy":"2021-09-08T02:45:16.059879Z","iopub.execute_input":"2021-09-08T02:45:16.060258Z","iopub.status.idle":"2021-09-08T02:45:16.766786Z","shell.execute_reply.started":"2021-09-08T02:45:16.060196Z","shell.execute_reply":"2021-09-08T02:45:16.765882Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Accuracy of the model on the 10000 test images: 82.79000091552734 %\n","output_type":"stream"}]},{"cell_type":"code","source":"# Save the model checkpoint\ntorch.save(model.state_dict(), 'model.ckpt')","metadata":{"execution":{"iopub.status.busy":"2021-09-08T02:45:16.768560Z","iopub.execute_input":"2021-09-08T02:45:16.768934Z","iopub.status.idle":"2021-09-08T02:45:16.775839Z","shell.execute_reply.started":"2021-09-08T02:45:16.768896Z","shell.execute_reply":"2021-09-08T02:45:16.775010Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}