{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# https://github.com/dragen1860/TensorFlow-2.x-Tutorials/tree/master/13-DCGAN","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-09-28T04:44:06.861296Z","iopub.execute_input":"2021-09-28T04:44:06.861588Z","iopub.status.idle":"2021-09-28T04:44:06.881120Z","shell.execute_reply.started":"2021-09-28T04:44:06.861510Z","shell.execute_reply":"2021-09-28T04:44:06.879831Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import  tensorflow as tf\nfrom    tensorflow import keras\n\n\nclass Generator(keras.Model):\n\n    def __init__(self):\n        super(Generator, self).__init__()\n\n        self.n_f = 512\n        self.n_k = 4\n\n        # input z vector is [None, 100]\n        self.dense1 = keras.layers.Dense(3 * 3 * self.n_f)\n        self.conv2 = keras.layers.Conv2DTranspose(self.n_f // 2, 3, 2, 'valid')\n        # https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2DTranspose\n        # filters, kernel_size, strides=(1, 1), padding='valid',\n        self.bn2 = keras.layers.BatchNormalization()\n        self.conv3 = keras.layers.Conv2DTranspose(self.n_f // 4, self.n_k, 2, 'same')\n        self.bn3 = keras.layers.BatchNormalization()\n        self.conv4 = keras.layers.Conv2DTranspose(1, self.n_k, 2, 'same')\n        return\n\n    def call(self, inputs, training=None):\n        # [b, 100] => [b, 3, 3, 512]\n        x = tf.nn.leaky_relu(tf.reshape(self.dense1(inputs), shape=[-1, 3, 3, self.n_f]))\n        x = tf.nn.leaky_relu(self.bn2(self.conv2(x), training=training))\n        x = tf.nn.leaky_relu(self.bn3(self.conv3(x), training=training))\n        x = tf.tanh(self.conv4(x))\n        return x\n\n\nclass Discriminator(keras.Model):\n\n    def __init__(self):\n        super(Discriminator, self).__init__()\n\n        self.n_f = 64\n        self.n_k = 4\n\n        # input image is [-1, 28, 28, 1]\n        self.conv1 = keras.layers.Conv2D(self.n_f, self.n_k, 2, 'same')\n        # arguments are size of filters, size of kernet, stride, padding\n        self.conv2 = keras.layers.Conv2D(self.n_f * 2, self.n_k, 2, 'same')\n        self.bn2 = keras.layers.BatchNormalization()\n        self.conv3 = keras.layers.Conv2D(self.n_f * 4, self.n_k, 2, 'same')\n        self.bn3 = keras.layers.BatchNormalization()\n        self.flatten4 = keras.layers.Flatten()\n        self.dense4 = keras.layers.Dense(1)\n        return\n\n    def call(self, inputs, training=None):\n        x = tf.nn.leaky_relu(self.conv1(inputs))\n        x = tf.nn.leaky_relu(self.bn2(self.conv2(x), training=training))\n        x = tf.nn.leaky_relu(self.bn3(self.conv3(x), training=training))\n        x = self.dense4(self.flatten4(x))\n        return x","metadata":{"execution":{"iopub.status.busy":"2021-09-28T04:44:08.466702Z","iopub.execute_input":"2021-09-28T04:44:08.466980Z","iopub.status.idle":"2021-09-28T04:44:14.015689Z","shell.execute_reply.started":"2021-09-28T04:44:08.466951Z","shell.execute_reply":"2021-09-28T04:44:14.015037Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Difference between valid and same padding\n# https://stackoverflow.com/questions/37674306/what-is-the-difference-between-same-and-valid-padding-in-tf-nn-max-pool-of-t","metadata":{"execution":{"iopub.status.busy":"2021-09-28T04:44:14.017087Z","iopub.execute_input":"2021-09-28T04:44:14.017448Z","iopub.status.idle":"2021-09-28T04:44:14.020358Z","shell.execute_reply.started":"2021-09-28T04:44:14.017419Z","shell.execute_reply":"2021-09-28T04:44:14.019819Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"!pip install scipy==1.1","metadata":{"execution":{"iopub.status.busy":"2021-09-28T04:44:24.699165Z","iopub.execute_input":"2021-09-28T04:44:24.699648Z","iopub.status.idle":"2021-09-28T04:44:40.176832Z","shell.execute_reply.started":"2021-09-28T04:44:24.699599Z","shell.execute_reply":"2021-09-28T04:44:40.175889Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"import  os\nimport  numpy as np\nimport  tensorflow as tf\nfrom    tensorflow import keras\n#from scipy.misc import toimage\nfrom    scipy.misc.pilutil import toimage","metadata":{"execution":{"iopub.status.busy":"2021-09-28T04:44:42.324073Z","iopub.execute_input":"2021-09-28T04:44:42.324383Z","iopub.status.idle":"2021-09-28T04:44:42.331355Z","shell.execute_reply.started":"2021-09-28T04:44:42.324344Z","shell.execute_reply":"2021-09-28T04:44:42.330420Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def save_result(val_out, val_block_size, image_fn, color_mode):\n    def preprocess(img):\n        img = ((img + 1.0) * 127.5).astype(np.uint8)\n        return img\n\n    preprocesed = preprocess(val_out)\n    final_image = np.array([])\n    single_row = np.array([])\n    for b in range(val_out.shape[0]):\n        # concat image into a row\n        if single_row.size == 0:\n            single_row = preprocesed[b, :, :, :]\n        else:\n            single_row = np.concatenate((single_row, preprocesed[b, :, :, :]), axis=1)\n\n        # concat image row to final_image\n        if (b+1) % val_block_size == 0:\n            if final_image.size == 0:\n                final_image = single_row\n            else:\n                final_image = np.concatenate((final_image, single_row), axis=0)\n\n            # reset single row\n            single_row = np.array([])\n\n    if final_image.shape[2] == 1:\n        final_image = np.squeeze(final_image, axis=2)\n    toimage(final_image, mode=color_mode).save(image_fn)","metadata":{"execution":{"iopub.status.busy":"2021-09-28T04:44:43.518733Z","iopub.execute_input":"2021-09-28T04:44:43.518976Z","iopub.status.idle":"2021-09-28T04:44:43.529298Z","shell.execute_reply.started":"2021-09-28T04:44:43.518950Z","shell.execute_reply":"2021-09-28T04:44:43.528536Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# shorten sigmoid cross entropy loss calculation\ndef celoss_ones(logits, smooth=0.0):\n    return tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logits,\n                                                                  labels=tf.ones_like(logits)*(1.0 - smooth)))\n\n\ndef celoss_zeros(logits, smooth=0.0):\n    return tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logits,\n                                                                  labels=tf.zeros_like(logits)*(1.0 - smooth)))\n# https://stackoverflow.com/questions/46291253/what-is-the-difference-between-a-sigmoid-followed-by-the-cross-entropy-and-sigmo","metadata":{"execution":{"iopub.status.busy":"2021-09-28T04:44:44.339856Z","iopub.execute_input":"2021-09-28T04:44:44.340234Z","iopub.status.idle":"2021-09-28T04:44:44.348185Z","shell.execute_reply.started":"2021-09-28T04:44:44.340196Z","shell.execute_reply":"2021-09-28T04:44:44.347257Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def d_loss_fn(generator, discriminator, input_noise, real_image, is_trainig):\n    fake_image = generator(input_noise, is_trainig)\n    d_real_logits = discriminator(real_image, is_trainig)\n    d_fake_logits = discriminator(fake_image, is_trainig)\n\n    d_loss_real = celoss_ones(d_real_logits, smooth=0.1)\n    d_loss_fake = celoss_zeros(d_fake_logits, smooth=0.0)\n    loss = d_loss_real + d_loss_fake\n    return loss\n\n# In the discriminator loss, the idea is to beat the generator and hence the discriminator \n# should identify all the data generated by the generator as fake\n\ndef g_loss_fn(generator, discriminator, input_noise, is_trainig):\n    fake_image = generator(input_noise, is_trainig)\n    d_fake_logits = discriminator(fake_image, is_trainig)\n    loss = celoss_ones(d_fake_logits, smooth=0.1)\n    return loss\n\n# When training the generator, the aim is that the discriminator should not be \n# able to identify the data as fake and should tell that the data is real ","metadata":{"execution":{"iopub.status.busy":"2021-09-28T04:44:45.018616Z","iopub.execute_input":"2021-09-28T04:44:45.019513Z","iopub.status.idle":"2021-09-28T04:44:45.027437Z","shell.execute_reply.started":"2021-09-28T04:44:45.019469Z","shell.execute_reply":"2021-09-28T04:44:45.026767Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"tf.random.set_seed(22)\nnp.random.seed(22)\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\nassert tf.__version__.startswith('2.')","metadata":{"execution":{"iopub.status.busy":"2021-09-28T04:46:10.529574Z","iopub.execute_input":"2021-09-28T04:46:10.529892Z","iopub.status.idle":"2021-09-28T04:46:10.535280Z","shell.execute_reply.started":"2021-09-28T04:46:10.529861Z","shell.execute_reply":"2021-09-28T04:46:10.534561Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# hyper parameters\nz_dim = 100\nepochs = 3000000\nepochs = 300\nbatch_size = 128\nlearning_rate = 0.0002\nis_training = True","metadata":{"execution":{"iopub.status.busy":"2021-09-28T05:00:52.827573Z","iopub.execute_input":"2021-09-28T05:00:52.828107Z","iopub.status.idle":"2021-09-28T05:00:52.831762Z","shell.execute_reply.started":"2021-09-28T05:00:52.828072Z","shell.execute_reply":"2021-09-28T05:00:52.831235Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"# for validation purpose\nassets_dir = './images'\nif not os.path.isdir(assets_dir):\n    os.makedirs(assets_dir)\nval_block_size = 10\nval_size = val_block_size * val_block_size","metadata":{"execution":{"iopub.status.busy":"2021-09-28T04:46:11.905690Z","iopub.execute_input":"2021-09-28T04:46:11.906533Z","iopub.status.idle":"2021-09-28T04:46:11.911263Z","shell.execute_reply.started":"2021-09-28T04:46:11.906452Z","shell.execute_reply":"2021-09-28T04:46:11.910582Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# load mnist data\n(x_train, _), (x_test, _) = keras.datasets.mnist.load_data()\nx_train = x_train.astype(np.float32) / 255.\ndb = tf.data.Dataset.from_tensor_slices(x_train).shuffle(batch_size*4).batch(batch_size).repeat()\ndb_iter = iter(db)\ninputs_shape = [-1, 28, 28, 1]","metadata":{"execution":{"iopub.status.busy":"2021-09-28T04:46:18.167376Z","iopub.execute_input":"2021-09-28T04:46:18.168378Z","iopub.status.idle":"2021-09-28T04:46:19.279469Z","shell.execute_reply.started":"2021-09-28T04:46:18.168338Z","shell.execute_reply":"2021-09-28T04:46:19.278501Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# create generator & discriminator\ngenerator = Generator()\ngenerator.build(input_shape=(batch_size, z_dim))\ngenerator.summary()","metadata":{"execution":{"iopub.status.busy":"2021-09-28T04:46:20.076929Z","iopub.execute_input":"2021-09-28T04:46:20.077507Z","iopub.status.idle":"2021-09-28T04:46:20.224477Z","shell.execute_reply.started":"2021-09-28T04:46:20.077471Z","shell.execute_reply":"2021-09-28T04:46:20.223559Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"discriminator = Discriminator()\ndiscriminator.build(input_shape=(batch_size, 28, 28, 1))\ndiscriminator.summary()","metadata":{"execution":{"iopub.status.busy":"2021-09-28T04:46:23.005945Z","iopub.execute_input":"2021-09-28T04:46:23.006634Z","iopub.status.idle":"2021-09-28T04:46:23.096425Z","shell.execute_reply.started":"2021-09-28T04:46:23.006591Z","shell.execute_reply":"2021-09-28T04:46:23.095763Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# prepare optimizer\nd_optimizer = keras.optimizers.Adam(learning_rate=learning_rate, beta_1=0.5)\ng_optimizer = keras.optimizers.Adam(learning_rate=learning_rate, beta_1=0.5)","metadata":{"execution":{"iopub.status.busy":"2021-09-28T04:46:27.856140Z","iopub.execute_input":"2021-09-28T04:46:27.856565Z","iopub.status.idle":"2021-09-28T04:46:27.862223Z","shell.execute_reply.started":"2021-09-28T04:46:27.856534Z","shell.execute_reply":"2021-09-28T04:46:27.861446Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"for epoch in range(epochs):\n\n\n        # no need labels\n        batch_x = next(db_iter)\n\n        # rescale images to -1 ~ 1\n        batch_x = tf.reshape(batch_x, shape=inputs_shape)\n        # -1 - 1\n        batch_x = batch_x * 2.0 - 1.0\n\n        # Sample random noise for G\n        batch_z = tf.random.uniform(shape=[batch_size, z_dim], minval=-1., maxval=1.)\n\n\n        with tf.GradientTape() as tape:\n            d_loss = d_loss_fn(generator, discriminator, batch_z, batch_x, is_training)\n        grads = tape.gradient(d_loss, discriminator.trainable_variables)\n        d_optimizer.apply_gradients(zip(grads, discriminator.trainable_variables))\n\n        with tf.GradientTape() as tape:\n            g_loss = g_loss_fn(generator, discriminator, batch_z, is_training)\n        grads = tape.gradient(g_loss, generator.trainable_variables)\n        g_optimizer.apply_gradients(zip(grads, generator.trainable_variables))\n\n\n\n        if epoch % 100 == 0:\n\n            print(epoch, 'd loss:', float(d_loss), 'g loss:', float(g_loss))\n\n            # validation results at every epoch\n            val_z = np.random.uniform(-1, 1, size=(val_size, z_dim))\n            fake_image = generator(val_z, training=False)\n            image_fn = os.path.join('images', 'gan-val-{:03d}.png'.format(epoch + 1))\n            save_result(fake_image.numpy(), val_block_size, image_fn, color_mode='L')","metadata":{"execution":{"iopub.status.busy":"2021-09-28T05:00:57.977773Z","iopub.execute_input":"2021-09-28T05:00:57.978258Z","iopub.status.idle":"2021-09-28T05:10:27.986250Z","shell.execute_reply.started":"2021-09-28T05:00:57.978225Z","shell.execute_reply":"2021-09-28T05:10:27.985418Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}