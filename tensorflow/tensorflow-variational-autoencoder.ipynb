{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# https://github.com/dragen1860/TensorFlow-2.x-Tutorials/tree/master/12-VAE","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-09-28T18:42:58.647872Z","iopub.execute_input":"2021-09-28T18:42:58.648581Z","iopub.status.idle":"2021-09-28T18:42:58.652579Z","shell.execute_reply.started":"2021-09-28T18:42:58.648531Z","shell.execute_reply":"2021-09-28T18:42:58.651821Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"import  os\nimport  tensorflow as tf\nimport  numpy as np\nfrom    tensorflow import keras\nfrom    PIL import Image\nfrom    matplotlib import pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2021-09-28T18:43:02.898210Z","iopub.execute_input":"2021-09-28T18:43:02.899019Z","iopub.status.idle":"2021-09-28T18:43:02.904235Z","shell.execute_reply.started":"2021-09-28T18:43:02.898965Z","shell.execute_reply":"2021-09-28T18:43:02.903312Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"tf.random.set_seed(22)\nnp.random.seed(22)\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\nassert tf.__version__.startswith('2.')","metadata":{"execution":{"iopub.status.busy":"2021-09-28T18:43:04.224158Z","iopub.execute_input":"2021-09-28T18:43:04.224746Z","iopub.status.idle":"2021-09-28T18:43:04.230295Z","shell.execute_reply.started":"2021-09-28T18:43:04.224708Z","shell.execute_reply":"2021-09-28T18:43:04.229284Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"(x_train, y_train), (x_test, y_test) = keras.datasets.fashion_mnist.load_data()\nx_train, x_test = x_train.astype(np.float32)/255., x_test.astype(np.float32)/255.","metadata":{"execution":{"iopub.status.busy":"2021-09-28T18:43:05.108195Z","iopub.execute_input":"2021-09-28T18:43:05.108835Z","iopub.status.idle":"2021-09-28T18:43:05.611980Z","shell.execute_reply.started":"2021-09-28T18:43:05.108794Z","shell.execute_reply":"2021-09-28T18:43:05.611149Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"print(x_train.shape, y_train.shape)\nprint(x_test.shape, y_test.shape)","metadata":{"execution":{"iopub.status.busy":"2021-09-28T18:43:06.993632Z","iopub.execute_input":"2021-09-28T18:43:06.994591Z","iopub.status.idle":"2021-09-28T18:43:07.001375Z","shell.execute_reply.started":"2021-09-28T18:43:06.994537Z","shell.execute_reply":"2021-09-28T18:43:07.000529Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# image grid\nnew_im = Image.new('L', (280, 280))\n\nimage_size = 28*28\nh_dim = 512\nz_dim = 20\nnum_epochs = 55\nbatch_size = 100\nlearning_rate = 1e-3","metadata":{"execution":{"iopub.status.busy":"2021-09-28T18:43:08.011937Z","iopub.execute_input":"2021-09-28T18:43:08.012519Z","iopub.status.idle":"2021-09-28T18:43:08.017082Z","shell.execute_reply.started":"2021-09-28T18:43:08.012482Z","shell.execute_reply":"2021-09-28T18:43:08.016159Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"class VAE(tf.keras.Model):\n\n    def __init__(self):\n        super(VAE, self).__init__()\n\n        # input => h\n        self.fc1 = keras.layers.Dense(h_dim)\n        # h => mu and variance\n        self.fc2 = keras.layers.Dense(z_dim)\n        self.fc3 = keras.layers.Dense(z_dim)\n\n        # sampled z => h\n        self.fc4 = keras.layers.Dense(h_dim)\n        # h => image\n        self.fc5 = keras.layers.Dense(image_size)\n\n    def encode(self, x):\n        h = tf.nn.relu(self.fc1(x))\n        # mu, log_variance\n        return self.fc2(h), self.fc3(h)\n\n    def reparameterize(self, mu, log_var):\n        \"\"\"\n        reparametrize trick\n        :param mu:\n        :param log_var:\n        :return:\n        \"\"\"\n        std = tf.exp(log_var * 0.5)\n        eps = tf.random.normal(std.shape)\n\n        return mu + eps * std\n\n    def decode_logits(self, z):\n        h = tf.nn.relu(self.fc4(z))\n        return self.fc5(h)\n\n    def decode(self, z):\n        return tf.nn.sigmoid(self.decode_logits(z))\n\n    def call(self, inputs, training=None, mask=None):\n        # encoder\n        mu, log_var = self.encode(inputs)\n        # sample\n        z = self.reparameterize(mu, log_var)\n        # decode\n        x_reconstructed_logits = self.decode_logits(z)\n\n        return x_reconstructed_logits, mu, log_var","metadata":{"execution":{"iopub.status.busy":"2021-09-28T18:43:09.012305Z","iopub.execute_input":"2021-09-28T18:43:09.012873Z","iopub.status.idle":"2021-09-28T18:43:09.026105Z","shell.execute_reply.started":"2021-09-28T18:43:09.012835Z","shell.execute_reply":"2021-09-28T18:43:09.025248Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"model = VAE()\nmodel.build(input_shape=(4, image_size))\nmodel.summary()\noptimizer = keras.optimizers.Adam(learning_rate)","metadata":{"execution":{"iopub.status.busy":"2021-09-28T18:43:09.907338Z","iopub.execute_input":"2021-09-28T18:43:09.908040Z","iopub.status.idle":"2021-09-28T18:43:09.950720Z","shell.execute_reply.started":"2021-09-28T18:43:09.908002Z","shell.execute_reply":"2021-09-28T18:43:09.949897Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# we do not need label\ndataset = tf.data.Dataset.from_tensor_slices(x_train)\ndataset = dataset.shuffle(batch_size * 5).batch(batch_size)\n\nnum_batches = x_train.shape[0] // batch_size","metadata":{"execution":{"iopub.status.busy":"2021-09-28T18:43:10.878782Z","iopub.execute_input":"2021-09-28T18:43:10.879306Z","iopub.status.idle":"2021-09-28T18:43:11.032720Z","shell.execute_reply.started":"2021-09-28T18:43:10.879267Z","shell.execute_reply":"2021-09-28T18:43:11.031786Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"for epoch in range(num_epochs):\n\n    for step, x in enumerate(dataset):\n\n        x = tf.reshape(x, [-1, image_size])\n\n        with tf.GradientTape() as tape:\n\n            # Forward pass\n            x_reconstruction_logits, mu, log_var = model(x)\n\n            # Compute reconstruction loss and kl divergence\n            # For KL divergence, see Appendix B in VAE paper or http://yunjey47.tistory.com/43\n            # Scaled by `image_size` for each individual pixel.\n            reconstruction_loss = tf.nn.sigmoid_cross_entropy_with_logits(labels=x, logits=x_reconstruction_logits)\n            reconstruction_loss = tf.reduce_sum(reconstruction_loss) / batch_size\n            # please refer to\n            # https://stats.stackexchange.com/questions/7440/kl-divergence-between-two-univariate-gaussians\n            kl_div = - 0.5 * tf.reduce_sum(1. + log_var - tf.square(mu) - tf.exp(log_var), axis=-1)\n            kl_div = tf.reduce_mean(kl_div)\n\n            # Backprop and optimize\n            loss = tf.reduce_mean(reconstruction_loss) + kl_div\n\n        gradients = tape.gradient(loss, model.trainable_variables)\n        for g in gradients:\n            tf.clip_by_norm(g, 15)\n        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n\n        if (step + 1) % 50 == 0:\n            print(\"Epoch[{}/{}], Step [{}/{}], Reconst Loss: {:.4f}, KL Div: {:.4f}\"\n                  .format(epoch + 1, num_epochs, step + 1, num_batches, float(reconstruction_loss), float(kl_div)))\n\n\n\n    # Generative model\n    z = tf.random.normal((batch_size, z_dim))\n    out = model.decode(z)  # decode with sigmoid\n    out = tf.reshape(out, [-1, 28, 28]).numpy() * 255\n    out = out.astype(np.uint8)\n\n\n    # since we can not find image_grid function from vesion 2.0\n    # we do it by hand.\n    index = 0\n    for i in range(0, 280, 28):\n        for j in range(0, 280, 28):\n            im = out[index]\n            im = Image.fromarray(im, mode='L')\n            new_im.paste(im, (i, j))\n            index += 1\n\n    new_im.save('./vae_sampled_epoch_%d.png' % (epoch + 1))\n    plt.imshow(np.asarray(new_im))\n    plt.show()\n\n    # Save the reconstructed images of last batch\n    out_logits, _, _ = model(x[:batch_size // 2])\n    out = tf.nn.sigmoid(out_logits)  # out is just the logits, use sigmoid\n    out = tf.reshape(out, [-1, 28, 28]).numpy() * 255\n\n    x = tf.reshape(x[:batch_size // 2], [-1, 28, 28])\n\n    x_concat = tf.concat([x, out], axis=0).numpy() * 255.\n    x_concat = x_concat.astype(np.uint8)\n\n    index = 0\n    for i in range(0, 280, 28):\n        for j in range(0, 280, 28):\n            im = x_concat[index]\n            im = Image.fromarray(im, mode='L')\n            new_im.paste(im, (i, j))\n            index += 1\n\n    new_im.save('./vae_reconstructed_epoch_%d.png' % (epoch + 1))\n    plt.imshow(np.asarray(new_im))\n    plt.show()\n    print('New images saved !')","metadata":{"execution":{"iopub.status.busy":"2021-09-28T18:43:44.327461Z","iopub.execute_input":"2021-09-28T18:43:44.327881Z","iopub.status.idle":"2021-09-28T18:51:35.923565Z","shell.execute_reply.started":"2021-09-28T18:43:44.327846Z","shell.execute_reply":"2021-09-28T18:51:35.922844Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}