{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# https://medium.com/@lovekeshbansal/cyclegan-unpaired-image-translation-7eb970bbd7c8\n# https://medium.com/deep-math-machine-learning-ai/ch-14-2-pix2pix-gan-and-cycle-gan-55cd84318fb8","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-09-29T22:37:08.416353Z","iopub.execute_input":"2021-09-29T22:37:08.416903Z","iopub.status.idle":"2021-09-29T22:37:08.433852Z","shell.execute_reply.started":"2021-09-29T22:37:08.416820Z","shell.execute_reply":"2021-09-29T22:37:08.433254Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import  os\nimport  tensorflow as tf\nimport  numpy as np\nfrom    tensorflow import keras\n\n\nclass Encoder(keras.Model):\n\n    def __init__(self):\n        super(Encoder, self).__init__()\n\n        # Small variance in initialization helps with preventing colour inversion.\n        self.conv1 = keras.layers.Conv2D(32, kernel_size=7, strides=1,\n                                            kernel_initializer=tf.random_normal_initializer(stddev=0.02))\n        self.conv2 = keras.layers.Conv2D(64, kernel_size=3, strides=2, padding='same',\n                                            kernel_initializer=tf.random_normal_initializer(stddev=0.02))\n        self.conv3 = keras.layers.Conv2D(128, kernel_size=3, strides=2, padding='same',\n                                            kernel_initializer=tf.random_normal_initializer(stddev=0.02))\n        \n        # TODO: replace Instance Normalization for batchnorm\n        self.bn1 = keras.layers.BatchNormalization()\n        self.bn2 = keras.layers.BatchNormalization()\n        self.bn3 = keras.layers.BatchNormalization()\n\n    def call(self, inputs, training=True):\n        x = tf.pad(inputs, [[0, 0], [3, 3], [3, 3], [0, 0]], \"REFLECT\")\n        # https://www.tensorflow.org/api_docs/python/tf/pad\n        x = self.conv1(x)\n        x = self.bn1(x, training=training)\n        # Implement instance norm to more closely match orig. paper (momentum=0.1)?\n        x = tf.nn.relu(x)\n\n        x = self.conv2(x)\n        x = self.bn2(x, training=training)\n        x = tf.nn.relu(x)\n\n        x = self.conv3(x)\n        x = self.bn3(x, training=training)\n        x = tf.nn.relu(x)\n\n        return x\n\n\nclass Residual(keras.Model):\n\n    def __init__(self):\n        super(Residual, self).__init__()\n\n        self.conv1 = keras.layers.Conv2D(128, kernel_size=3, strides=1,\n                                            kernel_initializer=tf.random_normal_initializer(stddev=0.02))\n        self.conv2 = keras.layers.Conv2D(128, kernel_size=3, strides=1,\n                                            kernel_initializer=tf.random_normal_initializer(stddev=0.02))\n        \n\n        # TODO: replace Instance Normalization for batchnorm\n        self.bn1 = keras.layers.BatchNormalization()\n        self.bn2 = keras.layers.BatchNormalization() \n\n    def call(self, inputs, training=True):\n        x = tf.pad(inputs, [[0, 0], [1, 1], [1, 1], [0, 0]], \"REFLECT\")\n\n        x = self.conv1(x)\n        x = self.bn1(x, training=training)\n        x = tf.nn.relu(x)\n\n        x = tf.pad(x, [[0, 0], [1, 1], [1, 1], [0, 0]], \"REFLECT\")\n\n        x = self.conv2(x)\n        x = self.bn2(x, training=training)\n\n        x = tf.add(x, inputs)\n\n        return x\n\n\nclass Decoder(keras.Model):\n\n    def __init__(self):\n        super(Decoder, self).__init__()\n\n        self.conv1 = keras.layers.Conv2DTranspose(64, kernel_size=3, strides=2, padding='same',\n                                                     kernel_initializer=tf.random_normal_initializer(stddev=0.02))\n        self.conv2 = keras.layers.Conv2DTranspose(32, kernel_size=3, strides=2, padding='same',\n                                                     kernel_initializer=tf.random_normal_initializer(stddev=0.02))\n        self.conv3 = keras.layers.Conv2D(3, kernel_size=7, strides=1,\n                                            kernel_initializer=tf.random_normal_initializer(stddev=0.02))\n\n\n        # TODO: replace Instance Normalization for batchnorm\n        self.bn1 = keras.layers.BatchNormalization()\n        self.bn2 = keras.layers.BatchNormalization()\n        self.bn3 = keras.layers.BatchNormalization()\n\n    def call(self, inputs, training=True):\n        x = self.conv1(inputs)\n        x = self.bn1(x, training=training)\n        x = tf.nn.relu(x)\n\n        x = self.conv2(x)\n        x = self.bn2(x, training=training)\n        x = tf.nn.relu(x)\n\n        x = tf.pad(x, [[0, 0], [3, 3], [3, 3], [0, 0]], \"REFLECT\")\n\n        x = self.conv3(x)\n        x = self.bn3(x, training=training)\n        x = tf.nn.tanh(x)\n\n        return x\n\n\nclass Generator(keras.Model):\n\n    def __init__(self, img_size=256, skip=False):\n        super(Generator, self).__init__()\n\n        self.img_size = img_size\n        self.skip = skip  # TODO: Add skip\n\n        self.encoder = Encoder()\n        if (img_size == 128):\n            self.res1 = Residual()\n            self.res2 = Residual()\n            self.res3 = Residual()\n            self.res4 = Residual()\n            self.res5 = Residual()\n            self.res6 = Residual()\n        else:\n            self.res1 = Residual()\n            self.res2 = Residual()\n            self.res3 = Residual()\n            self.res4 = Residual()\n            self.res5 = Residual()\n            self.res6 = Residual()\n            self.res7 = Residual()\n            self.res8 = Residual()\n            self.res9 = Residual()\n        self.decoder = Decoder()\n\n\n    def call(self, inputs, training=True):\n\n        x = self.encoder(inputs, training)\n        if (self.img_size == 128):\n            x = self.res1(x, training)\n            x = self.res2(x, training)\n            x = self.res3(x, training)\n            x = self.res4(x, training)\n            x = self.res5(x, training)\n            x = self.res6(x, training)\n        else:\n            x = self.res1(x, training)\n            x = self.res2(x, training)\n            x = self.res3(x, training)\n            x = self.res4(x, training)\n            x = self.res5(x, training)\n            x = self.res6(x, training)\n            x = self.res7(x, training)\n            x = self.res8(x, training)\n            x = self.res9(x, training)\n        x = self.decoder(x, training)\n\n        return x\n\n\nclass Discriminator(keras.Model):\n\n    def __init__(self):\n        super(Discriminator, self).__init__()\n\n        self.conv1 = keras.layers.Conv2D(64, kernel_size=4, strides=2, padding='same',\n                                            kernel_initializer=tf.random_normal_initializer(stddev=0.02))\n        self.conv2 = keras.layers.Conv2D(128, kernel_size=4, strides=2, padding='same',\n                                            kernel_initializer=tf.random_normal_initializer(stddev=0.02))\n        self.conv3 = keras.layers.Conv2D(256, kernel_size=4, strides=2, padding='same',\n                                            kernel_initializer=tf.random_normal_initializer(stddev=0.02))\n        self.conv4 = keras.layers.Conv2D(512, kernel_size=4, strides=1, padding='same',\n                                            kernel_initializer=tf.random_normal_initializer(stddev=0.02))\n        self.conv5 = keras.layers.Conv2D(1, kernel_size=4, strides=1, padding='same',\n                                            kernel_initializer=tf.random_normal_initializer(stddev=0.02))\n\n        self.leaky = keras.layers.LeakyReLU(0.2)\n\n\n        # TODO: replace Instance Normalization for batchnorm\n        self.bn1 = keras.layers.BatchNormalization()\n        self.bn2 = keras.layers.BatchNormalization()\n        self.bn3 = keras.layers.BatchNormalization()\n\n\n    def call(self, inputs, training=True):\n        x = self.conv1(inputs)\n        x = self.leaky(x)\n\n        x = self.conv2(x)\n        x = self.bn1(x, training=training)\n        x = self.leaky(x)\n\n        x = self.conv3(x)\n        x = self.bn2(x, training=training)\n        x = self.leaky(x)\n\n        x = self.conv4(x)\n        x = self.bn3(x, training=training)\n        x = self.leaky(x)\n\n        x = self.conv5(x)\n        # x = tf.nn.sigmoid(x) # use_sigmoid = not lsgan\n        return x\n\n\n\n\n\n\ndef discriminator_loss(disc_of_real_output, disc_of_gen_output, lsgan=True):\n    if lsgan:  # Use least squares loss\n        # real_loss = tf.reduce_mean(tf.squared_difference(disc_of_real_output, 1))\n        real_loss = keras.losses.mean_squared_error(disc_of_real_output, tf.ones_like(disc_of_real_output))\n        generated_loss = tf.reduce_mean(tf.square(disc_of_gen_output))\n\n        total_disc_loss = (real_loss + generated_loss) * 0.5  # 0.5 slows down rate that D learns compared to G\n    else:  # Use vanilla GAN loss\n        raise NotImplementedError\n        real_loss = tf.losses.sigmoid_cross_entropy(multi_class_labels=tf.ones_like(disc_of_real_output),\n                                                    logits=disc_of_real_output)\n        generated_loss = tf.losses.sigmoid_cross_entropy(multi_class_labels=tf.zeros_like(disc_of_gen_output),\n                                                         logits=disc_of_gen_output)\n\n        total_disc_loss = real_loss + generated_loss\n\n    return total_disc_loss\n\n\ndef generator_loss(disc_of_gen_output, lsgan=True):\n    if lsgan:  # Use least squares loss\n        # gen_loss = tf.reduce_mean(tf.squared_difference(disc_of_gen_output, 1))\n        gen_loss = keras.losses.mean_squared_error(disc_of_gen_output, tf.ones_like(disc_of_gen_output))\n    else:  # Use vanilla GAN loss\n        raise NotImplementedError\n        gen_loss = tf.losses.sigmoid_cross_entropy(multi_class_labels=tf.ones_like(disc_generated_output),\n                                                   logits=disc_generated_output)\n        # l1_loss = tf.reduce_mean(tf.abs(target - gen_output)) # Look up pix2pix loss\n    return gen_loss\n\n\ndef cycle_consistency_loss(data_A, data_B, reconstructed_data_A, reconstructed_data_B, cyc_lambda=10):\n    loss = tf.reduce_mean(tf.abs(data_A - reconstructed_data_A) + tf.abs(data_B - reconstructed_data_B))\n    return cyc_lambda * loss","metadata":{"execution":{"iopub.status.busy":"2021-09-29T23:26:08.343914Z","iopub.execute_input":"2021-09-29T23:26:08.344174Z","iopub.status.idle":"2021-09-29T23:26:13.068791Z","shell.execute_reply.started":"2021-09-29T23:26:08.344145Z","shell.execute_reply":"2021-09-29T23:26:13.068067Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import  os\nimport  time\nimport  numpy as np\nimport  matplotlib.pyplot as plt\nimport  tensorflow as tf\nimport  numpy as np\nfrom    tensorflow import keras","metadata":{"execution":{"iopub.status.busy":"2021-09-29T23:26:46.703578Z","iopub.execute_input":"2021-09-29T23:26:46.703957Z","iopub.status.idle":"2021-09-29T23:26:46.710624Z","shell.execute_reply.started":"2021-09-29T23:26:46.703913Z","shell.execute_reply":"2021-09-29T23:26:46.709925Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"tf.random.set_seed(22)\nnp.random.seed(22)\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\nassert tf.__version__.startswith('2.')","metadata":{"execution":{"iopub.status.busy":"2021-09-29T23:26:54.934488Z","iopub.execute_input":"2021-09-29T23:26:54.934768Z","iopub.status.idle":"2021-09-29T23:26:54.940343Z","shell.execute_reply.started":"2021-09-29T23:26:54.934719Z","shell.execute_reply":"2021-09-29T23:26:54.939480Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"learning_rate = 0.0002\nbatch_size = 1  # Set batch size to 4 or 16 if training multigpu\nimg_size = 256\ncyc_lambda = 10\nepochs = 1000","metadata":{"execution":{"iopub.status.busy":"2021-09-29T23:37:34.967567Z","iopub.execute_input":"2021-09-29T23:37:34.967860Z","iopub.status.idle":"2021-09-29T23:37:34.973391Z","shell.execute_reply.started":"2021-09-29T23:37:34.967829Z","shell.execute_reply":"2021-09-29T23:37:34.972666Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"path_to_zip = keras.utils.get_file('horse2zebra.zip',\n                              cache_subdir=os.path.abspath('.'),\n                              origin='https://people.eecs.berkeley.edu/~taesung_park/CycleGAN/datasets/horse2zebra.zip',\n                              extract=True)\n\nPATH = os.path.join(os.path.dirname(path_to_zip), 'horse2zebra/')","metadata":{"execution":{"iopub.status.busy":"2021-09-29T23:35:29.747948Z","iopub.execute_input":"2021-09-29T23:35:29.748670Z","iopub.status.idle":"2021-09-29T23:35:30.956455Z","shell.execute_reply.started":"2021-09-29T23:35:29.748633Z","shell.execute_reply":"2021-09-29T23:35:30.955722Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"trainA_path = os.path.join(PATH, \"trainA\")\ntrainB_path = os.path.join(PATH, \"trainB\")","metadata":{"execution":{"iopub.status.busy":"2021-09-29T23:35:33.802967Z","iopub.execute_input":"2021-09-29T23:35:33.803720Z","iopub.status.idle":"2021-09-29T23:35:33.807634Z","shell.execute_reply.started":"2021-09-29T23:35:33.803679Z","shell.execute_reply":"2021-09-29T23:35:33.806886Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"trainA_size = len(os.listdir(trainA_path))\ntrainB_size = len(os.listdir(trainB_path))\nprint('train A:', trainA_size)\nprint('train B:', trainB_size)","metadata":{"execution":{"iopub.status.busy":"2021-09-29T23:35:34.573573Z","iopub.execute_input":"2021-09-29T23:35:34.574174Z","iopub.status.idle":"2021-09-29T23:35:34.582516Z","shell.execute_reply.started":"2021-09-29T23:35:34.574138Z","shell.execute_reply":"2021-09-29T23:35:34.581442Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"def load_image(image_file):\n    image = tf.io.read_file(image_file)\n    image = tf.image.decode_jpeg(image, channels=3)\n    # scale alread!\n    image = tf.image.convert_image_dtype(image, tf.float32)\n    image = tf.image.resize(image, [256, 256])\n    # image = (image / 127.5) - 1\n    image = image * 2 - 1\n\n    return image","metadata":{"execution":{"iopub.status.busy":"2021-09-29T23:35:35.403144Z","iopub.execute_input":"2021-09-29T23:35:35.403698Z","iopub.status.idle":"2021-09-29T23:35:35.409153Z","shell.execute_reply.started":"2021-09-29T23:35:35.403660Z","shell.execute_reply":"2021-09-29T23:35:35.408079Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"train_datasetA = tf.data.Dataset.list_files(PATH + 'trainA/*.jpg', shuffle=False)\ntrain_datasetA = train_datasetA.shuffle(trainA_size).repeat(epochs)\ntrain_datasetA = train_datasetA.map(lambda x: load_image(x))\ntrain_datasetA = train_datasetA.batch(batch_size)\ntrain_datasetA = train_datasetA.prefetch(batch_size)\ntrain_datasetA = iter(train_datasetA)","metadata":{"execution":{"iopub.status.busy":"2021-09-29T23:35:36.155060Z","iopub.execute_input":"2021-09-29T23:35:36.155855Z","iopub.status.idle":"2021-09-29T23:35:36.247530Z","shell.execute_reply.started":"2021-09-29T23:35:36.155809Z","shell.execute_reply":"2021-09-29T23:35:36.246818Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"train_datasetB = tf.data.Dataset.list_files(PATH + 'trainB/*.jpg', shuffle=False)\ntrain_datasetB = train_datasetB.shuffle(trainB_size).repeat(epochs)\ntrain_datasetB = train_datasetB.map(lambda x: load_image(x))\ntrain_datasetB = train_datasetB.batch(batch_size)\ntrain_datasetB = train_datasetB.prefetch(batch_size)\n# https://stackoverflow.com/questions/47064693/tensorflow-data-api-prefetch\ntrain_datasetB = iter(train_datasetB)","metadata":{"execution":{"iopub.status.busy":"2021-09-29T23:35:37.027647Z","iopub.execute_input":"2021-09-29T23:35:37.028219Z","iopub.status.idle":"2021-09-29T23:35:37.066178Z","shell.execute_reply.started":"2021-09-29T23:35:37.028181Z","shell.execute_reply":"2021-09-29T23:35:37.065489Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"a = next(train_datasetA)\nprint('img shape:', a.shape, a.numpy().min(), a.numpy().max())","metadata":{"execution":{"iopub.status.busy":"2021-09-29T23:35:37.810252Z","iopub.execute_input":"2021-09-29T23:35:37.810501Z","iopub.status.idle":"2021-09-29T23:35:37.823654Z","shell.execute_reply.started":"2021-09-29T23:35:37.810473Z","shell.execute_reply":"2021-09-29T23:35:37.822855Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"discA = Discriminator()\ndiscB = Discriminator()\ngenA2B = Generator()\ngenB2A = Generator()","metadata":{"execution":{"iopub.status.busy":"2021-09-29T23:35:38.474769Z","iopub.execute_input":"2021-09-29T23:35:38.475323Z","iopub.status.idle":"2021-09-29T23:35:38.685069Z","shell.execute_reply.started":"2021-09-29T23:35:38.475290Z","shell.execute_reply":"2021-09-29T23:35:38.684404Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"discA_optimizer = keras.optimizers.Adam(learning_rate, beta_1=0.5)\ndiscB_optimizer = keras.optimizers.Adam(learning_rate, beta_1=0.5)\ngenA2B_optimizer = keras.optimizers.Adam(learning_rate, beta_1=0.5)\ngenB2A_optimizer = keras.optimizers.Adam(learning_rate, beta_1=0.5)","metadata":{"execution":{"iopub.status.busy":"2021-09-29T23:35:39.378476Z","iopub.execute_input":"2021-09-29T23:35:39.380905Z","iopub.status.idle":"2021-09-29T23:35:39.388939Z","shell.execute_reply.started":"2021-09-29T23:35:39.380857Z","shell.execute_reply":"2021-09-29T23:35:39.388015Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"def generate_images(A, B, B2A, A2B, epoch):\n    \"\"\"\n    :param A:\n    :param B:\n    :param B2A:\n    :param A2B:\n    :param epoch:\n    :return:\n    \"\"\"\n    plt.figure(figsize=(15, 15))\n    A = tf.reshape(A, [256, 256, 3]).numpy()\n    B = tf.reshape(B, [256, 256, 3]).numpy()\n    B2A = tf.reshape(B2A, [256, 256, 3]).numpy()\n    A2B = tf.reshape(A2B, [256, 256, 3]).numpy()\n    display_list = [A, B, A2B, B2A]\n\n    title = ['A', 'B', 'A2B', 'B2A']\n    for i in range(4):\n        plt.subplot(2, 2, i + 1)\n        plt.title(title[i])\n        # getting the pixel values between [0, 1] to plot it.\n        plt.imshow(display_list[i] * 0.5 + 0.5)\n        plt.axis('off')\n    plt.savefig('./generated_%d.png'%epoch)\n    plt.close()","metadata":{"execution":{"iopub.status.busy":"2021-09-29T23:36:04.896597Z","iopub.execute_input":"2021-09-29T23:36:04.897416Z","iopub.status.idle":"2021-09-29T23:36:04.905696Z","shell.execute_reply.started":"2021-09-29T23:36:04.897368Z","shell.execute_reply":"2021-09-29T23:36:04.904981Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"def train(train_datasetA, train_datasetB, epochs, lsgan=True, cyc_lambda=10):\n\n    for epoch in range(epochs):\n        start = time.time()\n\n\n        with tf.GradientTape() as genA2B_tape, tf.GradientTape() as genB2A_tape, \\\n                tf.GradientTape() as discA_tape, tf.GradientTape() as discB_tape:\n            try:\n                # Next training minibatches, default size 1\n                trainA = next(train_datasetA)\n                trainB = next(train_datasetB)\n            except tf.errors.OutOfRangeError:\n                print(\"Error, run out of data\")\n                break\n\n            genA2B_output = genA2B(trainA, training=True)\n            genB2A_output = genB2A(trainB, training=True)\n\n\n            discA_real_output = discA(trainA, training=True)\n            discB_real_output = discB(trainB, training=True)\n\n            discA_fake_output = discA(genB2A_output, training=True)\n            discB_fake_output = discB(genA2B_output, training=True)\n\n            reconstructedA = genB2A(genA2B_output, training=True)\n            reconstructedB = genA2B(genB2A_output, training=True)\n\n            # generate_images(reconstructedA, reconstructedB)\n\n            # Use history buffer of 50 for disc loss\n            discA_loss = discriminator_loss(discA_real_output, discA_fake_output, lsgan=lsgan)\n            discB_loss = discriminator_loss(discB_real_output, discB_fake_output, lsgan=lsgan)\n\n            genA2B_loss = generator_loss(discB_fake_output, lsgan=lsgan) + \\\n                          cycle_consistency_loss(trainA, trainB, reconstructedA, reconstructedB,\n                                                 cyc_lambda=cyc_lambda)\n            genB2A_loss = generator_loss(discA_fake_output, lsgan=lsgan) + \\\n                          cycle_consistency_loss(trainA, trainB, reconstructedA, reconstructedB,\n                                                 cyc_lambda=cyc_lambda)\n\n        genA2B_gradients = genA2B_tape.gradient(genA2B_loss, genA2B.trainable_variables)\n        genB2A_gradients = genB2A_tape.gradient(genB2A_loss, genB2A.trainable_variables)\n\n        discA_gradients = discA_tape.gradient(discA_loss, discA.trainable_variables)\n        discB_gradients = discB_tape.gradient(discB_loss, discB.trainable_variables)\n\n        genA2B_optimizer.apply_gradients(zip(genA2B_gradients, genA2B.trainable_variables))\n        genB2A_optimizer.apply_gradients(zip(genB2A_gradients, genB2A.trainable_variables))\n\n        discA_optimizer.apply_gradients(zip(discA_gradients, discA.trainable_variables))\n        discB_optimizer.apply_gradients(zip(discB_gradients, discB.trainable_variables))\n\n\n        if epoch % 40 == 0:\n            generate_images(trainA, trainB, genB2A_output, genA2B_output, epoch)\n\n            print('Time taken for epoch {} is {} sec'.format(epoch + 1, time.time() - start))\n\n\n\n\nif __name__ == '__main__':\n    train(train_datasetA, train_datasetB, epochs=epochs, lsgan=True, cyc_lambda=cyc_lambda)","metadata":{"execution":{"iopub.status.busy":"2021-09-29T23:37:38.610104Z","iopub.execute_input":"2021-09-29T23:37:38.610386Z","iopub.status.idle":"2021-09-29T23:44:33.392161Z","shell.execute_reply.started":"2021-09-29T23:37:38.610355Z","shell.execute_reply":"2021-09-29T23:44:33.391366Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}