{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# https://github.com/dragen1860/TensorFlow-2.x-Tutorials/tree/master/03-Play-with-MNIST","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-09-14T22:38:31.874255Z","iopub.execute_input":"2021-09-14T22:38:31.874466Z","iopub.status.idle":"2021-09-14T22:38:31.878403Z","shell.execute_reply.started":"2021-09-14T22:38:31.874444Z","shell.execute_reply":"2021-09-14T22:38:31.877385Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## Play with MNIST\nA detailed MNIST walk-through!\n\nLet's start by loading MNIST from keras.datasets and preprocessing to get rows of normalized 784-dimensional vectors.","metadata":{}},{"cell_type":"code","source":"import  tensorflow as tf\nfrom tensorflow.keras import datasets, layers, optimizers, Sequential, metrics\n\n(xs, ys),_ = datasets.mnist.load_data()\nprint('datasets:', xs.shape, ys.shape, xs.min(), xs.max(), type(xs), type(ys))\n\nxs = tf.convert_to_tensor(xs, dtype=tf.float32) / 255.\ndb = tf.data.Dataset.from_tensor_slices((xs,ys))\ndb = db.batch(32).repeat(10)","metadata":{"execution":{"iopub.status.busy":"2021-09-14T22:38:33.145144Z","iopub.execute_input":"2021-09-14T22:38:33.145425Z","iopub.status.idle":"2021-09-14T22:38:40.793230Z","shell.execute_reply.started":"2021-09-14T22:38:33.145389Z","shell.execute_reply":"2021-09-14T22:38:40.792506Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"2021-09-14 22:38:33.751209: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n","output_type":"stream"},{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n11493376/11490434 [==============================] - 0s 0us/step\ndatasets: (60000, 28, 28) (60000,) 0 255 <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n","output_type":"stream"},{"name":"stderr","text":"2021-09-14 22:38:38.340092: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n2021-09-14 22:38:38.343315: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n2021-09-14 22:38:38.391861: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-09-14 22:38:38.392535: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \npciBusID: 0000:00:04.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0\ncoreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s\n2021-09-14 22:38:38.392590: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n2021-09-14 22:38:38.417511: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n2021-09-14 22:38:38.417591: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n2021-09-14 22:38:38.436408: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n2021-09-14 22:38:38.492706: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n2021-09-14 22:38:38.533430: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n2021-09-14 22:38:38.541859: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n2021-09-14 22:38:38.545061: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n2021-09-14 22:38:38.545230: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-09-14 22:38:38.545954: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-09-14 22:38:38.547415: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n2021-09-14 22:38:38.550251: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2021-09-14 22:38:38.551534: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n2021-09-14 22:38:38.551681: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-09-14 22:38:38.552269: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \npciBusID: 0000:00:04.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0\ncoreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s\n2021-09-14 22:38:38.552306: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n2021-09-14 22:38:38.552328: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n2021-09-14 22:38:38.552343: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n2021-09-14 22:38:38.552389: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n2021-09-14 22:38:38.552411: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n2021-09-14 22:38:38.552430: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n2021-09-14 22:38:38.552455: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n2021-09-14 22:38:38.552476: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n2021-09-14 22:38:38.552574: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-09-14 22:38:38.553260: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-09-14 22:38:38.553883: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n2021-09-14 22:38:38.555329: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n2021-09-14 22:38:40.108506: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n2021-09-14 22:38:40.108561: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n2021-09-14 22:38:40.108573: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n2021-09-14 22:38:40.110811: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-09-14 22:38:40.111636: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-09-14 22:38:40.112261: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-09-14 22:38:40.112882: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14957 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Now let's build our network as a **keras.Sequential** model and instantiate a stochastic gradient descent optimizer from **keras.optimizers**.","metadata":{}},{"cell_type":"code","source":"network = Sequential([layers.Dense(256, activation='relu'),\n                     layers.Dense(256, activation='relu'),\n                     layers.Dense(256, activation='relu'),\n                     layers.Dense(10)])\nnetwork.build(input_shape=(None, 28*28))\n# https://www.tensorflow.org/guide/keras/custom_layers_and_models\nnetwork.summary()\n\noptimizer = optimizers.SGD(lr=0.01)\nacc_meter = metrics.Accuracy()","metadata":{"execution":{"iopub.status.busy":"2021-09-14T22:38:40.795023Z","iopub.execute_input":"2021-09-14T22:38:40.795299Z","iopub.status.idle":"2021-09-14T22:38:40.875677Z","shell.execute_reply.started":"2021-09-14T22:38:40.795266Z","shell.execute_reply":"2021-09-14T22:38:40.874907Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense (Dense)                (None, 256)               200960    \n_________________________________________________________________\ndense_1 (Dense)              (None, 256)               65792     \n_________________________________________________________________\ndense_2 (Dense)              (None, 256)               65792     \n_________________________________________________________________\ndense_3 (Dense)              (None, 10)                2570      \n=================================================================\nTotal params: 335,114\nTrainable params: 335,114\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Finally, we can iterate through our dataset and train our model. In this example, we use tf.GradientTape to manually compute the gradients of the loss with respect to our network's trainable variables. GradientTape is just one of many ways to perform gradient steps in TensorFlow 2.0:\n\n- **Tf.GradientTape:** Manually computes loss gradients with respect to given variables by recording operations within its context manager. This is the most flexible way to perform optimizer steps, as we can work directly with gradients and don't need a pre-defined Keras model or loss function.\n- **Model.train():** Keras's built-in function for iterating through a dataset and fitting a Keras.Model on it. This is often the best choice for training a Keras model and comes with options for progress bar displays, validation splits, multiprocessing, and generator support.\n- **Optimizer.minimize():** Computes and differentiates through a given loss function and performs a step to minimize it with gradient descent. This method is easy to implement, and can be conveniently slapped onto any existing computational graph to make a working optimization step.","metadata":{}},{"cell_type":"code","source":"for step, (x,y) in enumerate(db):\n\n    with tf.GradientTape() as tape:\n        # [b, 28, 28] => [b, 784]\n        x = tf.reshape(x, (-1, 28*28))\n        # [b, 784] => [b, 10]\n        out = network(x)\n        # [b] => [b, 10]\n        y_onehot = tf.one_hot(y, depth=10)\n        # [b, 10]\n        loss = tf.square(out-y_onehot)\n        # [b]\n        loss = tf.reduce_sum(loss) / 32\n\n\n    acc_meter.update_state(tf.argmax(out, axis=1), y)\n\n    grads = tape.gradient(loss, network.trainable_variables)\n    optimizer.apply_gradients(zip(grads, network.trainable_variables))\n\n\n    if step % 200==0:\n\n        print(step, 'loss:', float(loss), 'acc:', acc_meter.result().numpy())\n        acc_meter.reset_states()","metadata":{"execution":{"iopub.status.busy":"2021-09-14T22:38:40.876933Z","iopub.execute_input":"2021-09-14T22:38:40.877200Z","iopub.status.idle":"2021-09-14T22:40:46.145264Z","shell.execute_reply.started":"2021-09-14T22:38:40.877170Z","shell.execute_reply":"2021-09-14T22:40:46.144538Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"2021-09-14 22:38:41.155656: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n2021-09-14 22:38:42.081139: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n","output_type":"stream"},{"name":"stdout","text":"0 loss: 1.4643440246582031 acc: 0.0625\n200 loss: 0.4284134805202484 acc: 0.6846875\n400 loss: 0.3961877226829529 acc: 0.841875\n600 loss: 0.3652478754520416 acc: 0.8653125\n800 loss: 0.2641378343105316 acc: 0.8946875\n1000 loss: 0.3198693096637726 acc: 0.89703125\n1200 loss: 0.3060196340084076 acc: 0.9040625\n1400 loss: 0.22825348377227783 acc: 0.91734374\n1600 loss: 0.20560911297798157 acc: 0.913125\n1800 loss: 0.2043185979127884 acc: 0.92859375\n2000 loss: 0.20112140476703644 acc: 0.9440625\n2200 loss: 0.1445087492465973 acc: 0.9290625\n2400 loss: 0.20331504940986633 acc: 0.92859375\n2600 loss: 0.2115728110074997 acc: 0.9375\n2800 loss: 0.12368302047252655 acc: 0.9375\n3000 loss: 0.223783478140831 acc: 0.9323437\n3200 loss: 0.15414217114448547 acc: 0.9359375\n3400 loss: 0.1362285017967224 acc: 0.93609375\n3600 loss: 0.11636339873075485 acc: 0.93890625\n3800 loss: 0.16760046780109406 acc: 0.9571875\n4000 loss: 0.1829649806022644 acc: 0.95203125\n4200 loss: 0.14509813487529755 acc: 0.93953127\n4400 loss: 0.1466638594865799 acc: 0.9478125\n4600 loss: 0.1797003448009491 acc: 0.9471875\n4800 loss: 0.12249323725700378 acc: 0.943125\n5000 loss: 0.12952658534049988 acc: 0.9507812\n5200 loss: 0.23184937238693237 acc: 0.94359374\n5400 loss: 0.23395024240016937 acc: 0.94890624\n5600 loss: 0.06808396428823471 acc: 0.96234375\n5800 loss: 0.1583397537469864 acc: 0.96\n6000 loss: 0.11696768552064896 acc: 0.95265627\n6200 loss: 0.18405260145664215 acc: 0.95\n6400 loss: 0.11138822138309479 acc: 0.955\n6600 loss: 0.11504591256380081 acc: 0.95453125\n6800 loss: 0.10775473713874817 acc: 0.95421875\n7000 loss: 0.08970574289560318 acc: 0.95515627\n7200 loss: 0.3122771680355072 acc: 0.9479687\n7400 loss: 0.1281985491514206 acc: 0.96046877\n7600 loss: 0.13917794823646545 acc: 0.968125\n7800 loss: 0.0952659398317337 acc: 0.9584375\n8000 loss: 0.16570565104484558 acc: 0.9554688\n8200 loss: 0.08961600065231323 acc: 0.9610937\n8400 loss: 0.0696832612156868 acc: 0.9578125\n8600 loss: 0.10723478347063065 acc: 0.9557812\n8800 loss: 0.13974449038505554 acc: 0.96015626\n9000 loss: 0.1230202317237854 acc: 0.95390624\n9200 loss: 0.06492430716753006 acc: 0.959375\n9400 loss: 0.06927461177110672 acc: 0.97125\n9600 loss: 0.14920657873153687 acc: 0.96703124\n9800 loss: 0.06501468271017075 acc: 0.95921874\n10000 loss: 0.15641359984874725 acc: 0.9615625\n10200 loss: 0.10766921192407608 acc: 0.96265626\n10400 loss: 0.12030448019504547 acc: 0.95921874\n10600 loss: 0.08242516964673996 acc: 0.9665625\n10800 loss: 0.1727081537246704 acc: 0.96203125\n11000 loss: 0.08029627799987793 acc: 0.9579688\n11200 loss: 0.10642281919717789 acc: 0.9671875\n11400 loss: 0.09304123371839523 acc: 0.97203124\n11600 loss: 0.12501290440559387 acc: 0.9646875\n11800 loss: 0.08484695851802826 acc: 0.9634375\n12000 loss: 0.07428934425115585 acc: 0.965625\n12200 loss: 0.05495837330818176 acc: 0.9659375\n12400 loss: 0.11762042343616486 acc: 0.9675\n12600 loss: 0.151103675365448 acc: 0.9634375\n12800 loss: 0.10832579433917999 acc: 0.96140623\n13000 loss: 0.08455835282802582 acc: 0.966875\n13200 loss: 0.1609054058790207 acc: 0.9740625\n13400 loss: 0.0891246572136879 acc: 0.97046876\n13600 loss: 0.07747111469507217 acc: 0.96625\n13800 loss: 0.09770138561725616 acc: 0.9689062\n14000 loss: 0.05070333182811737 acc: 0.9696875\n14200 loss: 0.2158481627702713 acc: 0.9685938\n14400 loss: 0.08815488964319229 acc: 0.9684375\n14600 loss: 0.17581474781036377 acc: 0.96421874\n14800 loss: 0.0552481971681118 acc: 0.9664062\n15000 loss: 0.08839568495750427 acc: 0.9767187\n15200 loss: 0.09077616780996323 acc: 0.973125\n15400 loss: 0.10798516869544983 acc: 0.9684375\n15600 loss: 0.07503052800893784 acc: 0.969375\n15800 loss: 0.07672557234764099 acc: 0.9714062\n16000 loss: 0.11776122450828552 acc: 0.9678125\n16200 loss: 0.10052350908517838 acc: 0.97078127\n16400 loss: 0.08148708194494247 acc: 0.97015625\n16600 loss: 0.05869223177433014 acc: 0.96546876\n16800 loss: 0.1035025343298912 acc: 0.9734375\n17000 loss: 0.08908426761627197 acc: 0.9784375\n17200 loss: 0.03126253932714462 acc: 0.97078127\n17400 loss: 0.06686735153198242 acc: 0.97046876\n17600 loss: 0.0823526531457901 acc: 0.9715625\n17800 loss: 0.04689529165625572 acc: 0.9721875\n18000 loss: 0.06467711180448532 acc: 0.973125\n18200 loss: 0.08291774243116379 acc: 0.970625\n18400 loss: 0.060939688235521317 acc: 0.96984375\n18600 loss: 0.04594184085726738 acc: 0.97\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}