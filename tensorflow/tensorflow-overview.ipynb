{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# https://github.com/dragen1860/TensorFlow-2.x-Tutorials/tree/master/01-TF2.0-Overview","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-09-10T18:43:38.104673Z","iopub.execute_input":"2021-09-10T18:43:38.105381Z","iopub.status.idle":"2021-09-10T18:43:38.110010Z","shell.execute_reply.started":"2021-09-10T18:43:38.105344Z","shell.execute_reply":"2021-09-10T18:43:38.108929Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Fully-connected Network\nimport os\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers, optimizers, datasets\n\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # or any {'0', '1', '2'}","metadata":{"execution":{"iopub.status.busy":"2021-09-10T18:43:38.777532Z","iopub.execute_input":"2021-09-10T18:43:38.778331Z","iopub.status.idle":"2021-09-10T18:43:43.733694Z","shell.execute_reply.started":"2021-09-10T18:43:38.778296Z","shell.execute_reply":"2021-09-10T18:43:43.732667Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"2021-09-10 18:43:39.351065: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n","output_type":"stream"}]},{"cell_type":"code","source":"# Load numpy data\n\nimport numpy as np\nimport tensorflow as tf\n\nDATA_URL = 'https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz'\n\npath = tf.keras.utils.get_file('mnist.npz', DATA_URL)\nwith np.load(path) as data:\n    train_examples = data['x_train']\n    train_labels = data['y_train']\n    test_examples = data['x_test']\n    test_labels = data['y_test']","metadata":{"execution":{"iopub.status.busy":"2021-09-10T18:43:47.747848Z","iopub.execute_input":"2021-09-10T18:43:47.748224Z","iopub.status.idle":"2021-09-10T18:43:48.491554Z","shell.execute_reply.started":"2021-09-10T18:43:47.748170Z","shell.execute_reply":"2021-09-10T18:43:48.490540Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n11493376/11490434 [==============================] - 0s 0us/step\n","output_type":"stream"}]},{"cell_type":"code","source":"print(type(train_examples), train_examples.shape)\nprint(type(test_examples), test_examples.shape)\nprint(type(train_labels), train_labels.shape)\nprint(type(test_labels), test_labels.shape)","metadata":{"execution":{"iopub.status.busy":"2021-09-10T18:43:48.495729Z","iopub.execute_input":"2021-09-10T18:43:48.496008Z","iopub.status.idle":"2021-09-10T18:43:48.508127Z","shell.execute_reply.started":"2021-09-10T18:43:48.495978Z","shell.execute_reply":"2021-09-10T18:43:48.504174Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"<class 'numpy.ndarray'> (60000, 28, 28)\n<class 'numpy.ndarray'> (10000, 28, 28)\n<class 'numpy.ndarray'> (60000,)\n<class 'numpy.ndarray'> (10000,)\n","output_type":"stream"}]},{"cell_type":"code","source":"train_dataset = tf.data.Dataset.from_tensor_slices((train_examples, train_labels))\ntest_dataset = tf.data.Dataset.from_tensor_slices((test_examples, test_labels))","metadata":{"execution":{"iopub.status.busy":"2021-09-10T18:43:48.686747Z","iopub.execute_input":"2021-09-10T18:43:48.687029Z","iopub.status.idle":"2021-09-10T18:43:50.793269Z","shell.execute_reply.started":"2021-09-10T18:43:48.687000Z","shell.execute_reply":"2021-09-10T18:43:50.791058Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"2021-09-10 18:43:48.691975: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n2021-09-10 18:43:48.706094: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n2021-09-10 18:43:48.759951: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-09-10 18:43:48.761021: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \npciBusID: 0000:00:04.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0\ncoreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s\n2021-09-10 18:43:48.761073: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n2021-09-10 18:43:48.788504: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n2021-09-10 18:43:48.788604: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n2021-09-10 18:43:48.808353: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n2021-09-10 18:43:48.817682: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n2021-09-10 18:43:48.844092: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n2021-09-10 18:43:48.851023: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n2021-09-10 18:43:48.854191: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n2021-09-10 18:43:48.854395: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-09-10 18:43:48.855505: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-09-10 18:43:48.857600: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n2021-09-10 18:43:48.860055: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2021-09-10 18:43:48.861510: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n2021-09-10 18:43:48.861681: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-09-10 18:43:48.862733: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \npciBusID: 0000:00:04.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0\ncoreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s\n2021-09-10 18:43:48.862820: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n2021-09-10 18:43:48.862860: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n2021-09-10 18:43:48.862896: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n2021-09-10 18:43:48.862939: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n2021-09-10 18:43:48.862973: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n2021-09-10 18:43:48.863007: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n2021-09-10 18:43:48.863043: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n2021-09-10 18:43:48.863077: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n2021-09-10 18:43:48.863223: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-09-10 18:43:48.864336: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-09-10 18:43:48.865317: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n2021-09-10 18:43:48.866604: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n2021-09-10 18:43:50.709817: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n2021-09-10 18:43:50.709892: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n2021-09-10 18:43:50.709914: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n2021-09-10 18:43:50.712595: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-09-10 18:43:50.713687: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-09-10 18:43:50.714660: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-09-10 18:43:50.715504: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14957 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"# Shuffle and batch the datasets\nBATCH_SIZE = 64\nSHUFFLE_BUFFER_SIZE = 100\n\ntrain_dataset = train_dataset.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)\ntest_dataset = test_dataset.batch(BATCH_SIZE)","metadata":{"execution":{"iopub.status.busy":"2021-09-10T18:43:50.795674Z","iopub.execute_input":"2021-09-10T18:43:50.796035Z","iopub.status.idle":"2021-09-10T18:43:50.806574Z","shell.execute_reply.started":"2021-09-10T18:43:50.795976Z","shell.execute_reply":"2021-09-10T18:43:50.805508Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def mnist_dataset():\n    (x, y), _ = datasets.mnist.load_data()\n    ds = tf.data.Dataset.from_tensor_slices((x, y))\n    ds = ds.map(prepare_mnist_features_and_labels)\n    # https://www.gcptutorials.com/article/how-to-use-map-function-with-tensorflow-datasets\n    ds = ds.take(20000).shuffle(20000).batch(100)\n    return ds\n\ndef prepare_mnist_features_and_labels(x, y):\n    x = tf.cast(x, tf.float32) / 255.0\n    y = tf.cast(y, tf.int64)\n    # https://www.tensorflow.org/api_docs/python/tf/cast\n    return x, y","metadata":{"execution":{"iopub.status.busy":"2021-09-10T18:43:50.809570Z","iopub.execute_input":"2021-09-10T18:43:50.810640Z","iopub.status.idle":"2021-09-10T18:43:50.821119Z","shell.execute_reply.started":"2021-09-10T18:43:50.810597Z","shell.execute_reply":"2021-09-10T18:43:50.819970Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"model = keras.Sequential([\n    layers.Reshape(target_shape=(28 * 28,), input_shape=(28, 28)),\n    layers.Dense(100, activation='relu'),\n    layers.Dense(100, activation='relu'),\n    layers.Dense(10)])\n\noptimizer = optimizers.Adam()","metadata":{"execution":{"iopub.status.busy":"2021-09-10T18:43:50.823962Z","iopub.execute_input":"2021-09-10T18:43:50.824360Z","iopub.status.idle":"2021-09-10T18:43:51.226044Z","shell.execute_reply.started":"2021-09-10T18:43:50.824310Z","shell.execute_reply":"2021-09-10T18:43:51.224997Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"With our data and model set up, we can start setting up the training procedure. For the methods here, we use the @tf.function AutoGraph decorator to pre-compile our methods as TensorFlow computational graphs. TensorFlow 2.0 is fully imperative, so the AutoGraph decorator isn't necessary for our code to work, but it speeds up execution and lets us take advantage of graph execution, so @tf.function is definitely worth using in our case.","metadata":{}},{"cell_type":"code","source":"@tf.function\ndef compute_loss(logits, labels):\n    return tf.reduce_mean(\n        tf.nn.sparse_softmax_cross_entropy_with_logits(\n            logits=logits, labels=labels))\n\n@tf.function\ndef compute_accuracy(logits, labels):\n    predictions = tf.argmax(logits, axis=1)\n    return tf.reduce_mean(tf.cast(tf.equal(predictions, labels), tf.float32))\n\n@tf.function\ndef train_one_step(model, optimizer, x, y):\n\n    with tf.GradientTape() as tape:\n        logits = model(x)\n        loss = compute_loss(logits, y)\n\n  # compute gradient\n    grads = tape.gradient(loss, model.trainable_variables)\n    # https://www.tensorflow.org/api_docs/python/tf/GradientTape\n  # update to weights\n    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n  # https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Optimizer\n\n    accuracy = compute_accuracy(logits, y)\n\n  # loss and accuracy is scalar tensor\n    return loss, accuracy\n\ndef train(epoch, model, optimizer):\n\n    train_ds = mnist_dataset()\n    loss = 0.0\n    accuracy = 0.0\n    for step, (x, y) in enumerate(train_ds):\n        loss, accuracy = train_one_step(model, optimizer, x, y)\n\n        if step % 500 == 0:\n            print('epoch', epoch, ': loss', loss.numpy(), '; accuracy', accuracy.numpy())\n\n    return loss, accuracy","metadata":{"execution":{"iopub.status.busy":"2021-09-10T18:43:51.228113Z","iopub.execute_input":"2021-09-10T18:43:51.228478Z","iopub.status.idle":"2021-09-10T18:43:51.242096Z","shell.execute_reply.started":"2021-09-10T18:43:51.228428Z","shell.execute_reply":"2021-09-10T18:43:51.240975Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"Now that we have our training procedure set up, we can throw it in a loop and start training!","metadata":{}},{"cell_type":"code","source":"for epoch in range(20):\n    loss, accuracy = train(epoch, model, optimizer)\n\nprint('Final epoch', epoch, ': loss', loss.numpy(), '; accuracy', accuracy.numpy())","metadata":{"execution":{"iopub.status.busy":"2021-09-10T18:43:51.626246Z","iopub.execute_input":"2021-09-10T18:43:51.631739Z","iopub.status.idle":"2021-09-10T18:44:22.578473Z","shell.execute_reply.started":"2021-09-10T18:43:51.631681Z","shell.execute_reply":"2021-09-10T18:44:22.576636Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":"2021-09-10 18:43:52.474113: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n2021-09-10 18:43:52.479424: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199995000 Hz\n2021-09-10 18:43:53.812139: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n2021-09-10 18:43:54.734546: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n","output_type":"stream"},{"name":"stdout","text":"epoch 0 : loss 2.3214438 ; accuracy 0.06\nepoch 1 : loss 0.26186752 ; accuracy 0.93\nepoch 2 : loss 0.1625739 ; accuracy 0.94\nepoch 3 : loss 0.060843468 ; accuracy 0.99\nepoch 4 : loss 0.07338034 ; accuracy 0.98\nepoch 5 : loss 0.017805804 ; accuracy 1.0\nepoch 6 : loss 0.018908933 ; accuracy 1.0\nepoch 7 : loss 0.019537352 ; accuracy 1.0\nepoch 8 : loss 0.028114202 ; accuracy 1.0\nepoch 9 : loss 0.015089001 ; accuracy 1.0\nepoch 10 : loss 0.028484225 ; accuracy 1.0\nepoch 11 : loss 0.054152954 ; accuracy 0.99\nepoch 12 : loss 0.006558891 ; accuracy 1.0\nepoch 13 : loss 0.00673928 ; accuracy 1.0\nepoch 14 : loss 0.008107851 ; accuracy 1.0\nepoch 15 : loss 0.011208303 ; accuracy 1.0\nepoch 16 : loss 0.0044960077 ; accuracy 1.0\nepoch 17 : loss 0.0022714527 ; accuracy 1.0\nepoch 18 : loss 0.012544717 ; accuracy 0.99\nepoch 19 : loss 0.002500914 ; accuracy 1.0\nFinal epoch 19 : loss 0.028578045 ; accuracy 0.99\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Convolutional Network\n\nNow that we've gotten our feet we with a simple DNN, let's try something more advanced. Although the process is the same, we'll be working with some additional features:\n\n- Convolution, pooling, and dropout layers for building more complex models\n- Visualizing training with TensorBoard\n- Validation and test set evaluation for measuring generalizability\n- Exporting with SavedModel to save training progress and deploy trained models\n\nAs usual, we'll start by preparing our MNIST data.","metadata":{}},{"cell_type":"code","source":"import os\nimport time\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.python.ops import summary_ops_v2\nfrom tensorflow import keras\nfrom tensorflow.keras import datasets, layers, models, optimizers, metrics\n\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # or any {'0', '1', '2'}","metadata":{"execution":{"iopub.status.busy":"2021-09-10T18:44:22.580975Z","iopub.execute_input":"2021-09-10T18:44:22.581382Z","iopub.status.idle":"2021-09-10T18:44:22.588630Z","shell.execute_reply.started":"2021-09-10T18:44:22.581336Z","shell.execute_reply":"2021-09-10T18:44:22.587081Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def mnist_datasets():\n    (x_train, y_train), (x_test, y_test) = datasets.mnist.load_data()\n    # Numpy defaults to dtype=float64; TF defaults to float32. Stick with float32.\n    x_train, x_test = x_train / np.float32(255), x_test / np.float32(255)\n    y_train, y_test = y_train.astype(np.int64), y_test.astype(np.int64)\n    train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n    test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n    return train_dataset, test_dataset\n\n\ntrain_ds, test_ds = mnist_datasets()\ntrain_ds = train_ds.shuffle(60000).batch(100)\ntest_ds = test_ds.batch(100)","metadata":{"execution":{"iopub.status.busy":"2021-09-10T18:44:22.590543Z","iopub.execute_input":"2021-09-10T18:44:22.591694Z","iopub.status.idle":"2021-09-10T18:44:23.165295Z","shell.execute_reply.started":"2021-09-10T18:44:22.591648Z","shell.execute_reply":"2021-09-10T18:44:23.164222Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"type(train_ds)","metadata":{"execution":{"iopub.status.busy":"2021-09-10T18:44:23.168123Z","iopub.execute_input":"2021-09-10T18:44:23.168503Z","iopub.status.idle":"2021-09-10T18:44:23.178185Z","shell.execute_reply.started":"2021-09-10T18:44:23.168455Z","shell.execute_reply":"2021-09-10T18:44:23.176682Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"tensorflow.python.data.ops.dataset_ops.BatchDataset"},"metadata":{}}]},{"cell_type":"markdown","source":"Now, let's use use Conv2D, MaxPooling2D, and Dropout from keras.layers to build a keras.Sequential convolutional model.","metadata":{}},{"cell_type":"code","source":"model = tf.keras.Sequential([\n    layers.Reshape(\n        target_shape=[28, 28, 1],\n        input_shape=(28, 28,)),\n    layers.Conv2D(2, 5, padding='same', activation=tf.nn.relu),\n    layers.MaxPooling2D((2, 2), (2, 2), padding='same'),\n    layers.Conv2D(4, 5, padding='same', activation=tf.nn.relu),\n    layers.MaxPooling2D((2, 2), (2, 2), padding='same'),\n    layers.Flatten(),\n    layers.Dense(32, activation=tf.nn.relu),\n    layers.Dropout(rate=0.4),\n    layers.Dense(10)])\n\noptimizer = optimizers.SGD(learning_rate=0.01, momentum=0.5)","metadata":{"execution":{"iopub.status.busy":"2021-09-10T18:44:23.180114Z","iopub.execute_input":"2021-09-10T18:44:23.180552Z","iopub.status.idle":"2021-09-10T18:44:23.270935Z","shell.execute_reply.started":"2021-09-10T18:44:23.180505Z","shell.execute_reply":"2021-09-10T18:44:23.269950Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"Next, let's set up forward and backward functionality. In addition to the training procedure, we'll also write test() a method for evaluation, and use **tf.python.summary_ops_v2** to record training summaries to TensorBoard.","metadata":{}},{"cell_type":"code","source":"compute_loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\ncompute_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n\ndef train_step(model, optimizer, images, labels):\n\n    # Record the operations used to compute the loss, so that the gradient\n    # of the loss with respect to the variables can be computed.\n    with tf.GradientTape() as tape:\n        logits = model(images, training=True)\n        loss = compute_loss(labels, logits)\n        compute_accuracy(labels, logits)\n\n    grads = tape.gradient(loss, model.trainable_variables)\n    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n\n    return loss\n\ndef train(model, optimizer, dataset, log_freq=50):\n    \"\"\"\n    Trains model on `dataset` using `optimizer`.\n    \"\"\"\n    # Metrics are stateful. They accumulate values and return a cumulative\n    # result when you call .result(). Clear accumulated values with .reset_states()\n    avg_loss = metrics.Mean('loss', dtype=tf.float32)\n\n    # Datasets can be iterated over like any other Python iterable.\n    for images, labels in dataset:\n        loss = train_step(model, optimizer, images, labels)\n        avg_loss(loss)\n\n        if tf.equal(optimizer.iterations % log_freq, 0):\n            # summary_ops_v2.scalar('loss', avg_loss.result(), step=optimizer.iterations)\n            # summary_ops_v2.scalar('accuracy', compute_accuracy.result(), step=optimizer.iterations)\n            print('step:', int(optimizer.iterations),\n                  'loss:', avg_loss.result().numpy(),\n                  'acc:', compute_accuracy.result().numpy())\n            avg_loss.reset_states()\n            compute_accuracy.reset_states()\n\ndef test(model, dataset, step_num):\n    \"\"\"\n    Perform an evaluation of `model` on the examples from `dataset`.\n    \"\"\"\n    avg_loss = metrics.Mean('loss', dtype=tf.float32)\n\n    for (images, labels) in dataset:\n        logits = model(images, training=False)\n        avg_loss(compute_loss(labels, logits))\n        compute_accuracy(labels, logits)\n\n    print('Model test set loss: {:0.4f} accuracy: {:0.2f}%'.format(\n        avg_loss.result(), compute_accuracy.result() * 100))\n\n    print('loss:', avg_loss.result(), 'acc:', compute_accuracy.result())\n    # summary_ops_v2.scalar('loss', avg_loss.result(), step=step_num)\n    # summary_ops_v2.scalar('accuracy', compute_accuracy.result(), step=step_num)","metadata":{"execution":{"iopub.status.busy":"2021-09-10T18:44:23.272287Z","iopub.execute_input":"2021-09-10T18:44:23.272623Z","iopub.status.idle":"2021-09-10T18:44:23.298709Z","shell.execute_reply.started":"2021-09-10T18:44:23.272566Z","shell.execute_reply":"2021-09-10T18:44:23.297664Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"Now that we have our data, model, and training procedure ready, we just need to designate a directory and create a **tf.train.Checkpoint** file to save our parameters to as we train.","metadata":{}},{"cell_type":"code","source":"# Where to save checkpoints, tensorboard summaries, etc.\nMODEL_DIR = '../kaggle/working/'\n\n\ndef apply_clean():\n    if tf.io.gfile.exists(MODEL_DIR):\n        print('Removing existing model dir: {}'.format(MODEL_DIR))\n        tf.io.gfile.rmtree(MODEL_DIR)\n\n\napply_clean()\n\ncheckpoint_dir = os.path.join(MODEL_DIR, 'checkpoints')\ncheckpoint_prefix = os.path.join(checkpoint_dir, 'ckpt')\n\ncheckpoint = tf.train.Checkpoint(model=model, optimizer=optimizer)\n\n# Restore variables on creation if a checkpoint exists.\ncheckpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))","metadata":{"execution":{"iopub.status.busy":"2021-09-10T18:50:01.639533Z","iopub.execute_input":"2021-09-10T18:50:01.639874Z","iopub.status.idle":"2021-09-10T18:50:01.657694Z","shell.execute_reply.started":"2021-09-10T18:50:01.639841Z","shell.execute_reply":"2021-09-10T18:50:01.656293Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"<tensorflow.python.training.tracking.util.InitializationOnlyStatus at 0x7f4bd1db2290>"},"metadata":{}}]},{"cell_type":"markdown","source":"We're finally ready to start training!","metadata":{}},{"cell_type":"code","source":"NUM_TRAIN_EPOCHS = 5\n\nfor i in range(NUM_TRAIN_EPOCHS):\n    start = time.time()\n    #   with train_summary_writer.as_default():\n    train(model, optimizer, train_ds, log_freq=500)\n    end = time.time()\n    print('Train time for epoch #{} ({} total steps): {}'.format(\n        i + 1, int(optimizer.iterations), end - start))\n    #   with test_summary_writer.as_default():\n    #     test(model, test_ds, optimizer.iterations)\n    checkpoint.save(checkpoint_prefix)\n    print('saved checkpoint.')\n\nexport_path = os.path.join(MODEL_DIR, 'export')\ntf.saved_model.save(model, export_path)\nprint('saved SavedModel for exporting.')","metadata":{"execution":{"iopub.status.busy":"2021-09-10T18:51:17.214687Z","iopub.execute_input":"2021-09-10T18:51:17.215564Z","iopub.status.idle":"2021-09-10T18:52:20.505484Z","shell.execute_reply.started":"2021-09-10T18:51:17.215522Z","shell.execute_reply":"2021-09-10T18:52:20.503534Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stderr","text":"2021-09-10 18:51:17.678750: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n","output_type":"stream"},{"name":"stdout","text":"step: 500 loss: 1.9935889 acc: 0.29872\nTrain time for epoch #1 (600 total steps): 16.93648338317871\nsaved checkpoint.\nstep: 1000 loss: 0.7801143 acc: 0.72106\nTrain time for epoch #2 (1200 total steps): 11.061720609664917\nsaved checkpoint.\nstep: 1500 loss: 0.566319 acc: 0.80318\nTrain time for epoch #3 (1800 total steps): 11.447207927703857\nsaved checkpoint.\nstep: 2000 loss: 0.43725118 acc: 0.85012\nTrain time for epoch #4 (2400 total steps): 11.01601529121399\nsaved checkpoint.\nstep: 2500 loss: 0.36324552 acc: 0.8743\nstep: 3000 loss: 0.34172356 acc: 0.89308\nTrain time for epoch #5 (3000 total steps): 11.19942331314087\nsaved checkpoint.\n","output_type":"stream"},{"name":"stderr","text":"2021-09-10 18:52:19.543997: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n","output_type":"stream"},{"name":"stdout","text":"saved SavedModel for exporting.\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}