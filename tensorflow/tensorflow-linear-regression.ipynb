{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# https://github.com/dragen1860/TensorFlow-2.x-Tutorials/blob/master/04-Linear-Regression/main.py","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-09-17T02:28:58.657572Z","iopub.execute_input":"2021-09-17T02:28:58.658079Z","iopub.status.idle":"2021-09-17T02:28:58.668743Z","shell.execute_reply.started":"2021-09-17T02:28:58.658009Z","shell.execute_reply":"2021-09-17T02:28:58.668035Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import  tensorflow as tf\nimport  numpy as np\nfrom    tensorflow import keras\nimport  os","metadata":{"execution":{"iopub.status.busy":"2021-09-17T02:29:13.495865Z","iopub.execute_input":"2021-09-17T02:29:13.496129Z","iopub.status.idle":"2021-09-17T02:29:18.061832Z","shell.execute_reply.started":"2021-09-17T02:29:13.496100Z","shell.execute_reply":"2021-09-17T02:29:18.061038Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"2021-09-17 02:29:14.096595: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n","output_type":"stream"}]},{"cell_type":"code","source":"class Regressor(keras.layers.Layer):\n\n    def __init__(self):\n        super(Regressor, self).__init__()\n\n        # here must specify shape instead of tensor !\n        # name here is meanless !\n        # [dim_in, dim_out]\n        self.w = self.add_variable('meanless-name', [13, 1])\n        # [dim_out]\n        self.b = self.add_variable('meanless-name', [1])\n\n        print(self.w.shape, self.b.shape)\n        print(type(self.w), tf.is_tensor(self.w), self.w.name)\n        print(type(self.b), tf.is_tensor(self.b), self.b.name)\n\n\n    def call(self, x):\n\n        x = tf.matmul(x, self.w) + self.b\n\n        return x","metadata":{"execution":{"iopub.status.busy":"2021-09-17T02:29:19.169939Z","iopub.execute_input":"2021-09-17T02:29:19.170203Z","iopub.status.idle":"2021-09-17T02:29:19.177077Z","shell.execute_reply.started":"2021-09-17T02:29:19.170175Z","shell.execute_reply":"2021-09-17T02:29:19.176251Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"def main():\n\n    tf.random.set_seed(22)\n    np.random.seed(22)\n    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n    assert tf.__version__.startswith('2.')\n\n\n    (x_train, y_train), (x_val, y_val) = keras.datasets.boston_housing.load_data()\n    #\n    print(x_train.shape, y_train.shape, type(x_train), type(y_train))\n    x_train, x_val = x_train.astype(np.float32), x_val.astype(np.float32)\n    # (404, 13) (404,) (102, 13) (102,)\n    print(x_train.shape, y_train.shape, x_val.shape, y_val.shape)\n    # Here has two mis-leading issues:\n    # 1. (x_train, y_train) cant be written as [x_train, y_train]\n    # 2.\n    db_train = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(64)\n    db_val = tf.data.Dataset.from_tensor_slices((x_val, y_val)).batch(102)\n\n\n    model = Regressor()\n    criteon = keras.losses.MeanSquaredError()\n    optimizer = keras.optimizers.Adam(learning_rate=1e-2)\n\n    for epoch in range(200):\n\n        for step, (x, y) in enumerate(db_train):\n\n            with tf.GradientTape() as tape:\n                # [b, 1]\n                logits = model(x)\n                # [b]\n                #print(logits.shape)\n                logits = tf.squeeze(logits, axis=1)\n                #print(logits.shape)\n                # [b] vs [b]\n                loss = criteon(y, logits)\n\n            grads = tape.gradient(loss, model.trainable_variables)\n            optimizer.apply_gradients(zip(grads, model.trainable_variables))\n\n        print(epoch, 'loss:', loss.numpy())\n\n\n        if epoch % 10 == 0:\n\n            for x, y in db_val:\n                # [b, 1]\n                logits = model(x)\n                # [b]\n                logits = tf.squeeze(logits, axis=1)\n                # [b] vs [b]\n                loss = criteon(y, logits)\n\n                print(epoch, 'val loss:', loss.numpy())\nif __name__ == '__main__':\n    main()","metadata":{"execution":{"iopub.status.busy":"2021-09-17T02:29:20.325155Z","iopub.execute_input":"2021-09-17T02:29:20.325412Z","iopub.status.idle":"2021-09-17T02:29:31.125483Z","shell.execute_reply.started":"2021-09-17T02:29:20.325382Z","shell.execute_reply":"2021-09-17T02:29:31.124695Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/boston_housing.npz\n57344/57026 [==============================] - 0s 0us/step\n(404, 13) (404,) <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n(404, 13) (404,) (102, 13) (102,)\n","output_type":"stream"},{"name":"stderr","text":"2021-09-17 02:29:20.657501: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n2021-09-17 02:29:20.660798: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n2021-09-17 02:29:20.712262: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-09-17 02:29:20.712919: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \npciBusID: 0000:00:04.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0\ncoreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s\n2021-09-17 02:29:20.712975: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n2021-09-17 02:29:20.747838: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n2021-09-17 02:29:20.747918: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n2021-09-17 02:29:20.765884: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n2021-09-17 02:29:20.792499: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n2021-09-17 02:29:20.824513: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n2021-09-17 02:29:20.831919: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n2021-09-17 02:29:20.834476: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n2021-09-17 02:29:20.834641: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-09-17 02:29:20.835321: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-09-17 02:29:20.836824: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n2021-09-17 02:29:20.838409: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2021-09-17 02:29:20.839414: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n2021-09-17 02:29:20.839586: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-09-17 02:29:20.840200: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \npciBusID: 0000:00:04.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0\ncoreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s\n2021-09-17 02:29:20.840243: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n2021-09-17 02:29:20.840269: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n2021-09-17 02:29:20.840288: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n2021-09-17 02:29:20.840306: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n2021-09-17 02:29:20.840325: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n2021-09-17 02:29:20.840343: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n2021-09-17 02:29:20.840362: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n2021-09-17 02:29:20.840381: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n2021-09-17 02:29:20.840485: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-09-17 02:29:20.841108: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-09-17 02:29:20.841654: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n2021-09-17 02:29:20.843067: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n2021-09-17 02:29:22.294872: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n2021-09-17 02:29:22.294929: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n2021-09-17 02:29:22.294941: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n2021-09-17 02:29:22.296820: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-09-17 02:29:22.297566: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-09-17 02:29:22.298235: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2021-09-17 02:29:22.298827: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14957 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py:2281: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n  warnings.warn('`layer.add_variable` is deprecated and '\n","output_type":"stream"},{"name":"stdout","text":"(13, 1) (1,)\n<class 'tensorflow.python.ops.resource_variable_ops.ResourceVariable'> True meanless-name:0\n<class 'tensorflow.python.ops.resource_variable_ops.ResourceVariable'> True meanless-name:0\n","output_type":"stream"},{"name":"stderr","text":"2021-09-17 02:29:22.659013: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n2021-09-17 02:29:23.461316: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n","output_type":"stream"},{"name":"stdout","text":"0 loss: 39694.82\n0 val loss: 36500.332\n1 loss: 18709.125\n2 loss: 6534.4346\n3 loss: 1271.5068\n4 loss: 51.908894\n5 loss: 236.74033\n6 loss: 401.17242\n7 loss: 293.07904\n8 loss: 127.253456\n9 loss: 48.899597\n10 loss: 42.268055\n10 val loss: 124.677574\n11 loss: 49.233555\n12 loss: 47.356434\n13 loss: 42.244324\n14 loss: 39.96755\n15 loss: 39.8223\n16 loss: 39.752235\n17 loss: 39.398033\n18 loss: 39.110874\n19 loss: 38.935944\n20 loss: 38.738983\n20 val loss: 120.3187\n21 loss: 38.48421\n22 loss: 38.20948\n23 loss: 37.93725\n24 loss: 37.667336\n25 loss: 37.395905\n26 loss: 37.119164\n27 loss: 36.833477\n28 loss: 36.537876\n29 loss: 36.234398\n30 loss: 35.92582\n30 val loss: 114.442184\n31 loss: 35.61399\n32 loss: 35.299515\n33 loss: 34.982445\n34 loss: 34.662853\n35 loss: 34.34115\n36 loss: 34.01806\n37 loss: 33.694305\n38 loss: 33.370476\n39 loss: 33.047012\n40 loss: 32.72424\n40 val loss: 107.79624\n41 loss: 32.402504\n42 loss: 32.082157\n43 loss: 31.76353\n44 loss: 31.446949\n45 loss: 31.13268\n46 loss: 30.820965\n47 loss: 30.512033\n48 loss: 30.206081\n49 loss: 29.90329\n50 loss: 29.603836\n50 val loss: 101.2273\n51 loss: 29.30787\n52 loss: 29.015537\n53 loss: 28.726965\n54 loss: 28.442265\n55 loss: 28.16154\n56 loss: 27.884882\n57 loss: 27.612377\n58 loss: 27.34411\n59 loss: 27.08014\n60 loss: 26.820505\n60 val loss: 95.07061\n61 loss: 26.565292\n62 loss: 26.314514\n63 loss: 26.068233\n64 loss: 25.826466\n65 loss: 25.58925\n66 loss: 25.356602\n67 loss: 25.128523\n68 loss: 24.90504\n69 loss: 24.686152\n70 loss: 24.471865\n70 val loss: 89.49144\n71 loss: 24.262169\n72 loss: 24.05706\n73 loss: 23.856522\n74 loss: 23.660542\n75 loss: 23.469097\n76 loss: 23.282177\n77 loss: 23.099747\n78 loss: 22.921776\n79 loss: 22.748238\n80 loss: 22.579092\n80 val loss: 84.54922\n81 loss: 22.414314\n82 loss: 22.253849\n83 loss: 22.097668\n84 loss: 21.945713\n85 loss: 21.79795\n86 loss: 21.654333\n87 loss: 21.51481\n88 loss: 21.37932\n89 loss: 21.247826\n90 loss: 21.120266\n90 val loss: 80.23585\n91 loss: 20.996588\n92 loss: 20.87673\n93 loss: 20.760641\n94 loss: 20.648258\n95 loss: 20.539532\n96 loss: 20.434393\n97 loss: 20.332785\n98 loss: 20.23465\n99 loss: 20.139921\n100 loss: 20.048544\n100 val loss: 76.50178\n101 loss: 19.960445\n102 loss: 19.875578\n103 loss: 19.793869\n104 loss: 19.71526\n105 loss: 19.639694\n106 loss: 19.567099\n107 loss: 19.497417\n108 loss: 19.430592\n109 loss: 19.366556\n110 loss: 19.305248\n110 val loss: 73.276215\n111 loss: 19.246609\n112 loss: 19.190586\n113 loss: 19.137104\n114 loss: 19.086117\n115 loss: 19.03756\n116 loss: 18.991371\n117 loss: 18.947506\n118 loss: 18.905891\n119 loss: 18.86648\n120 loss: 18.829214\n120 val loss: 70.481636\n121 loss: 18.79404\n122 loss: 18.760904\n123 loss: 18.72975\n124 loss: 18.700527\n125 loss: 18.673183\n126 loss: 18.647667\n127 loss: 18.62393\n128 loss: 18.60192\n129 loss: 18.58159\n130 loss: 18.562887\n130 val loss: 68.04348\n131 loss: 18.545773\n132 loss: 18.5302\n133 loss: 18.516119\n134 loss: 18.503489\n135 loss: 18.492264\n136 loss: 18.482405\n137 loss: 18.473867\n138 loss: 18.466614\n139 loss: 18.460598\n140 loss: 18.455795\n140 val loss: 65.89558\n141 loss: 18.45215\n142 loss: 18.449635\n143 loss: 18.448208\n144 loss: 18.44784\n145 loss: 18.448498\n146 loss: 18.450138\n147 loss: 18.452736\n148 loss: 18.456264\n149 loss: 18.460674\n150 loss: 18.465954\n150 val loss: 63.982597\n151 loss: 18.472061\n152 loss: 18.478973\n153 loss: 18.48666\n154 loss: 18.49509\n155 loss: 18.504242\n156 loss: 18.514091\n157 loss: 18.52461\n158 loss: 18.53577\n159 loss: 18.547552\n160 loss: 18.559937\n160 val loss: 62.26008\n161 loss: 18.57289\n162 loss: 18.586403\n163 loss: 18.600443\n164 loss: 18.615\n165 loss: 18.630045\n166 loss: 18.645557\n167 loss: 18.661526\n168 loss: 18.677927\n169 loss: 18.694754\n170 loss: 18.711975\n170 val loss: 60.693516\n171 loss: 18.729578\n172 loss: 18.747553\n173 loss: 18.765875\n174 loss: 18.78453\n175 loss: 18.803509\n176 loss: 18.822788\n177 loss: 18.842365\n178 loss: 18.862225\n179 loss: 18.882349\n180 loss: 18.902725\n180 val loss: 59.256615\n181 loss: 18.92334\n182 loss: 18.944187\n183 loss: 18.965252\n184 loss: 18.98652\n185 loss: 19.007978\n186 loss: 19.029629\n187 loss: 19.051453\n188 loss: 19.073442\n189 loss: 19.095581\n190 loss: 19.11787\n190 val loss: 57.929447\n191 loss: 19.140295\n192 loss: 19.162851\n193 loss: 19.185524\n194 loss: 19.208303\n195 loss: 19.231188\n196 loss: 19.254168\n197 loss: 19.277237\n198 loss: 19.300377\n199 loss: 19.323597\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}