{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# https://github.com/dragen1860/TensorFlow-2.x-Tutorials/blob/master/14-Pixel2Pixel\n# https://ai.plainenglish.io/understanding-pix2pix-gan-e21c2bedd213\n# https://medium.com/@ma.bagheri/a-tutorial-on-conditional-generative-adversarial-nets-keras-implementation-694dcafa6282\n# https://medium.datadriveninvestor.com/an-introduction-to-conditional-gans-cgans-727d1f5bb011\n# https://sahiltinky94.medium.com/understanding-patchgan-9f3c8380c207\n# https://medium.com/swlh/build-a-pix2pix-gan-with-python-6db841b302c7","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-09-29T19:40:51.870525Z","iopub.execute_input":"2021-09-29T19:40:51.871475Z","iopub.status.idle":"2021-09-29T19:40:51.889012Z","shell.execute_reply.started":"2021-09-29T19:40:51.871372Z","shell.execute_reply":"2021-09-29T19:40:51.888138Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import  os\nimport  tensorflow as tf\nimport  numpy as np\nfrom    tensorflow import keras","metadata":{"execution":{"iopub.status.busy":"2021-09-29T19:40:55.958960Z","iopub.execute_input":"2021-09-29T19:40:55.959296Z","iopub.status.idle":"2021-09-29T19:41:01.658856Z","shell.execute_reply.started":"2021-09-29T19:40:55.959267Z","shell.execute_reply":"2021-09-29T19:41:01.657719Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"class Downsample(keras.Model):\n\n    def __init__(self, filters, size, apply_batchnorm=True):\n        super(Downsample, self).__init__()\n        \n        self.apply_batchnorm = apply_batchnorm\n        initializer = tf.random_normal_initializer(0., 0.02)\n\n        self.conv1 = keras.layers.Conv2D(filters,\n                                            (size, size),\n                                            strides=2,\n                                            padding='same',\n                                            kernel_initializer=initializer,\n                                            use_bias=False)\n        if self.apply_batchnorm:\n            self.batchnorm = keras.layers.BatchNormalization()\n\n    def call(self, x, training):\n        x = self.conv1(x)\n        if self.apply_batchnorm:\n            x = self.batchnorm(x, training=training)\n        x = tf.nn.leaky_relu(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2021-09-29T19:41:31.631010Z","iopub.execute_input":"2021-09-29T19:41:31.631296Z","iopub.status.idle":"2021-09-29T19:41:31.642776Z","shell.execute_reply.started":"2021-09-29T19:41:31.631268Z","shell.execute_reply":"2021-09-29T19:41:31.641441Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"class Upsample(keras.Model):\n\n    def __init__(self, filters, size, apply_dropout=False):\n        super(Upsample, self).__init__()\n        \n        self.apply_dropout = apply_dropout\n        initializer = tf.random_normal_initializer(0., 0.02)\n\n        self.up_conv = keras.layers.Conv2DTranspose(filters,\n                                                       (size, size),\n                                                       strides=2,\n                                                       padding='same',\n                                                       kernel_initializer=initializer,\n                                                       use_bias=False)\n        self.batchnorm = keras.layers.BatchNormalization()\n        if self.apply_dropout:\n            self.dropout = keras.layers.Dropout(0.5)\n\n    def call(self, x1, x2, training=None):\n\n        x = self.up_conv(x1)\n        x = self.batchnorm(x, training=training)\n        if self.apply_dropout:\n            x = self.dropout(x, training=training)\n        x = tf.nn.relu(x)\n        x = tf.concat([x, x2], axis=-1)\n        return x","metadata":{"execution":{"iopub.status.busy":"2021-09-29T19:41:32.490915Z","iopub.execute_input":"2021-09-29T19:41:32.491547Z","iopub.status.idle":"2021-09-29T19:41:32.502949Z","shell.execute_reply.started":"2021-09-29T19:41:32.491514Z","shell.execute_reply":"2021-09-29T19:41:32.501949Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"class Generator(keras.Model):\n\n    def __init__(self):\n        super(Generator, self).__init__()\n\n        initializer = tf.random_normal_initializer(0., 0.02)\n\n        self.down1 = Downsample(64, 4, apply_batchnorm=False)\n        self.down2 = Downsample(128, 4)\n        self.down3 = Downsample(256, 4)\n        self.down4 = Downsample(512, 4)\n        self.down5 = Downsample(512, 4)\n        self.down6 = Downsample(512, 4)\n        self.down7 = Downsample(512, 4)\n        self.down8 = Downsample(512, 4)\n\n        self.up1 = Upsample(512, 4, apply_dropout=True)\n        self.up2 = Upsample(512, 4, apply_dropout=True)\n        self.up3 = Upsample(512, 4, apply_dropout=True)\n        self.up4 = Upsample(512, 4)\n        self.up5 = Upsample(256, 4)\n        self.up6 = Upsample(128, 4)\n        self.up7 = Upsample(64, 4)\n\n        self.last = keras.layers.Conv2DTranspose(3, (4, 4),\n                                                    strides=2,\n                                                    padding='same',\n                                                    kernel_initializer=initializer)\n\n\n    def call(self, x, training=None):\n\n        # x shape == (bs, 256, 256, 3)    \n        x1 = self.down1(x, training=training)  # (bs, 128, 128, 64)\n        x2 = self.down2(x1, training=training)  # (bs, 64, 64, 128)\n        x3 = self.down3(x2, training=training)  # (bs, 32, 32, 256)\n        x4 = self.down4(x3, training=training)  # (bs, 16, 16, 512)\n        x5 = self.down5(x4, training=training)  # (bs, 8, 8, 512)\n        x6 = self.down6(x5, training=training)  # (bs, 4, 4, 512)\n        x7 = self.down7(x6, training=training)  # (bs, 2, 2, 512)\n        x8 = self.down8(x7, training=training)  # (bs, 1, 1, 512)\n\n        x9 = self.up1(x8, x7, training=training)  # (bs, 2, 2, 1024)\n        x10 = self.up2(x9, x6, training=training)  # (bs, 4, 4, 1024)\n        x11 = self.up3(x10, x5, training=training)  # (bs, 8, 8, 1024)\n        x12 = self.up4(x11, x4, training=training)  # (bs, 16, 16, 1024)\n        x13 = self.up5(x12, x3, training=training)  # (bs, 32, 32, 512)\n        x14 = self.up6(x13, x2, training=training)  # (bs, 64, 64, 256)\n        x15 = self.up7(x14, x1, training=training)  # (bs, 128, 128, 128)\n\n        x16 = self.last(x15)  # (bs, 256, 256, 3)\n        x16 = tf.nn.tanh(x16)\n\n        return x16","metadata":{"execution":{"iopub.status.busy":"2021-09-29T19:41:33.866348Z","iopub.execute_input":"2021-09-29T19:41:33.866657Z","iopub.status.idle":"2021-09-29T19:41:33.885316Z","shell.execute_reply.started":"2021-09-29T19:41:33.866629Z","shell.execute_reply":"2021-09-29T19:41:33.884244Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"class DiscDownsample(keras.Model):\n\n    def __init__(self, filters, size, apply_batchnorm=True):\n        super(DiscDownsample, self).__init__()\n\n        self.apply_batchnorm = apply_batchnorm\n        initializer = tf.random_normal_initializer(0., 0.02)\n\n        self.conv1 = keras.layers.Conv2D(filters, (size, size),\n                                            strides=2,\n                                            padding='same',\n                                            kernel_initializer=initializer,\n                                            use_bias=False)\n        if self.apply_batchnorm:\n            self.batchnorm = keras.layers.BatchNormalization()\n\n    def call(self, x, training=None):\n\n        x = self.conv1(x)\n        if self.apply_batchnorm:\n            x = self.batchnorm(x, training=training)\n        x = tf.nn.leaky_relu(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2021-09-29T19:41:34.527284Z","iopub.execute_input":"2021-09-29T19:41:34.528148Z","iopub.status.idle":"2021-09-29T19:41:34.536220Z","shell.execute_reply.started":"2021-09-29T19:41:34.528113Z","shell.execute_reply":"2021-09-29T19:41:34.535203Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"class Discriminator(keras.Model):\n\n    def __init__(self):\n        super(Discriminator, self).__init__()\n\n        initializer = tf.random_normal_initializer(0., 0.02)\n\n        self.down1 = DiscDownsample(64, 4, False)\n        self.down2 = DiscDownsample(128, 4)\n        self.down3 = DiscDownsample(256, 4)\n\n        # we are zero padding here with 1 because we need our shape to \n        # go from (batch_size, 32, 32, 256) to (batch_size, 31, 31, 512)\n        self.zero_pad1 = keras.layers.ZeroPadding2D()\n        self.conv = keras.layers.Conv2D(512, (4, 4),\n                                           strides=1,\n                                           kernel_initializer=initializer,\n                                           use_bias=False)\n        self.batchnorm1 = keras.layers.BatchNormalization()\n\n        # shape change from (batch_size, 31, 31, 512) to (batch_size, 30, 30, 1)\n        self.zero_pad2 = keras.layers.ZeroPadding2D()\n        self.last = keras.layers.Conv2D(1, (4, 4),\n                                           strides=1,\n                                           kernel_initializer=initializer)\n\n\n    def call(self, inputs, training=None):\n        inp, target = inputs\n\n        # concatenating the input and the target\n        x = tf.concat([inp, target], axis=-1)  # (bs, 256, 256, channels*2)\n        x = self.down1(x, training=training)  # (bs, 128, 128, 64)\n        x = self.down2(x, training=training)  # (bs, 64, 64, 128)\n        x = self.down3(x, training=training)  # (bs, 32, 32, 256)\n\n        x = self.zero_pad1(x)  # (bs, 34, 34, 256)\n        x = self.conv(x)  # (bs, 31, 31, 512)\n        x = self.batchnorm1(x, training=training)\n        x = tf.nn.leaky_relu(x)\n\n        x = self.zero_pad2(x)  # (bs, 33, 33, 512)\n        # don't add a sigmoid activation here since\n        # the loss function expects raw logits.\n        x = self.last(x)  # (bs, 30, 30, 1)\n\n        return x","metadata":{"execution":{"iopub.status.busy":"2021-09-29T19:41:35.059960Z","iopub.execute_input":"2021-09-29T19:41:35.060647Z","iopub.status.idle":"2021-09-29T19:41:35.073014Z","shell.execute_reply.started":"2021-09-29T19:41:35.060598Z","shell.execute_reply":"2021-09-29T19:41:35.071913Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"import  os\nimport  tensorflow as tf\nimport  numpy as np\nfrom    tensorflow import keras\nimport  time\nfrom    matplotlib import pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2021-09-29T19:41:35.762514Z","iopub.execute_input":"2021-09-29T19:41:35.765328Z","iopub.status.idle":"2021-09-29T19:41:35.772683Z","shell.execute_reply.started":"2021-09-29T19:41:35.765284Z","shell.execute_reply":"2021-09-29T19:41:35.771196Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"tf.random.set_seed(22)\nnp.random.seed(22)\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\nassert tf.__version__.startswith('2.')","metadata":{"execution":{"iopub.status.busy":"2021-09-29T19:41:36.479074Z","iopub.execute_input":"2021-09-29T19:41:36.479644Z","iopub.status.idle":"2021-09-29T19:41:36.485730Z","shell.execute_reply.started":"2021-09-29T19:41:36.479609Z","shell.execute_reply":"2021-09-29T19:41:36.484182Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"batch_size = 1\nIMG_WIDTH = 256\nIMG_HEIGHT = 256","metadata":{"execution":{"iopub.status.busy":"2021-09-29T19:41:37.502851Z","iopub.execute_input":"2021-09-29T19:41:37.503153Z","iopub.status.idle":"2021-09-29T19:41:37.508110Z","shell.execute_reply.started":"2021-09-29T19:41:37.503123Z","shell.execute_reply":"2021-09-29T19:41:37.506928Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"path_to_zip = keras.utils.get_file('facades.tar.gz',\n                                  cache_subdir=os.path.abspath('.'),\n                                  origin='http://efrosgans.eecs.berkeley.edu/pix2pix/datasets/facades.tar.gz',\n                                  extract=True)","metadata":{"execution":{"iopub.status.busy":"2021-09-29T19:41:38.464820Z","iopub.execute_input":"2021-09-29T19:41:38.465648Z","iopub.status.idle":"2021-09-29T19:41:48.852946Z","shell.execute_reply.started":"2021-09-29T19:41:38.465613Z","shell.execute_reply":"2021-09-29T19:41:48.852058Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"PATH = os.path.join(os.path.dirname(path_to_zip), 'facades/')\nprint('dataset path:', PATH)","metadata":{"execution":{"iopub.status.busy":"2021-09-29T19:41:52.355947Z","iopub.execute_input":"2021-09-29T19:41:52.356345Z","iopub.status.idle":"2021-09-29T19:41:52.370255Z","shell.execute_reply.started":"2021-09-29T19:41:52.356302Z","shell.execute_reply":"2021-09-29T19:41:52.369098Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def load_image(image_file, is_train):\n    \"\"\"\n    load and preprocess images\n    :param image_file:\n    :param is_train:\n    :return:\n    \"\"\"\n    image = tf.io.read_file(image_file)\n    image = tf.image.decode_jpeg(image)\n\n    w = image.shape[1]\n\n    w = w // 2\n    real_image = image[:, :w, :]\n    input_image = image[:, w:, :]\n\n    input_image = tf.cast(input_image, tf.float32)\n    real_image = tf.cast(real_image, tf.float32)\n\n    if is_train:\n        # random jittering\n\n        # resizing to 286 x 286 x 3\n        input_image = tf.image.resize(input_image, [286, 286])\n        real_image = tf.image.resize(real_image, [286, 286])\n\n        # randomly cropping to 256 x 256 x 3\n        stacked_image = tf.stack([input_image, real_image], axis=0)\n        cropped_image = tf.image.random_crop(stacked_image, size=[2, IMG_HEIGHT, IMG_WIDTH, 3])\n        input_image, real_image = cropped_image[0], cropped_image[1]\n\n        if np.random.random() > 0.5:\n            # random mirroring\n            input_image = tf.image.flip_left_right(input_image)\n            real_image = tf.image.flip_left_right(real_image)\n    else:\n        input_image = tf.image.resize(input_image, size=[IMG_HEIGHT, IMG_WIDTH])\n        real_image = tf.image.resize(real_image, size=[IMG_HEIGHT, IMG_WIDTH])\n\n    # normalizing the images to [-1, 1]\n    input_image = (input_image / 127.5) - 1\n    real_image = (real_image / 127.5) - 1\n\n    # [256, 256, 3], [256, 256, 3]\n    # print(input_image.shape, real_image.shape)\n\n    # => [256, 256, 6]\n    out = tf.concat([input_image, real_image], axis=2)\n\n    return out","metadata":{"execution":{"iopub.status.busy":"2021-09-29T19:41:53.127821Z","iopub.execute_input":"2021-09-29T19:41:53.128144Z","iopub.status.idle":"2021-09-29T19:41:53.140918Z","shell.execute_reply.started":"2021-09-29T19:41:53.128114Z","shell.execute_reply":"2021-09-29T19:41:53.139774Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"train_dataset = tf.data.Dataset.list_files(PATH+'/train/*.jpg')\n# The following snippet can not work, so load it hand by hand.\n# train_dataset = train_dataset.map(lambda x: load_image(x, True)).batch(1)\ntrain_iter = iter(train_dataset)\ntrain_data = []\nfor x in train_iter:\n    train_data.append(load_image(x, True))","metadata":{"execution":{"iopub.status.busy":"2021-09-29T19:41:53.851476Z","iopub.execute_input":"2021-09-29T19:41:53.851813Z","iopub.status.idle":"2021-09-29T19:41:58.596971Z","shell.execute_reply.started":"2021-09-29T19:41:53.851773Z","shell.execute_reply":"2021-09-29T19:41:58.595857Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"print(len(train_data), train_data[0].shape, type(train_data[0]))","metadata":{"execution":{"iopub.status.busy":"2021-09-29T19:41:58.600255Z","iopub.execute_input":"2021-09-29T19:41:58.600783Z","iopub.status.idle":"2021-09-29T19:41:58.609319Z","shell.execute_reply.started":"2021-09-29T19:41:58.600715Z","shell.execute_reply":"2021-09-29T19:41:58.607994Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"train_data = tf.stack(train_data, axis=0)\n# [800, 256, 256, 3]\nprint('train:', train_data.shape)\ntrain_dataset = tf.data.Dataset.from_tensor_slices(train_data)\ntrain_dataset = train_dataset.shuffle(400).batch(1)","metadata":{"execution":{"iopub.status.busy":"2021-09-29T19:41:58.611020Z","iopub.execute_input":"2021-09-29T19:41:58.611814Z","iopub.status.idle":"2021-09-29T19:41:59.100291Z","shell.execute_reply.started":"2021-09-29T19:41:58.611766Z","shell.execute_reply":"2021-09-29T19:41:59.099291Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"test_dataset = tf.data.Dataset.list_files(PATH+'test/*.jpg')\n# test_dataset = test_dataset.map(lambda x: load_image(x, False)).batch(1)\ntest_iter = iter(test_dataset)\ntest_data = []\nfor x in test_iter:\n    test_data.append(load_image(x, False))\ntest_data = tf.stack(test_data, axis=0)\n# [800, 256, 256, 3]\nprint('test:', test_data.shape)\ntest_dataset = tf.data.Dataset.from_tensor_slices(test_data)\ntest_dataset = test_dataset.shuffle(400).batch(1)","metadata":{"execution":{"iopub.status.busy":"2021-09-29T19:42:00.026050Z","iopub.execute_input":"2021-09-29T19:42:00.026813Z","iopub.status.idle":"2021-09-29T19:42:00.556550Z","shell.execute_reply.started":"2021-09-29T19:42:00.026769Z","shell.execute_reply":"2021-09-29T19:42:00.555643Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"generator = Generator()\ngenerator.build(input_shape=(batch_size, 256, 256, 3))\ngenerator.summary()\ndiscriminator = Discriminator()\ndiscriminator.build(input_shape=[(batch_size, 256, 256, 3), (batch_size, 256, 256, 3)])\ndiscriminator.summary()\n\ng_optimizer = keras.optimizers.Adam(learning_rate=2e-4, beta_1=0.5)\nd_optimizer = keras.optimizers.Adam(learning_rate=2e-4, beta_1=0.5)","metadata":{"execution":{"iopub.status.busy":"2021-09-29T19:42:00.739965Z","iopub.execute_input":"2021-09-29T19:42:00.740858Z","iopub.status.idle":"2021-09-29T19:42:01.465545Z","shell.execute_reply.started":"2021-09-29T19:42:00.740822Z","shell.execute_reply":"2021-09-29T19:42:01.464646Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"def discriminator_loss(disc_real_output, disc_generated_output):\n    # [1, 30, 30, 1] with [1, 30, 30, 1]\n    # print(disc_real_output.shape, disc_generated_output.shape)\n    real_loss = keras.losses.binary_crossentropy(\n                    tf.ones_like(disc_real_output), disc_real_output, from_logits=True)\n\n    generated_loss = keras.losses.binary_crossentropy(\n                    tf.zeros_like(disc_generated_output), disc_generated_output, from_logits=True)\n\n    real_loss = tf.reduce_mean(real_loss)\n    generated_loss = tf.reduce_mean(generated_loss)\n\n    total_disc_loss = real_loss + generated_loss\n\n    return total_disc_loss\n\n\n\ndef generator_loss(disc_generated_output, gen_output, target):\n\n    LAMBDA = 100\n\n    gan_loss = keras.losses.binary_crossentropy(\n                tf.ones_like(disc_generated_output), disc_generated_output, from_logits=True)\n    # mean absolute error\n    l1_loss = tf.reduce_mean(tf.abs(target - gen_output))\n\n    gan_loss = tf.reduce_mean(gan_loss)\n\n    total_gen_loss = gan_loss + (LAMBDA * l1_loss)\n\n    return total_gen_loss","metadata":{"execution":{"iopub.status.busy":"2021-09-29T19:42:01.656587Z","iopub.execute_input":"2021-09-29T19:42:01.657108Z","iopub.status.idle":"2021-09-29T19:42:01.665675Z","shell.execute_reply.started":"2021-09-29T19:42:01.657075Z","shell.execute_reply":"2021-09-29T19:42:01.664656Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"def generate_images(model, test_input, tar, epoch):\n    # the training=True is intentional here since\n    # we want the batch statistics while running the model\n    # on the test dataset. If we use training=False, we will get\n    # the accumulated statistics learned from the training dataset\n    # (which we don't want)\n    prediction = model(test_input, training=True)\n    plt.figure(figsize=(15,15))\n\n    display_list = [test_input[0], tar[0], prediction[0]]\n    title = ['Input Image', 'Ground Truth', 'Predicted Image']\n\n    for i in range(3):\n        plt.subplot(1, 3, i+1)\n        plt.title(title[i])\n        # getting the pixel values between [0, 1] to plot it.\n        plt.imshow(display_list[i] * 0.5 + 0.5)\n        plt.axis('off')\n    plt.savefig('./epoch%d.png'%epoch)\n    print('saved images.')\n    # plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-29T19:42:02.403500Z","iopub.execute_input":"2021-09-29T19:42:02.403814Z","iopub.status.idle":"2021-09-29T19:42:02.411864Z","shell.execute_reply.started":"2021-09-29T19:42:02.403785Z","shell.execute_reply":"2021-09-29T19:42:02.410369Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"def main():\n\n    epochs = 10\n\n    for epoch in range(epochs):\n\n        start = time.time()\n\n        for step, inputs in enumerate(train_dataset):\n\n            input_image, target = tf.split(inputs, num_or_size_splits=[3, 3], axis=3)\n            # print(input_image.shape, target.shape)\n            # print(type(input_image), type(target))\n\n            with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n                # get generated pixel2pixel image\n                gen_output = generator(input_image, training=True)\n                # fed real pixel2pixel image together with original image\n                disc_real_output = discriminator([input_image, target], training=True)\n                # fed generated/fake pixel2pixel image together with original image\n                disc_generated_output = discriminator([input_image, gen_output], training=True)\n\n                gen_loss = generator_loss(disc_generated_output, gen_output, target)\n                disc_loss = discriminator_loss(disc_real_output, disc_generated_output)\n\n            generator_gradients = gen_tape.gradient(gen_loss, generator.trainable_variables)\n            g_optimizer.apply_gradients(zip(generator_gradients, generator.trainable_variables))\n\n            discriminator_gradients = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n            d_optimizer.apply_gradients(zip(discriminator_gradients, discriminator.trainable_variables))\n\n            if step% 100 == 0:\n                # print(disc_loss.shape, gen_loss.shape)\n                print(epoch, step, float(disc_loss), float(gen_loss))\n\n        if epoch % 1 == 0:\n\n            for inputs in test_dataset:\n                input_image, target = tf.split(inputs, num_or_size_splits=[3, 3], axis=3)\n                generate_images(generator, input_image, target, epoch)\n                break\n\n        print('Time taken for epoch {} is {} sec\\n'.format(epoch + 1, time.time() - start))\n\n\n\n    for inputs in test_dataset:\n        input_image, target = tf.split(inputs, num_or_size_splits=[3, 3], axis=3)\n        generate_images(generator, input_image, target, 99999)\n        break\n\n\nif __name__ == '__main__':\n    main()","metadata":{"execution":{"iopub.status.busy":"2021-09-29T19:42:03.083178Z","iopub.execute_input":"2021-09-29T19:42:03.083691Z","iopub.status.idle":"2021-09-29T19:50:46.430996Z","shell.execute_reply.started":"2021-09-29T19:42:03.083659Z","shell.execute_reply":"2021-09-29T19:50:46.429794Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}